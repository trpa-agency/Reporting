{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Development Right Transfers\n",
    "#### Meeting Agenda: Development Rights Transfer & Conversion Analysis\n",
    "\n",
    "1. Objectives & Data Review\n",
    "    * Goal: Standardize ETL of transfer â†’ conversion process & confirm data integration\n",
    "    * Review analysis requirements\n",
    "    * Review of data sources:\n",
    "        * LT Info TDR Transactions (APN, type, land capability, quantity)\n",
    "        * Parcel Master (jurisdiction, town center proximity, local plan)\n",
    "        * Accela (transfer status, permit data)\n",
    "2. Coding Plan & Standardization\n",
    "    * Walkthrough of data integration approach\n",
    "    * Confirm transfer first, then convert process\n",
    "    * Address any inconsistencies or edge cases\n",
    "3. Key Analyses\n",
    "    * Land Capability: SEZ, sensitive, non-sensitive\n",
    "    * Distance from Center: Trends by proximity\n",
    "    * Interjurisdictional Activity: Transfers & conversions across boundaries\n",
    "4. Next Steps\n",
    "    * Assign action items & timeline for completion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes: From Ken\n",
    "- Transfer Reporting Status - comes from LTinfo\n",
    "    - Transfers come out of LTinfo \n",
    "- Status of Transaction - comes from Accela\n",
    "    - transaction is considered complete and development rights are moved to recieving parcel when the transfer is acknowledged\n",
    "- Status of the Development on the Recieving Parcel\n",
    "    - associate the transaction in LTinfo to the development project in Accela/Local Jurisdiction data\n",
    "    - what is the status of the development project? (i.e. when is it existing on the ground)\n",
    " \n",
    "- Transfer vs Conversion sequence\n",
    "    - should be transfer dev rights then convert on the recieving parcel \n",
    "- Parcel Geneology Lookup needs to be built\n",
    "    - Identify old APNs and current APNs\n",
    "- Data Clean-up\n",
    "    - categorization of unit types has evolved (e.g. PRUU vs RUU) same/same now\n",
    "- Conversions\n",
    "    - we track the transfers and then convert onto the recieving parcel (or onsite conversion)\n",
    "    - track conversion net change\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pathlib\n",
    "import arcpy\n",
    "from arcgis.features import FeatureLayer, GeoAccessor, GeoSeriesAccessor\n",
    "from utils import *\n",
    "from datetime import datetime\n",
    "from time import strftime  \n",
    "# set data frame display options\n",
    "# pandas options\n",
    "pd.options.mode.copy_on_write = True\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.options.display.max_columns = 999\n",
    "pd.options.display.max_rows    = 999\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "   \n",
    "# set environement workspace to in memory \n",
    "arcpy.env.workspace = 'memory'\n",
    "# overwrite true\n",
    "arcpy.env.overwriteOutput = True\n",
    "# Set spatial reference to NAD 1983 UTM Zone 10N\n",
    "sr = arcpy.SpatialReference(26910)\n",
    "arcpy.env.outputCoordinateSystem = sr\n",
    "\n",
    "# current working directory\n",
    "local_path = pathlib.Path().absolute()\n",
    "# set data path as a subfolder of the current working directory TravelDemandModel\\2022\\\n",
    "data_dir   = local_path.parents[0] / 'Reporting/data/raw_data'\n",
    "# folder to save processed data\n",
    "out_dir    = local_path.parents[0] / 'Reporting/data/processed_data'\n",
    "# local geodatabase path\n",
    "local_gdb = Path(\"C:\\GIS\\Scratch.gdb\")\n",
    "# network path to connection files\n",
    "filePath = \"F:/GIS/PARCELUPDATE/Workspace/\"\n",
    "# database file path \n",
    "sdeBase    = os.path.join(filePath, \"Vector.sde\")\n",
    "sdeCollect = os.path.join(filePath, \"Collection.sde\")\n",
    "sdeTabular = os.path.join(filePath, \"Tabular.sde\")\n",
    "sdeEdit    = os.path.join(filePath, \"Edit.sde\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "### Data Pipeline Overview\n",
    "1. Extract data from LT Info, Parcel Master, and Accela.\n",
    "2. Clean and preprocess data for consistency.\n",
    "3. Merge datasets using APN as the primary key.\n",
    "4. Standardize workflow: **transfer first, then convert**.\n",
    "5. Identify and resolve inconsistencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Extract data from LT Info, Parcel Master, and Accela."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Sources\n",
    "- **LT Info TDR Transactions**: Tracks APN, development right type, land capability, and quantity.\n",
    "- **Parcel Master**: Provides jurisdiction, town center proximity, and\n",
    "- **Accela**: Contains transfer status and permit details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Sources\n",
    "* https://www.laketahoeinfo.org/WebServices/List\n",
    "* https://maps.trpa.org/server/rest/services/\n",
    "* https://parcels.laketahoeinfo.org/TdrTransaction/TransactionList\n",
    "* sdeBase, sdeCollect, sdeTabular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Parcel Master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# web service and database paths\n",
    "# portal_ParcelMaster = 'https://maps.trpa.org/server/rest/services/Parcel_Master/FeatureServer/0'\n",
    "sde_ParcelMaster    = Path(sdeBase) / \"sde.SDE.Parcels\\\\sde.SDE.Parcel_Master\"\n",
    "# get spatially enabled dataframes\n",
    "sdfParcels = pd.DataFrame.spatial.from_featureclass(sde_ParcelMaster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 LTInfo Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer grid downloaded from LTinfo https://parcels.laketahoeinfo.org/TdrTransaction/TransactionList\n",
    "# dfTransactionsGrid = pd.read_csv(local_path / \"data/raw_data/TransactedAndBankedDevelopmentRights.csv\")\n",
    "\n",
    "# grid path\n",
    "# dfTransactionsGrid = pd.read_excel(local_path / \"data/raw_data/TdrTransactions as of 02_06_2025 12_00 PM.xlsx\")a\n",
    "dfTransfers   = pd.read_excel(data_dir / \"TdrTransactions as of 02_06_2025 12_00 PM.xlsx\", sheet_name='Transfers')\n",
    "dfConversions = pd.read_excel(data_dir / \"TdrTransactions as of 02_06_2025 12_00 PM.xlsx\", sheet_name='Conversions') \n",
    "dfConvTransfer = pd.read_excel(data_dir / \"TdrTransactions as of 02_06_2025 12_00 PM.xlsx\", sheet_name='Conversion with Transfers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LT Info Data\n",
    "# get banked\n",
    "dfDevRightBanked     = pd.read_json(\"https://www.laketahoeinfo.org/WebServices/GetBankedDevelopmentRights/JSON/e17aeb86-85e3-4260-83fd-a2b32501c476\")\n",
    "# Verified Development Rights from Accela as a DataFrame\n",
    "# Development Rights Transacted and Banked as a DataFrame\n",
    "dfDevRightTransacted = pd.read_json(\"https://www.laketahoeinfo.org/WebServices/GetTransactedAndBankedDevelopmentRights/JSON/e17aeb86-85e3-4260-83fd-a2b32501c476\")\n",
    "dfDevRightForAccela  = pd.read_json(\"https://www.laketahoeinfo.org/WebServices/GetParcelDevelopmentRightsForAccela/JSON/e17aeb86-85e3-4260-83fd-a2b32501c476\")\n",
    "# All Parcels as a DataFrame\n",
    "dfLTParcel           = pd.read_json(\"https://www.laketahoeinfo.org/WebServices/GetAllParcels/JSON/e17aeb86-85e3-4260-83fd-a2b32501c476\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Accela Permit Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API access to download excel file of Accela Record Details\n",
    "accelaRecorDetails = \"https://laketahoeinfo.org/Api/GetAccelaRecordDetailsExcel/1A77D078-B83E-44E0-8CA5-8D7429E1A6B4\"\n",
    "# download the file\n",
    "dfAccelaRecord = pd.read_excel(accelaRecorDetails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get detailed project data report\n",
    "dfDetailedProjectData = pd.read_excel(data_dir / \"PermitStatusReport.xlsx\")\n",
    "dfDetailedProjectData.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Merge & Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_schema = ['Transaction Status',\n",
    "                'Transaction Type',\n",
    "                'Development Right',\n",
    "                'Sending Parcel APN',\n",
    "                'Receiving Parcel APN',\n",
    "                'Sending Quantity',\n",
    "                'Receiving Quantity',\n",
    "                'Sending Bailey Rating',\n",
    "                'Receiving Bailey Rating',\n",
    "                'Issued',\n",
    "                'Acknowledged',\n",
    "                'Project Completed', \n",
    "                'APN',\n",
    "                'JURISDICTION',  \n",
    "                'PLAN_TYPE',\n",
    "                'LOCATION_TO_TOWNCENTER',\n",
    "                'SHAPE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter columns in sdf Parcels\n",
    "parcels = sdfParcels[['APN', 'JURISDICTION', 'PLAN_TYPE', 'LOCATION_TO_TOWNCENTER', 'SHAPE']]\n",
    "# merge dfTransfers with dfDetailedProjectData\n",
    "df = pd.merge(dfTransfers, dfDetailedProjectData, left_on='Accela ID', right_on='File Number', how='left')\n",
    "# merge Sending APN to Parcel APN\n",
    "df = pd.merge(parcels, df, left_on='APN', right_on= 'Sending Parcel APN', how='inner')\n",
    "# limit to final schema columns\n",
    "df = df[final_schema]\n",
    "# convert numeric columns to float\n",
    "df['Sending Quantity'] = df['Sending Quantity'].astype(float)\n",
    "df['Receiving Quantity'] = df['Receiving Quantity'].astype(float)\n",
    "# export df to feature class\n",
    "df.spatial.to_featureclass(local_gdb / \"Parcel_Transfers\", sanitize_columns=True, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's do this join twice once for the sending and once for the receiving\n",
    "# merge dfTransfers with dfDetailedProjectData\n",
    "df = pd.merge(dfTransfers, dfDetailedProjectData, left_on='Accela ID', right_on='File Number', how='left')\n",
    "\n",
    "# merge Receiving APN to Parcel APN\n",
    "dfRecieving = pd.merge(parcels, df, left_on='APN', right_on= 'Receiving Parcel APN', how='inner')\n",
    "dfSending   = pd.merge(parcels, df, left_on='APN', right_on= 'Sending Parcel APN', how='inner')\n",
    "\n",
    "# limit to final schema columns\n",
    "dfRecieving = dfRecieving[final_schema]\n",
    "dfSending   = dfSending[final_schema]\n",
    "\n",
    "dfSending['Transaction Type'] = 'Sending'\n",
    "dfRecieving['Transaction Type'] = 'Receiving'\n",
    "dfSending['Net_Change'] = 0 - dfSending['Sending Quantity']\n",
    "dfRecieving['Net_Change'] = dfRecieving['Receiving Quantity']\n",
    "\n",
    "# group by APN, Development Right Type, and sum net change\n",
    "dfRecieving = dfRecieving.groupby(['APN', 'Development Right'], as_index=False).agg({'Net_Change': 'sum'})\n",
    "dfSending   = dfSending.groupby(['APN', 'Development Right'], as_index=False).agg({'Net_Change': 'sum'})\n",
    "\n",
    "# stack the two dataframes\n",
    "df = pd.concat([dfRecieving, dfSending], axis=0, ignore_index=True)\n",
    "# df.spatial.to_featureclass(local_gdb / \"Parcel_Transfers\", sanitize_columns=True, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dfTransfers with dfDetailedProjectData\n",
    "df = pd.merge(dfTransfers, dfDetailedProjectData, left_on='Accela ID', right_on='File Number', how='left')\n",
    "# merge Sending APN to Parcel APN\n",
    "df = pd.merge(df, parcels, left_on='Sending Parcel APN', right_on='APN', how='left')\n",
    "# rename parcels fields with prefix SENDING_\n",
    "df.rename(columns={'JURISDICTION': 'SENDING_JURISDICTION', 'PLAN_TYPE': 'SENDING_PLAN_TYPE', 'LOCATION_TO_TOWNCENTER': 'SENDING_LOCATION_TO_TOWNCENTER'}, inplace=True)\n",
    "# merge Receiving APN to Parcel APN\n",
    "df = pd.merge(df, parcels, left_on='Receiving Parcel APN', right_on='APN', how='left')\n",
    "# rename parcels fields with prefix RECEIVING_\n",
    "df.rename(columns={'JURISDICTION': 'RECEIVING_JURISDICTION', 'PLAN_TYPE': 'RECEIVING_PLAN_TYPE', 'LOCATION_TO_TOWNCENTER': 'RECEIVING_LOCATION_TO_TOWNCENTER'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Analyses & Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Land Capability Analysis\n",
    "- Categorize transfers by SEZ, sensitive, and non-sensitive land."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# web service and database paths\n",
    "# portal_ParcelMaster = 'https://maps.trpa.org/server/rest/services/Parcel_Master/FeatureServer/0'\n",
    "sde_ParcelMaster    = Path(sdeBase) / \"sde.SDE.Parcels\\\\sde.SDE.Parcel_Master\"\n",
    "# get spatially enabled dataframes\n",
    "sdfParcels = pd.DataFrame.spatial.from_featureclass(sde_ParcelMaster)\n",
    "\n",
    "# Development Rights Transacted and Banked as a DataFrame\n",
    "dfDevRightTransacted = pd.read_json(\"https://www.laketahoeinfo.org/WebServices/GetTransactedAndBankedDevelopmentRights/JSON/e17aeb86-85e3-4260-83fd-a2b32501c476\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdeParcelHistory = Path(sdeBase) / \"sde.SDE.Parcels\\\\sde.SDE.Parcel_History\"\n",
    "parcel_history = pd.DataFrame.spatial.from_featureclass(sdeParcelHistory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcel_history.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_apn(old_apn, parcel_history):\n",
    "    \"\"\"\n",
    "    Given an old APN, return the new APN(s) from the parcel history DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - old_apn (str): The historical APN to look up.\n",
    "    - parcel_history (pd.DataFrame): DataFrame with parcel history, containing APN, Status, APN_Current, and APNs_Current.\n",
    "\n",
    "    Returns:\n",
    "    - str | list | None: The new APN (str), list of APNs if split, or None if not found.\n",
    "    \"\"\"\n",
    "    row = parcel_history[parcel_history['APN'] == old_apn]\n",
    "\n",
    "    if row.empty:\n",
    "        return None\n",
    "\n",
    "    row = row.iloc[0]  # There should be only one match per old APN\n",
    "\n",
    "    # Priority to APN_Current if it's a clean one-to-one mapping\n",
    "    if pd.notna(row['APN_Current']):\n",
    "        return row['APN_Current']\n",
    "\n",
    "    # If there's a list in APNs_Current\n",
    "    if pd.notna(row['APNs_Current']):\n",
    "        apns = [apn.strip() for apn in row['APNs_Current'].split(',')]\n",
    "        return apns if len(apns) > 1 else apns[0]\n",
    "\n",
    "    return None\n",
    "\n",
    "# example usage\n",
    "get_new_apn('022-343-27', parcel_history)\n",
    "# make a list of all APNs that didnt join to parcel master SHAPE is null\n",
    "dfNoAPN = df[df['SHAPE'].isnull()]\n",
    "# get the APNs that are not in the parcel master\n",
    "dfNoAPN = dfNoAPN[['APN']]\n",
    "# remove duplicates\n",
    "dfNoAPN = dfNoAPN.drop_duplicates()\n",
    "# get the APNs from the parcel history that are not in the parcel master\n",
    "old_apns = dfNoAPN['APN'].tolist()\n",
    "\n",
    "# next lets itterate through a list of APNs to return new APNs and create a column in the other dataframe for 'NewAPN'\n",
    "def get_new_apns(df, old_apns parcel_history):\n",
    "    \"\"\"\n",
    "    Given a DataFrame with APNs, return a new DataFrame with the new APNs.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): DataFrame containing APNs.\n",
    "    - parcel_history (pd.DataFrame): DataFrame with parcel history.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with original APNs and their corresponding new APNs.\n",
    "    \"\"\"\n",
    "    df['NewAPN'] = df['APN'].apply(lambda x: get_new_apn(x, parcel_history))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a copy\n",
    "df = dfDevRightTransacted[['APN',\n",
    "                        'RecordType',\n",
    "                        'DevelopmentRight',\n",
    "                        'LandCapability',\n",
    "                        'IPESScore',\n",
    "                        'CumulativeBankedQuantity',\n",
    "                        'RemainingBankedQuantity',\n",
    "                        'LastUpdated',\n",
    "                        'TransactionNumber',\n",
    "                        'TransactionApprovalDate',\n",
    "                        'SendingParcel',\n",
    "                        'ReceivingParcel',\n",
    "                        'AccelaID',\n",
    "                        'JurisdictionPermitNumber']].copy()\n",
    "\n",
    "# filter columns of copy\n",
    "parcels = sdfParcels[['APN', \n",
    "                        'JURISDICTION',  \n",
    "                        'PLAN_ID',\n",
    "                        'PLAN_NAME',\n",
    "                        'ZONING_ID',\n",
    "                        'ZONING_DESCRIPTION',\n",
    "                        'TOWN_CENTER',\n",
    "                        'LOCATION_TO_TOWNCENTER',\n",
    "                        'TAZ', \n",
    "                        'WITHIN_BONUSUNIT_BNDY', \n",
    "                        'WITHIN_TRPA_BNDY',\n",
    "                        'LOCAL_PLAN_HYPERLINK',\n",
    "                        'LTINFO_HYPERLINK',\n",
    "                        'PARCEL_ACRES', 'PARCEL_SQFT', 'SHAPE']].copy()\n",
    "\n",
    "# fix issues with LOCATION_TO_TOWNCENTER values\n",
    "parcels['LOCATION_TO_TOWNCENTER'] = parcels['LOCATION_TO_TOWNCENTER'].str.strip()\n",
    "parcels['LOCATION_TO_TOWNCENTER'].replace({'Within Quarter Mile of Town Center': 'Quarter Mile Buffer',\n",
    "                                            'Within Town Center': 'Town Center',\n",
    "                                            'Further than Quarter Mile from Town Center': 'Outside Buffer'\n",
    "                                            }, inplace=True)\n",
    "\n",
    "# filter to only include the record types in the list\n",
    "record_types = ['Conversion With Transfer Receiving Parcel',\n",
    "                'Conversion With Transfer Sending Parcel',\n",
    "                'Transfer Receiving Parcel', \n",
    "                'Transfer Sending Parcel']\n",
    "\n",
    "# filter the dataframe to only include the record types in the list\n",
    "df = df[df['RecordType'].isin(record_types)]\n",
    "# # # if ApprovalData is not  then it is approved\n",
    "df = df[df['TransactionApprovalDate'] != '']\n",
    "\n",
    "# categorize bailey rating\n",
    "landcap_dict = {'1b':'SEZ',\n",
    "                '1a':'Sensitive',\n",
    "                '1c':'Sensitive',\n",
    "                '2':'Sensitive',\n",
    "                '3':'Sensitive',\n",
    "                '4':'Non-Sensitive',\n",
    "                '5':'Non-Sensitive',\n",
    "                '6':'Non-Sensitive',\n",
    "                '7':'Non-Sensitive'}\n",
    "\n",
    "# land capability class = strip -1 if string starts with Bailey\n",
    "df.loc[df['LandCapability'].notnull() & df['LandCapability'].str.startswith('Bailey'), \n",
    "                                        'LandCapability'] = df['LandCapability'].str.strip('Bailey ')\n",
    "\n",
    "# map the land capability class to the dictionary after filtering out 'IPES'\n",
    "df.loc[df['LandCapability'].notnull() & df['LandCapability'] != 'IPES', \n",
    "                                        'LandCapabilityCategory'] = df['LandCapability'].map(landcap_dict)\n",
    "\n",
    "# if IPESScore class to 0 = SEZ, 1-725 = Sensitive, >725 = Non Sensitive\n",
    "df.loc[df['IPESScore'] == 0, 'LandCapabilityCategory'] = 'SEZ'\n",
    "df.loc[(df['IPESScore'] > 0) & (df['IPESScore'] <= 725), 'LandCapabilityCategory'] = 'Sensitive'\n",
    "df.loc[df['IPESScore'] > 725, 'LandCapabilityCategory'] = 'Non-Sensitive'\n",
    "\n",
    "# merge with parcels\n",
    "df = pd.merge(df, parcels, left_on='APN', right_on='APN', how='left')\n",
    "def get_new_apn(old_apn, parcel_history):\n",
    "    \"\"\"\n",
    "    Given an old APN, return the new APN(s) from the parcel history DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - old_apn (str): The historical APN to look up.\n",
    "    - parcel_history (pd.DataFrame): DataFrame with parcel history, containing APN, Status, APN_Current, and APNs_Current.\n",
    "\n",
    "    Returns:\n",
    "    - str | list | None: The new APN (str), list of APNs if split, or None if not found.\n",
    "    \"\"\"\n",
    "    row = parcel_history[parcel_history['APN'] == old_apn]\n",
    "\n",
    "    if row.empty:\n",
    "        return None\n",
    "\n",
    "    row = row.iloc[0]  # There should be only one match per old APN\n",
    "\n",
    "    # Priority to APN_Current if it's a clean one-to-one mapping\n",
    "    if pd.notna(row['APN_Current']):\n",
    "        return row['APN_Current']\n",
    "\n",
    "    # If there's a list in APNs_Current\n",
    "    if pd.notna(row['APNs_Current']):\n",
    "        apns = [apn.strip() for apn in row['APNs_Current'].split(',')]\n",
    "        return apns if len(apns) > 1 else apns[0]\n",
    "\n",
    "    return None\n",
    "\n",
    "# example usage\n",
    "get_new_apn('022-343-27', parcel_history)\n",
    "# make a list of all APNs that didnt join to parcel master SHAPE is null\n",
    "dfNoAPN = df[df['SHAPE'].isnull()]\n",
    "# get the APNs that are not in the parcel master\n",
    "dfNoAPN = dfNoAPN[['APN']]\n",
    "# remove duplicates\n",
    "dfNoAPN = dfNoAPN.drop_duplicates()\n",
    "# get the APNs from the parcel history that are not in the parcel master\n",
    "old_apns = dfNoAPN['APN'].tolist()\n",
    "\n",
    "# next lets itterate through a list of APNs to return new APNs and create a column in the other dataframe for 'NewAPN'\n",
    "def get_new_apns(df, old_apns parcel_history):\n",
    "    \"\"\"\n",
    "    Given a DataFrame with APNs, return a new DataFrame with the new APNs.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): DataFrame containing APNs.\n",
    "    - parcel_history (pd.DataFrame): DataFrame with parcel history.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with original APNs and their corresponding new APNs.\n",
    "    \"\"\"\n",
    "    df['NewAPN'] = df['APN'].apply(lambda x: get_new_apn(x, parcel_history))\n",
    "    return df\n",
    "\n",
    "### Transform functions ###\n",
    "# SendingVsReceiving from RecordType\n",
    "def classify_sending_receiving(record_type):\n",
    "    if \"Receiving Parcel\" in record_type:\n",
    "        return \"Receiving\"\n",
    "    elif \"Sending Parcel\" in record_type:\n",
    "        return \"Sending\"\n",
    "    return \"Unknown\"\n",
    "\n",
    "# get the sensitivity of the counterpart parcel\n",
    "def get_counterpart_sensitivity(row):\n",
    "    if row['SendingVsReceiving'] == 'Receiving':\n",
    "        return apn_to_sensitivity.get(row['SendingParcel'], 'Unknown')\n",
    "    elif row['SendingVsReceiving'] == 'Sending':\n",
    "        return apn_to_sensitivity.get(row['ReceivingParcel'], 'Unknown')\n",
    "    return 'Unknown'\n",
    "\n",
    "# Build the From â†’ To sensitivity string\n",
    "def classify_sensitivity_transition(row):\n",
    "    if row['SendingVsReceiving'] == 'Sending':\n",
    "        return f\"From {row['LandCapabilityCategory']} to {row['CounterpartSensitivity']}\"\n",
    "    elif row['SendingVsReceiving'] == 'Receiving':\n",
    "        return f\"From {row['CounterpartSensitivity']} to {row['LandCapabilityCategory']}\"\n",
    "    return 'Unknown'\n",
    "\n",
    "# Look up counterparty Town Center classification\n",
    "def get_counterpart_towncenter(row):\n",
    "    if row['SendingVsReceiving'] == 'Receiving':\n",
    "        return apn_to_towncenter.get(row['SendingParcel'], 'Unknown')\n",
    "    elif row['SendingVsReceiving'] == 'Sending':\n",
    "        return apn_to_towncenter.get(row['ReceivingParcel'], 'Unknown')\n",
    "    return 'Unknown'\n",
    "\n",
    "# Build the From â†’ To Town Center transition string\n",
    "def classify_towncenter_transition(row):\n",
    "    if row['SendingVsReceiving'] == 'Sending':\n",
    "        return f\"From {row['LOCATION_TO_TOWNCENTER']} to {row['CounterpartTownCenter']}\"\n",
    "    elif row['SendingVsReceiving'] == 'Receiving':\n",
    "        return f\"From {row['CounterpartTownCenter']} to {row['LOCATION_TO_TOWNCENTER']}\"\n",
    "    return 'Unknown'\n",
    "\n",
    "# Build combined category for land sensitivity and town center location\n",
    "def build_land_towncenter_combo(row):\n",
    "    sending_sens = row['LandCapabilityCategory']  # e.g. 'Sensitive' or 'Non-Sensitive'\n",
    "    sending_loc = row['LOCATION_TO_TOWNCENTER']  # e.g. 'Town Center', 'Quarter Mile Buffer', 'Outside Buffer'\n",
    "    receiving_sens = row['CounterpartSensitivity']  # e.g. 'Sensitive' or 'Non-Sensitive'\n",
    "    receiving_loc = row['CounterpartTownCenter']  # e.g. 'Town Center', 'Quarter Mile Buffer', 'Outside Buffer'\n",
    "    \n",
    "    if pd.isna(sending_sens) or pd.isna(sending_loc) or pd.isna(receiving_sens) or pd.isna(receiving_loc):\n",
    "        return 'Unknown'\n",
    "    return f\"Sending: {sending_sens} ({sending_loc}) â†’ Receiving: {receiving_sens} ({receiving_loc})\"\n",
    "\n",
    "# classify sending vs receiving\n",
    "df['SendingVsReceiving'] = df['RecordType'].apply(classify_sending_receiving)\n",
    "# Create lookup from APN to LandCapabilityCategory\n",
    "apn_to_sensitivity = df.set_index('APN')['LandCapabilityCategory'].to_dict()\n",
    "df['CounterpartSensitivity'] = df.apply(get_counterpart_sensitivity, axis=1)\n",
    "df['Sensitivity_Transition'] = df.apply(classify_sensitivity_transition, axis=1)\n",
    "# Create a lookup from APN to LOCATION_TO_TOWNCENTER\n",
    "apn_to_towncenter = df.set_index('APN')['LOCATION_TO_TOWNCENTER'].to_dict()\n",
    "df['CounterpartTownCenter'] = df.apply(get_counterpart_towncenter, axis=1)\n",
    "df['TownCenter_Transition'] = df.apply(classify_towncenter_transition, axis=1)\n",
    "\n",
    "df['LandSensitivity_and_TownCenter_Transition'] = df.apply(build_land_towncenter_combo, axis=1)\n",
    "\n",
    "# export to feature class\n",
    "df.spatial.to_featureclass(local_gdb / \"Parcel_Transfers\", sanitize_columns=False, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proximity Analysis\n",
    "- Assess distance of transfers from town centers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.copy()\n",
    "# categorize\n",
    "landcap_dict = {'1b':'SEZ',\n",
    "                '1a':'Sensitive',\n",
    "                '2':'Sensitive',\n",
    "                '3':'Sensitive',\n",
    "                '4':'Non-Sensitive',\n",
    "                '5':'Non-Sensitive',\n",
    "                '6':'Non-Sensitive',\n",
    "                '7':'Non-Sensitive'}\n",
    "# map land capability to land capability category\n",
    "df['Sending_Land_Capability_Category'] = df['Sending Bailey Rating'].map(landcap_dict)\n",
    "# map land capability to land capability category\n",
    "df['Receiving_Land_Capability_Category'] = df['Receiving Bailey Rating'].map(landcap_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby sending_land_capability_category and receiving_land_capability_category\n",
    "df_landcap_group = df.groupby(['Sending_Land_Capability_Category', 'Receiving_Land_Capability_Category', 'Development Right']).agg({\n",
    "                                'Sending Quantity':'sum',\n",
    "                                'Receiving Quantity': 'sum'}).reset_index()\n",
    "df_landcap_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_towncenter = df.groupby(['SENDING_LOCATION_TO_TOWNCENTER', 'RECEIVING_LOCATION_TO_TOWNCENTER', 'Development Right']).agg({\n",
    "                                'Sending Quantity':'sum',\n",
    "                                'Receiving Quantity': 'sum'}).reset_index() \n",
    "df_towncenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sending land capability category vs receiving location to town center\n",
    "\n",
    "# recieving land capability category vs sending location to town center\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interjurisdictional Transfers\n",
    "- Examine development right transfers across jurisdictional boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "df_jurisdiction = df.groupby(['SENDING_JURISDICTION', 'RECEIVING_JURISDICTION', 'Development Right']).agg({\n",
    "                                'Sending Quantity':'sum',\n",
    "                                'Receiving Quantity': 'sum'}).reset_index() \n",
    "df_jurisdiction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "### Action Items\n",
    "- Build Accela Report that gets us issued data \n",
    "- Get Accela ID and Jurisdiction Permit Number into LTinfo Web Service Development Rights Transacted and Banked\n",
    "- Fix Parcel geneology for current 'APN', 'Recieving APN' and 'Sending APN' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arcgispro-py3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
