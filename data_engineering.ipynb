{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Engineering Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Terminology "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Data engineering can consist of ***collection, cleaning, transformation, processing, and automating and monitoring tasks***\n",
    "* Collection - examples include getting data from a rest service as a\n",
    "* Cleaning - categorizing \n",
    "* Transformation - cateogorizing, standardization, \n",
    "* Processing - algorithm, pivot, groupby, merge\n",
    "* Automating - schedule task, Apache Airflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Planning Jargon\n",
    "* ADU - Accessory Dwelling Unit\n",
    "* Existing Development Right - refers to residential, commercial, or tourist development currently built in the Lake Tahoe Basin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Packages, Maps, and Reference Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from utils import *\n",
    "import getpass\n",
    "from arcgis.features import GeoAccessor, GeoSeriesAccessor\n",
    "from arcgis.mapping import show_styles, display_colormaps\n",
    "from arcgis.gis import GIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Pandas Options***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data frame display options\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.options.display.float_format = '{:,.2f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Map Setup***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the GIS object\n",
    "## portal URL = \"https://maps.trpa.org/portal/home/\"\n",
    "## AGOL URL   = \"https://www.arcgis.com\"\n",
    "gis = GIS(\n",
    "    url=\"https://maps.trpa.org/portal/home/\",\n",
    "    ## enter username above ##\n",
    "    username= input(\"Enter username:\"),\n",
    "    ## enter password above ##\n",
    "    password=getpass.getpass(\"Enter password:\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a map object\n",
    "map = gis.map(\"Lake Tahoe\", zoomlevel=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Get Reference Data***\n",
    "* https://www.laketahoeinfo.org/WebServices/List\n",
    "* https://maps.trpa.org/server/rest/services/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LT Info Data\n",
    "# Verified Development Rights\n",
    "dfDevRight  = pd.read_json(\"https://www.laketahoeinfo.org/WebServices/GetParcelDevelopmentRightsForAccela/JSON/e17aeb86-85e3-4260-83fd-a2b32501c476\")\n",
    "# Deed Restrictions as a DataFrame\n",
    "dfDeed      = pd.read_json(\"https://laketahoeinfo.org/WebServices/GetDeedRestrictedParcels/JSON/e17aeb86-85e3-4260-83fd-a2b32501c476\")\n",
    "# IPES LTinfo as a DataFrame\n",
    "dfIPES      = pd.read_json(\"https://www.laketahoeinfo.org/WebServices/GetParcelIPESScores/JSON/e17aeb86-85e3-4260-83fd-a2b32501c476\")\n",
    "# Development Rights Transacted and Banked as a DataFrame\n",
    "dfDevRights = pd.read_json(\"https://www.laketahoeinfo.org/WebServices/GetTransactedAndBankedDevelopmentRights/JSON/e17aeb86-85e3-4260-83fd-a2b32501c476\")\n",
    "# All Parcels as a DataFrame\n",
    "dfLTParcel  = pd.read_json(\"https://www.laketahoeinfo.org/WebServices/GetAllParcels/JSON/e17aeb86-85e3-4260-83fd-a2b32501c476\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRPA Data \n",
    "# Parcel Master as a Spatially Enabled Dataframe from a Feature Service\n",
    "sdfParcel     = get_fs_data_spatial(\"https://maps.trpa.org/server/rest/services/Parcels/FeatureServer/0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRPA Data \n",
    "# Parcel Master as a Spatially Enabled Dataframe from a Feature Service\n",
    "sdfParcel     = get_fs_data_spatial(\"https://maps.trpa.org/server/rest/services/Parcels/FeatureServer/0\")\n",
    "# TRPA Boundary as a Spatially Enabled Dataframe from a Feature Service\n",
    "sdfBoundary   = get_fs_data_spatial(\"https://maps.trpa.org/server/rest/services/Boundaries/FeatureServer/4\")\n",
    "# Plan Area Boundary as a Spatially Enabled Dataframe from a Feature Service\n",
    "sdfPlanArea   = get_fs_data_spatial(\"https://maps.trpa.org/server/rest/services/Boundaries/FeatureServer/0\")\n",
    "# District Boundary as a Spatially Enabled Dataframe from a Feature Service\n",
    "sdfDistrict   = get_fs_data_spatial(\"https://maps.trpa.org/server/rest/services/Zoning/FeatureServer/0\")\n",
    "# Town Center Boundary as a Spatially Enabled Dataframe from a Feature Service\n",
    "sdfTownCenter = get_fs_data_spatial(\"https://maps.trpa.org/server/rest/services/Boundaries/FeatureServer/1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Testing***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdfParcel.spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdfParcel.spatial.full_extent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdfParcel.spatial.project(4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdfParcel.spatial.sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdfParcel.spatial.full_extent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdfParcel.spatial.plot(map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdfParcel.spatial.join(sdfBoundary, how='left', op='intersects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdfParcel.spatial.overlay(sdfBoundary, how='intersection')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permit Data Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TRPA Permit Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Get Data***\n",
    "> TRPA permit data is exported from accela nightly then stored in colleciton.sde enterprise geodatabase and published to the trpa server as the web service below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# web service url\n",
    "permitTable = \"https://maps.trpa.org/server/rest/services/Permit_Records/MapServer/1\"\n",
    "# get permit data as a dataframe\n",
    "dfTRPAPermit = get_fs_data(permitTable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRPA Permit Data Engineering\n",
    "dfTRPAPermit.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Transformation***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfTRPAPermit\n",
    "\n",
    "# final fields for all permit dataframes\n",
    "fields = ['APN', 'Address', 'Jurisdiction', 'Permit_ID', \n",
    "          'Permit_Type','Permit_Category', 'Permit_Status',  'Description',\n",
    "          'Applied_Date', 'Issued_Date', 'PreGrade_Date', 'Finaled_Date'\n",
    "          ]\n",
    "\n",
    "# # set fields\n",
    "column_mapping = {\n",
    "'Accela_ID' : 'Permit_ID',\n",
    "'Detailed_Description' : 'Description',\n",
    "'Record_Status' : 'Permit_Status',\n",
    "'Accela_CAPType_Name' : 'Permit_Type',\n",
    "'File_Date' : 'Applied_Date'\n",
    "}\n",
    "\n",
    "# rename columns based on dictionary\n",
    "df = renamecolumns(df, column_mapping, False)\n",
    "\n",
    "# add missing fields\n",
    "for field in fields:\n",
    "    # if field not in dataframe add it\n",
    "    if field not in df.columns:\n",
    "        # insert new column\n",
    "        df[field] = None\n",
    "# limit to the final fields\n",
    "df = df[fields]\n",
    "# add jurisdiction value\n",
    "df.Jurisdiction = \"TRPA\"\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Processing***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out unique Record_Status values one at a time\n",
    "for description in dfTRPAPermit.Detailed_Description.unique():\n",
    "    print(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out unique Record_Status values one at a time\n",
    "for permittype in dfTRPAPermit.Accela_CAPType_Name.unique():\n",
    "    print(permittype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out unique Record_Status values one at a time\n",
    "for status in dfTRPAPermit.Record_Status.unique():\n",
    "    print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_lookup = \"resources\\Value_Lookups.csv\"\n",
    "trpa_reportingcategory_lookup = import_lookup_dictionary(value_lookup,'key','value','Jurisdiction','TRPA','FieldName','Reporting_Category')\n",
    "trpa_permittype_lookup        = import_lookup_dictionary(value_lookup,'key','value','Jurisdiction','TRPA','FieldName','Permit_Type')\n",
    "trpa_permitstatus_lookup      = import_lookup_dictionary(value_lookup,'key','value','Jurisdiction','TRPA','FieldName','Permit_Status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update fields from lookup dictionaries\n",
    "df['Reporting_Category'] = df['Reporting_Category'].map(trpa_reportingcategory_lookup)\n",
    "df['Permit_Type'] = df['Permit_Type'].map(trpa_permittype_lookup)\n",
    "df['Permit_Status'] = df['Permit_Status'].map(trpa_permitstatus_lookup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### City of South Lake Tahoe Permit Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Get Data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## City of South Lake Tahoe Permit data was sent over by Ryan Malhoski on 4/9/2021\n",
    "dfCSLTPermit = read_file(\"data\\PermitData_CSLT_040924.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCSLTPermit.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Transformation***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop existing 'Address' field\n",
    "df = dfCSLTPermit.drop('Address', axis=1)\n",
    "\n",
    "# final fields for all permit dataframes\n",
    "fields = ['APN', 'Address', 'Jurisdiction', \n",
    "          'Permit_ID', 'Permit_Type','Permit_Status', 'Description',\n",
    "          'Applied_Date', 'Issued_Date', 'Finaled_Date'\n",
    "          ]\n",
    "\n",
    "# # set fields\n",
    "column_mapping = {\n",
    "            'Parcel ID': 'APN',\n",
    "            'Location Address':'Address',\n",
    "            'Permit Number' : 'Permit_ID',\n",
    "            'Note Text' : 'Description',\n",
    "            'Status' : 'Permit_Status',\n",
    "            'Permit Type' : 'Permit_Type',\n",
    "            'Permit Issue Date' : 'Applied_Date',\n",
    "            'Certificate Issue Date': \"Finaled_Date\"\n",
    "            }\n",
    "\n",
    "# rename columns based on dictionary\n",
    "df = renamecolumns(df, column_mapping,False)\n",
    "\n",
    "# add missing fields\n",
    "for field in fields:\n",
    "    # if field not in dataframe add it\n",
    "    if field not in df.columns:\n",
    "        # insert new column\n",
    "        df[field] = None\n",
    "# limit to the final fields\n",
    "df = df[fields]\n",
    "# add jurisdiction value\n",
    "df.Jurisdiction = \"CSLT\"\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# APN is a PPNO format in the CSLT data, and also contains EL old naming convetion (-0)\n",
    "# need to format to xxx-xxx-xxx and filter any odd values (e.g. 500 series)\n",
    "# get rid of 100's and 500's series, and format to xxx-xxx-xxx, also remove any that start with strings\n",
    "# strip off trailing spaces\n",
    "df.APN = df.APN.str.replace(' ', '') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Processing***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# potential values for Permit Type\n",
    "# \n",
    "# get unique permit types\n",
    "for permittype in dfCSLTPermit[\"Permit Type\"].unique():\n",
    "    print(permittype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### El Dorado County Permit Data\n",
    ">  there are two files, one for all TRPA files and one for all files in our geographic area, including TRPA files and EDC files. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Get Data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## El Dorado Permit data representing all files in our geographic area\n",
    "## exported by Ken Kasman on 4/1/2021 from their Trakit database\n",
    "dfElDoPermit = read_file(\"data\\PermitData_ElDorado_040124.csv\")\n",
    "dfElDoPermit.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Transformation***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop existing 'Address' field\n",
    "df = dfElDoPermit\n",
    "\n",
    "# final fields for all permit dataframes\n",
    "fields = ['APN', 'Address', 'Jurisdiction', \n",
    "          'Permit_ID', 'Permit_Type','Permit_Status','Description',\n",
    "          'Applied_Date', 'Issued_Date', 'Finaled_Date'\n",
    "          ]\n",
    "\n",
    "# # set fields\n",
    "column_mapping = {\n",
    "            'SITE_APN' : 'APN',\n",
    "            'SITE_ADDR':'Address',\n",
    "            'Permit Number' : 'Permit_ID',\n",
    "            'DESCRIPTION' : 'Description',\n",
    "            'STATUS' : 'Permit_Status',\n",
    "            'PERMITTYPE' : 'Permit_Type',\n",
    "            'APPLIED' : 'Applied_Date',\n",
    "            'ISSUED'  : 'Issued_Date',\n",
    "            'FINALED' : \"Finaled_Date\"\n",
    "            }\n",
    "\n",
    "# rename columns based on dictionary\n",
    "df = renamecolumns(df, column_mapping, False)\n",
    "\n",
    "# add missing fields\n",
    "for field in fields:\n",
    "    # if field not in dataframe add it\n",
    "    if field not in df.columns:\n",
    "        # insert new column\n",
    "        df[field] = None\n",
    "# limit to the final fields\n",
    "df = df[fields]\n",
    "# add jurisdiction value\n",
    "df.Jurisdiction = \"EL\"\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for permittype in dfElDoPermit[\"PERMITTYPE\"].unique():\n",
    "    print(permittype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get lookup dictionary\n",
    "lookupTable = read_file(\"resources/lookup_reporting_category.csv\")\n",
    "lookupTable[\"Reporting Category\"].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Processing***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Placer County Permit Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Get Data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Placer Permit Data Comes in monthly via email, and gets saved to the folder below.\n",
    "## The code below will merge all the files in the folder into a single file, return a dataframe, and export to csv\n",
    "\n",
    "# folder with the CSV files\n",
    "folder_path = r\"F:\\Research and Analysis\\Local Jurisdiction MOU data collection\\Placer MOU Files\\Placer\"\n",
    "# List to hold the DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Loop through the files in the folder and identify CSV files\n",
    "for file_name in os.listdir(folder_path):\n",
    "    # Construct the full file path\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    # Read the CSV file into a DataFrame and append to the list\n",
    "    df = pd.read_excel(file_path)\n",
    "    # Append the DataFrame to the list\n",
    "    dfs.append(df)\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "final_df = pd.concat(dfs, ignore_index=True)\n",
    "# Add today's date at the end of the file name _MMDDYY\n",
    "today = pd.Timestamp.today().strftime(\"%m%d%y\")\n",
    "# Export the final DataFrame to a CSV file\n",
    "final_df.to_csv(\"data\\PermitData_Placer_\" + today + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Placer Permit data explained above. \n",
    "dfPlacerPermit =read_file(\"data\\PermitData_Placer_040924.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPlacerPermit.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPlacerPermit.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Transformation***\n",
    "> hyperlink to Placer Accela record can be bulit using SERV_PROD_CODE, B1_PER_ID1, B1_PER_ID2, B1_PER_ID3\n",
    "* https://permits.placer.ca.gov/CitizenAccess/Cap/CapDetail.aspx?Module=TRPA&TabName=TRPA&capID1=16CAP&capID2=00000&capID3=0036O&agencyCode=PLACERCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create lookup dictionary\n",
    "lookupTable = read_file(\"resources/PL_lookup_reporting_category.csv\")\n",
    "lookupTable[\"Reporting Category\"].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Processing***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merege the processed dfs\n",
    "df = pd.concat([dfTRPA, dfCSLT, dfEL, dfPL], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data\\PermitData.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cumulative Accounting Data Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Existing Development Rights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Get Data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get parcels APNs to compare\n",
    "dfCAParcel = pd.read_excel(\"data\\CumulativeAccountingParcels06052024.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 368827 entries, 0 to 368826\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   APN     368827 non-null  object\n",
      " 1   YEAR    368827 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 5.6+ MB\n"
     ]
    }
   ],
   "source": [
    "dfCAParcel.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2023, 2022, 2021, 2012, 2020, 2019, 2018], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfCAParcel.YEAR.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_merge\n",
       "both          41069\n",
       "left_only       220\n",
       "right_only        0\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter rows for 2018 in dfCAParcel\n",
    "dfCAParcel2018 = dfCAParcel[dfCAParcel.YEAR == 2018]\n",
    "# merge with parcelUnits18\n",
    "dfCAParcel2018 = dfCAParcel2018.merge(parcelUnits18, left_on='APN', right_on='APN', how='left', indicator=True)\n",
    "dfCAParcel2018._merge.value_counts()\n",
    "# merge with parcelUnits18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 60826 entries, 0 to 60825\n",
      "Data columns (total 38 columns):\n",
      " #   Column                      Non-Null Count  Dtype         \n",
      "---  ------                      --------------  -----         \n",
      " 0   OBJECTID                    60826 non-null  Int64         \n",
      " 1   APN                         60826 non-null  string        \n",
      " 2   PPNO                        60501 non-null  Float64       \n",
      " 3   APO_ADDRESS                 60501 non-null  string        \n",
      " 4   Residential_Units           60501 non-null  Int32         \n",
      " 5   TouristAccommodation_Units  60501 non-null  Int32         \n",
      " 6   CommercialFloorArea_SqFt    60501 non-null  Float64       \n",
      " 7   YEAR                        60826 non-null  Int32         \n",
      " 8   JURISDICTION                0 non-null      string        \n",
      " 9   COUNTY                      0 non-null      string        \n",
      " 10  OWNERSHIP_TYPE              0 non-null      string        \n",
      " 11  COUNTY_LANDUSE_DESCRIPTION  0 non-null      string        \n",
      " 12  EXISTING_LANDUSE            0 non-null      string        \n",
      " 13  REGIONAL_LANDUSE            0 non-null      string        \n",
      " 14  AS_SUM                      0 non-null      Int32         \n",
      " 15  TAX_SUM                     0 non-null      Int32         \n",
      " 16  YEAR_BUILT                  0 non-null      string        \n",
      " 17  PLAN_ID                     0 non-null      string        \n",
      " 18  PLAN_NAME                   0 non-null      string        \n",
      " 19  ZONING_ID                   0 non-null      string        \n",
      " 20  ZONING_DESCRIPTION          0 non-null      string        \n",
      " 21  TOWN_CENTER                 0 non-null      string        \n",
      " 22  LOCATION_TO_TOWNCENTER      0 non-null      string        \n",
      " 23  TAZ                         0 non-null      Float64       \n",
      " 24  WITHIN_TRPA_BNDY            0 non-null      Int32         \n",
      " 25  PARCEL_ACRES                0 non-null      Float64       \n",
      " 26  PARCEL_SQFT                 0 non-null      Float64       \n",
      " 27  WITHIN_BONUSUNIT_BNDY       0 non-null      Int32         \n",
      " 28  GlobalID                    60826 non-null  string        \n",
      " 29  created_user                0 non-null      string        \n",
      " 30  created_date                0 non-null      datetime64[us]\n",
      " 31  last_edited_user            9 non-null      string        \n",
      " 32  last_edited_date            9 non-null      datetime64[us]\n",
      " 33  Assessor_Units              0 non-null      Int32         \n",
      " 34  Shape.STArea()              60826 non-null  Float64       \n",
      " 35  Shape.STLength()            60826 non-null  Float64       \n",
      " 36  SHAPE                       60826 non-null  geometry      \n",
      " 37  Year                        60826 non-null  object        \n",
      "dtypes: Float64(7), Int32(8), Int64(1), datetime64[us](2), geometry(1), object(1), string(18)\n",
      "memory usage: 16.7+ MB\n"
     ]
    }
   ],
   "source": [
    "parcelUnits12.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APN</th>\n",
       "      <th>YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>007-011-01</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>007-011-05</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>007-011-06</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>007-011-09</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>007-011-10</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368813</th>\n",
       "      <td>881-091-30</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368814</th>\n",
       "      <td>881-091-31</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368815</th>\n",
       "      <td>881-092-19</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368818</th>\n",
       "      <td>881-093-19</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368821</th>\n",
       "      <td>991-275-82</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60829 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               APN  YEAR\n",
       "3       007-011-01  2012\n",
       "7       007-011-05  2012\n",
       "11      007-011-06  2012\n",
       "15      007-011-09  2012\n",
       "19      007-011-10  2012\n",
       "...            ...   ...\n",
       "368813  881-091-30  2012\n",
       "368814  881-091-31  2012\n",
       "368815  881-092-19  2012\n",
       "368818  881-093-19  2012\n",
       "368821  991-275-82  2012\n",
       "\n",
       "[60829 rows x 2 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfCAParcel2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021\n"
     ]
    }
   ],
   "source": [
    "print(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter dfCAParcel for 2012 using .loc\n",
    "dfCAParcel2012 = dfCAParcel.loc[dfCAParcel.YEAR == 2012]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APN</th>\n",
       "      <th>YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>007-011-01</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>007-011-05</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>007-011-06</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>007-011-09</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>007-011-10</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368813</th>\n",
       "      <td>881-091-30</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368814</th>\n",
       "      <td>881-091-31</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368815</th>\n",
       "      <td>881-092-19</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368818</th>\n",
       "      <td>881-093-19</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368821</th>\n",
       "      <td>991-275-82</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60829 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               APN  YEAR\n",
       "3       007-011-01  2012\n",
       "7       007-011-05  2012\n",
       "11      007-011-06  2012\n",
       "15      007-011-09  2012\n",
       "19      007-011-10  2012\n",
       "...            ...   ...\n",
       "368813  881-091-30  2012\n",
       "368814  881-091-31  2012\n",
       "368815  881-092-19  2012\n",
       "368818  881-093-19  2012\n",
       "368821  991-275-82  2012\n",
       "\n",
       "[60829 rows x 2 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfCAParcel2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012\n",
      "_merge\n",
      "both          60826\n",
      "left_only         3\n",
      "right_only        0\n",
      "Name: count, dtype: int64\n",
      "2018\n",
      "_merge\n",
      "both          41285\n",
      "left_only         4\n",
      "right_only        0\n",
      "Name: count, dtype: int64\n",
      "2019\n",
      "_merge\n",
      "both          41461\n",
      "left_only         3\n",
      "right_only        0\n",
      "Name: count, dtype: int64\n",
      "2020\n",
      "_merge\n",
      "both          41608\n",
      "left_only         3\n",
      "right_only        0\n",
      "Name: count, dtype: int64\n",
      "2021\n",
      "_merge\n",
      "both          63568\n",
      "left_only         4\n",
      "right_only        0\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# get parcels APNs to compare\n",
    "dfCAParcel = pd.read_excel(\"data\\CumulativeAccountingParcels06052024.xlsx\")\n",
    "\n",
    "# list of dataframes to merge and years\n",
    "dfs   = [parcelUnits12, parcelUnits18, parcelUnits19,parcelUnits20, parcelUnits21]\n",
    "years = ['2012', '2018', '2019', '2020', '2021']\n",
    "\n",
    "for df, year in zip(dfs, years):\n",
    "    dfCAParcel_year = dfCAParcel.loc[dfCAParcel.YEAR == int(year)]\n",
    "    df = dfCAParcel_year.merge(df, left_on='APN', right_on='APN', how='left', indicator=True)\n",
    "    # print year and merge value counts\n",
    "    print(year)\n",
    "    print(df._merge.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a csv from left only merge for each year\n",
    "for df, year in zip(dfs, years):\n",
    "    dfCAParcel_year = dfCAParcel.loc[dfCAParcel.YEAR == int(year)]\n",
    "    df = dfCAParcel_year.merge(df, left_on='APN', right_on='APN', how='left', indicator=True)\n",
    "    # filter left only merge\n",
    "    df = df.loc[df._merge == 'left_only']\n",
    "    # keep only APN, Year_x, and _merge columns\n",
    "    df = df[['APN', 'YEAR_x', '_merge']]\n",
    "    # rename YEAR_x to YEAR\n",
    "    df.rename(columns={'YEAR_x':'YEAR'}, inplace=True)\n",
    "    # export to csv\n",
    "    df.to_csv(\"data\\Parcel_MissingAPNs_fromShapes_revised\" + year + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get 2022 development units\n",
    "devhistoryURL = \"https://maps.trpa.org/server/rest/services/Existing_Development/MapServer/2\"\n",
    "parcelUnits12 = get_fs_data_spatial_query(devhistoryURL, \"Year = 2012\")\n",
    "parcelUnits18 = get_fs_data_spatial_query(devhistoryURL, \"Year = 2018\")\n",
    "parcelUnits19 = get_fs_data_spatial_query(devhistoryURL, \"Year = 2019\")\n",
    "parcelUnits20 = get_fs_data_spatial_query(devhistoryURL, \"Year = 2020\")\n",
    "parcelUnits21 = get_fs_data_spatial_query(devhistoryURL, \"Year = 2021\")\n",
    "parcelUnits22 = get_fs_data_spatial_query(devhistoryURL, \"Year = 2022\")\n",
    "parcelUnits23 = get_fs_data_spatial_query(devhistoryURL, \"Year = 2023\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<StringArray>\n",
       "[ '122-051-01',  '122-051-02',  '122-051-03',  '122-051-04',  '122-051-05',  '122-051-06',  '122-051-07',  '122-051-08',  '122-051-09',  '122-051-10',\n",
       " ...\n",
       " '117-130-065', '117-130-062', '117-180-047', '117-180-046', '117-130-061', '111-160-027', '093-620-075', '111-160-024', '111-160-025', '085-400-030']\n",
       "Length: 41069, dtype: string"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parcelUnits18.APN.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APN_Length\n",
       "11    30080\n",
       "10     7114\n",
       "15     3875\n",
       "Name: count, dtype: Int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# identify how many characeters are in the APN field in COUNTY == 'EL'\n",
    "df = parcelUnits18\n",
    "df['APN_Length'] = df['APN'].str.len()\n",
    "df.APN_Length.value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 0 entries\n",
      "Data columns (total 37 columns):\n",
      " #   Column                      Non-Null Count  Dtype         \n",
      "---  ------                      --------------  -----         \n",
      " 0   OBJECTID                    0 non-null      Int64         \n",
      " 1   APN                         0 non-null      string        \n",
      " 2   PPNO                        0 non-null      Float64       \n",
      " 3   APO_ADDRESS                 0 non-null      string        \n",
      " 4   Residential_Units           0 non-null      Int32         \n",
      " 5   TouristAccommodation_Units  0 non-null      Int32         \n",
      " 6   CommercialFloorArea_SqFt    0 non-null      Float64       \n",
      " 7   YEAR                        0 non-null      Int32         \n",
      " 8   JURISDICTION                0 non-null      string        \n",
      " 9   COUNTY                      0 non-null      string        \n",
      " 10  OWNERSHIP_TYPE              0 non-null      string        \n",
      " 11  COUNTY_LANDUSE_DESCRIPTION  0 non-null      string        \n",
      " 12  EXISTING_LANDUSE            0 non-null      string        \n",
      " 13  REGIONAL_LANDUSE            0 non-null      string        \n",
      " 14  AS_SUM                      0 non-null      Int32         \n",
      " 15  TAX_SUM                     0 non-null      Int32         \n",
      " 16  YEAR_BUILT                  0 non-null      string        \n",
      " 17  PLAN_ID                     0 non-null      string        \n",
      " 18  PLAN_NAME                   0 non-null      string        \n",
      " 19  ZONING_ID                   0 non-null      string        \n",
      " 20  ZONING_DESCRIPTION          0 non-null      string        \n",
      " 21  TOWN_CENTER                 0 non-null      string        \n",
      " 22  LOCATION_TO_TOWNCENTER      0 non-null      string        \n",
      " 23  TAZ                         0 non-null      Float64       \n",
      " 24  WITHIN_TRPA_BNDY            0 non-null      Int32         \n",
      " 25  PARCEL_ACRES                0 non-null      Float64       \n",
      " 26  PARCEL_SQFT                 0 non-null      Float64       \n",
      " 27  WITHIN_BONUSUNIT_BNDY       0 non-null      Int32         \n",
      " 28  GlobalID                    0 non-null      string        \n",
      " 29  created_user                0 non-null      string        \n",
      " 30  created_date                0 non-null      datetime64[us]\n",
      " 31  last_edited_user            0 non-null      string        \n",
      " 32  last_edited_date            0 non-null      datetime64[us]\n",
      " 33  Assessor_Units              0 non-null      Int32         \n",
      " 34  Shape.STArea()              0 non-null      Float64       \n",
      " 35  Shape.STLength()            0 non-null      Float64       \n",
      " 36  SHAPE                       0 non-null      geometry      \n",
      "dtypes: Float64(7), Int32(8), Int64(1), datetime64[us](2), geometry(1), string(18)\n",
      "memory usage: 0.0 bytes\n"
     ]
    }
   ],
   "source": [
    "# select all APN rows with 12 characters\n",
    "parcelUnits18 = parcelUnits18[parcelUnits18.APN.str.len() == 11]\n",
    "parcelUnits18.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parcel history\n",
    "url = 'https://maps.trpa.org/server/rest/services/AllParcels/MapServer/3'\n",
    "dfParcelHistory = get_fs_data(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select all rows where b2023 active = 1 and all other fields = 0\n",
    "dfParcel2023 = dfParcelHistory[(dfParcelHistory['b2023Active'] == 1) & \n",
    "                               (dfParcelHistory['b2022Active'] == 0) & \n",
    "                               (dfParcelHistory['b2021Active'] == 0) & \n",
    "                               (dfParcelHistory['b2020Active'] == 0) & \n",
    "                               (dfParcelHistory['b2019Active'] == 0) & \n",
    "                               (dfParcelHistory['b2018Active'] == 0) & \n",
    "                               (dfParcelHistory['b2012Active'] == 0)]\n",
    "dfParcel2023.info()\n",
    "list2023 = dfParcel2023['APN'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to data\\parcelUnits_currentdate.csv with date stamp\n",
    "today = pd.Timestamp.today().strftime(\"%m%d%y\")\n",
    "parcelUnits12.to_csv(\"data\\parcelUnits12_\" + today + \".csv\", index=False)\n",
    "# parcelUnits18.to_csv(\"data\\parcelUnits18_\" + today + \".csv\", index=False)\n",
    "# parcelUnits19.to_csv(\"data\\parcelUnits19_\" + today + \".csv\", index=False)\n",
    "# parcelUnits20.to_csv(\"data\\parcelUnits20_\" + today + \".csv\", index=False)\n",
    "# parcelUnits21.to_csv(\"data\\parcelUnits21_\" + today + \".csv\", index=False)\n",
    "parcelUnits22.to_csv(\"data\\parcelUnits22_\" + today + \".csv\", index=False)\n",
    "parcelUnits23.to_csv(\"data\\parcelUnits23_\" + today + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commercial data changes\n",
    "dfCFA_Change            = pd.read_excel(\"data/CFA Changes.xlsx\", sheet_name=0, skiprows=1)\n",
    "dfCFA_ChangesLTinfo     = pd.read_excel(\"data/Working CFA Changes from LT Info Verifications.xlsx\")\n",
    "# drop any column with \"Unamed\" in the name\n",
    "dfCFA_ChangesLTinfo     = dfCFA_ChangesLTinfo.loc[:, ~dfCFA_ChangesLTinfo.columns.str.contains('^Unnamed')]\n",
    "\n",
    "# Residential data changes\n",
    "parcelUnits12_Updated   = read_file(\"data/Updated_2012Analysis.csv\")\n",
    "dfRES_Change            = pd.read_excel(\"data/Residential Cleanup.xlsx\")\n",
    "\n",
    "# Tourist data changes\n",
    "dfTAU_Change            = read_excel(\"data\\Commercial and TAU Cumulative Accounting.xlsx\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace CFA with the updated values\n",
    "parcelUnits12.CFA_SQFT = parcelUnits12_Updated.CFA_SQFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcelUnits12.CommercialFloorArea_SqFt.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Transformation***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Commercial/TAU changes – this file includes the changes tracked for commercial and TAU changes from ~2013 to current. There are projects listed that are completed, and others that have been permitted but not completed. Need to reconcile city-permitted permits from CSLT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Proecssing***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare where b20022 is 1 and b2023 is 0\n",
    "dfParcelOld = dfParcelHistory[(dfParcelHistory['b2022Active'] == 1) & \n",
    "                               (dfParcelHistory['b2023Active'] == 0)]\n",
    "\n",
    "# compare where b20022 is 0 and b2023 is 1\n",
    "dfParcelNew = dfParcelHistory[(dfParcelHistory['b2022Active'] == 0) & \n",
    "                               (dfParcelHistory['b2023Active'] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# merge parcel22 and parcel23 on APN\n",
    "dfParcelMerge = pd.merge(parcelUnits22, parcelUnits23, on='APN', how='outer', indicator=True)\n",
    "# left only and right only\n",
    "dfParcelMissing = dfParcelMerge[dfParcelMerge['_merge'] != 'both']\n",
    "\n",
    "# dfParcelMissing.info()\n",
    "\n",
    "# left only\n",
    "dfParcelMissingLeft = dfParcelMerge[dfParcelMerge['_merge'] == 'left_only']\n",
    "# dfParcelMissingLeft.info()\n",
    "\n",
    "# sum of Residential_Units_x\n",
    "dfParcelMissingLeft.Residential_Units_x.sum() \n",
    "\n",
    "# right only\n",
    "dfParcelMissingRight = dfParcelMerge[dfParcelMerge['_merge'] == 'right_only']   \n",
    "# dfParcelMissingRight.Residential_Units_y.sum() \n",
    "\n",
    "# display only APN columns in dfParcelMissingRight\n",
    "df = dfParcelMissingRight[['APN']]\n",
    "df.to_csv(\"data\\parcel2023_newAPN.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spatial join of dfParcelMissingLeft and dfParcelMissingRigh\n",
    "sdf = parcelUnits22.spatial.join(parcelUnits23, how='inner', op='intersects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arcpy spatial join\n",
    "import arcpy\n",
    "\n",
    "# arcpy spatial join of parcelUnits22 and parcelUnits23\n",
    "df = arcpy.spatial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter to rows where APN_left and APN_right !=\n",
    "sdf2 = sdf[sdf.APN_left != sdf.APN_right]\n",
    "sdf2.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spatial overlay of parcelUnits22 and parcelUnits23\n",
    "sdf = parcelUnits22.spatial.overlay(parcelUnits23, how='union')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deed Restrictions\n",
    "> Deed restricted unit research needs to be merged with LTinfo housing deed restricitons and parcel unit data from 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Get Data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDeedUnits  = read_excel(\"data\\Housing_Deed_Restrcitions.xlsx\", 0)\n",
    "dfDeedLTinfo = pd.read_json(\"https://laketahoeinfo.org/WebServices/GetDeedRestrictedParcels/JSON/e17aeb86-85e3-4260-83fd-a2b32501c476\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDeedUnits.to_csv(\"data\\DeedRestricted_HousingUnits.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDeedUnits.Units.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDeedLTinfo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unique values for deed restrcition type\n",
    "dfDeedLTinfo.DeedRestrictionType.unique()\n",
    "\n",
    "# filter to Affordable, Achievable, and Moderate\n",
    "dfDeedLTinfo = dfDeedLTinfo[dfDeedLTinfo.DeedRestrictionType.isin(['Affordable Housing', 'Moderate Income Housing', 'Achievable Housing'])]  \n",
    "\n",
    "# count of total records\n",
    "dfDeedLTinfo.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcelUnits22.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDeedUnitsMerge = dfDeedUnits.merge(dfDeedLTinfo, on='APN', how='outer', indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDeedUnitsMerge._merge.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDeedLTinfo[dfDeedLTinfo.duplicated(subset=['APN','DeedRestrictionType'], keep=False)].sort_values('APN').to_csv(\"HousingDeedRestrictions_LTinfo_Duplicates.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify duplicates unique by APN and \n",
    "dfDeedUnits[dfDeedUnits.duplicated(subset=['APN', 'Deed_Restriction_Type','Units'], keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify duplicates\n",
    "dfDeedUnitsMerge[dfDeedUnitsMerge.duplicated(subset=['APN'], keep=False)].sort_values(by='APN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDeedUnitsMerge.to_csv(\"HousingDeedRestrictions_All.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the deed restricted units with the parcel units\n",
    "dfDeedUnits_ParcelUnits  = dfDeedUnits.merge(parcelUnits22, on='APN', how='left')\n",
    "# merge the deed restricted units with the parcel units\n",
    "dfDeedLTinfo_ParcelUnits = dfDeedLTinfo.merge(parcelUnits22, left_on='APN', right_on='APN', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDeedLTinfo_ParcelUnits.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDeedLTinfo_ParcelUnits.Residential_Units.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ADU Tracking\n",
    "> ADU permit tracking from TRPA and othe Jurisdictions. There is a need to establish a system of record for this information (LT Info). This is similar to the Residential Bonus Unit data and there’s crossover on some of these, where a bonus unit was used to create an ADU, but you can have an ADU without requiring a bonus unit, and you can use a bonus unit without it being an ADU… "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Get Data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfADU = read_excel(\"data\\ADU Tracking.xlsx\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfADU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Allocations\n",
    "> This file includes all of the allocations that have been tracked in LT Info, and adds in whether the subject parcel has been issued a BMP/SCC certificate and/or whether Air Quality/Mobility Mitigation fees (for added VMT) or Water Quality Mitigation fees (for added coverage) have been paid. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allocations = read_excel(\"data\\Allocation_Tracking.xlsx\", 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transactions with Inactive APNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inactiveParcels = read_file(\"data\\Transactions_InactiveParcels.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QA Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Process to "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
