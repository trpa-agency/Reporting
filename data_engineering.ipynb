{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Engineering Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CountyParcel_Transform.py\n",
    "Created: June 15th,2023\n",
    "Last Updated: October 20th, 2023\n",
    "Amy Fish, Tahoe Regional Planning Agency\n",
    "Andy McClary, Tahoe Regional Planning Agency\n",
    "Mason Bindl, Tahoe Regional Planning Agency\n",
    "\n",
    "This python script was developed to get data from the five Tahoe Counties.\n",
    "El Dorado, Carson, Douglas, Placer, and Washoe. \n",
    "The data is then staged for transformation. \n",
    "\n",
    "This script uses Python 3.x and was designed to be used with \n",
    "the default ArcGIS Pro python enivorment \"\"C:/Program Files/ArcGIS/Pro/bin/Python/envs/arcgispro-py3/python.exe\"\", with\n",
    "no need for installing new libraries.\n",
    "\n",
    "This script runs on the 16th of each month at 1am on Arc10 from scheduled task \"CountyParcelTransform\"\n",
    "\"\"\"\n",
    "#----------------------------------------------------------------------\n",
    "# SETUP\n",
    "#----------------------------------------------------------------------\n",
    "# import packages\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import logging\n",
    "from datetime import datetime \n",
    "import time\n",
    "import pandas as pd\n",
    "import arcpy\n",
    "from time import strftime\n",
    "import smtplib\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.text import MIMEText\n",
    "\n",
    "# environment settings\n",
    "arcpy.env.workspace = \"//Trpa-fs01/GIS/PARCELUPDATE/Workspace/ParcelStaging.gdb\"\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.outputCoordinateSystem = arcpy.SpatialReference(26910)\n",
    "\n",
    "# set workspace and sde connections \n",
    "workspace = \"F:/GIS/PARCELUPDATE/Workspace/Staging\"\n",
    "\n",
    "# network path to connection files\n",
    "filePath = \"F:/GIS/PARCELUPDATE/Workspace/\"\n",
    "# database file path \n",
    "sdeBase    = os.path.join(filePath, \"Vector.sde/\")\n",
    "sdeCollect = os.path.join(filePath, \"Collection.sde\")\n",
    "sdeTabular = os.path.join(filePath, \"Tabular.sde\")\n",
    "\n",
    "# portal signin\n",
    "## TRPA_ADMIN credentials \n",
    "# portal_user = \"TRPA_PORTAL_ADMIN\"\n",
    "# portal_pwd = str(os.environ.get('Password'))\n",
    "# portal_url = \"https://maps.trpa.org/portal/\"\n",
    "# # sign in\n",
    "# arcpy.SignInToPortal(portal_url, portal_user, portal_pwd)\n",
    "\n",
    "# Parcel AOI to select parcels to keep (includes TRPA Boundary and Olympic Valley Watershed)\n",
    "parcelAOI = \"Parcel_AOI\"\n",
    "\n",
    "#sde feature classes to use in attribution stage\n",
    "sde_Impervious       = sdeBase + \"\\\\sde.SDE.Impervious\\\\sde.SDE.Impervious_2019\"\n",
    "sde_Bailey           = sdeBase + \"\\\\sde.SDE.Soils\\sde.SDE.land_capability_Bailey_Soils\"\n",
    "sde_RegionalLandUse  = os.path.join(sdeBase,\"sde.SDE.Planning/sde.SDE.RegionalLandUse\")\n",
    "sde_NRCSSoils1974    = sdeBase + \"\\\\sde.SDE.Soils\\\\sde.SDE.NRCS_Soils_1974\"\n",
    "sde_NRCSSoils2003    = sdeBase + \"\\\\sde.SDE.Soils\\\\sde.SDE.NRCS_Soils_2003\"\n",
    "sde_Catchment        = sdeBase + \"\\\\sde.SDE.WaterQuality\\\\sde.SDE.TMDL_Catchment\"\n",
    "sde_HydroArea        = sdeBase + \"\\\\sde.SDE.Water\\\\sde.SDE.Hydro_Areas\"\n",
    "sde_Watershed        = sdeBase + \"\\\\sde.SDE.Water\\\\sde.SDE.Watershed\"\n",
    "sde_FireDistrict     = sdeBase + \"\\\\sde.SDE.Jurisdictions\\\\sde.SDE.FireDistricts\"\n",
    "sde_LocalPlan        = sdeBase + \"\\\\sde.SDE.Planning\\\\sde.SDE.LocalPlan\"\n",
    "sde_SpecialDistrict  = sdeBase + \"\\\\sde.SDE.Planning\\\\sde.SDE.SpecialPlanningDistrict\"\n",
    "sde_CSLT             = sdeBase + \"\\\\sde.SDE.Jurisdictions\\\\sde.SDE.CSLT\"\n",
    "sde_CurrentParcels   = sdeBase + \"\\\\sde.SDE.Parcels\\\\sde.SDE.Parcel_Master\"\n",
    "sde_Zoning           = sdeBase + \"\\\\sde.SDE.Planning\\\\sde.SDE.District\"\n",
    "sde_TownCenter       = sdeBase + \"\\\\sde.SDE.Planning\\\\sde.SDE.TownCenter\"\n",
    "sde_TownCenterBuffer = sdeBase + \"\\\\sde.SDE.Planning\\\\sde.SDE.TownCenter_Buffer\"\n",
    "sde_Index1987        = sdeBase + \"\\\\sde.SDE.Index\\\\sde.SDE.AssessorMapIndex_1987\"\n",
    "sde_TRPAboundary     = sdeBase + \"\\\\sde.SDE.Jurisdictions\\\\sde.SDE.TRPA_bdy\"\n",
    "sde_BonusUnitboundary= sdeBase + \"\\\\sde.SDE.Planning\\\\sde.SDE.Bonus_unit_boundary\"\n",
    "sde_UrbanArea        = sdeBase + \"\\\\sde.SDE.Jurisdictions\\\\sde.SDE.UrbanAreas\"\n",
    "sde_Zip              = sdeBase + \"\\\\sde.SDE.Jurisdictions\\\\sde.SDE.Postal_ZIP\"\n",
    "sde_TAZ              = sdeBase + \"\\\\sde.SDE.Transportation\\\\sde.SDE.Transportation_Analysis_Zone\"\n",
    "sde_Littoral         = sdeBase + \"\\\\sde.SDE.Shorezone\\\\sde.SDE.LittoralParcel\"\n",
    "sde_Tolerance        = sdeBase + \"\\\\sde.SDE.Shorezone\\\\sde.SDE.Tolerance_District\"\n",
    "\n",
    "# sde Collect feature classes to use for attribution\n",
    "sde_collect_IPES     = os.path.join(sdeCollect, 'SDE.Parcel\\SDE.Parcel_LTinfo_IPES')\n",
    "sde_collect_LCV      = os.path.join(sdeCollect, 'SDE.Parcel\\SDE.Parcel_LTinfo_LCV')\n",
    "sde_collect_BMP      = os.path.join(sdeCollect, 'SDE.Parcel\\SDE.Parcel_BMP')\n",
    "sde_collect_Deed     = os.path.join(sdeCollect, 'SDE.Parcel\\SDE.Parcel_LTinfo_Deed_Restriction')  \n",
    "sde_collect_VHR      = os.path.join(sdeCollect, 'SDE.Parcel\\SDE.Parcel_VHR')\n",
    "\n",
    "# in memory fcs to use in the attribution stage\n",
    "memory = \"memory\" + \"\\\\\"\n",
    "ParcelPoint_RegionalLandUse = memory + \"ParcelPoint_RegionalLandUse\"\n",
    "ParcelPoint_Soils74         = memory + \"ParcelPoint_Soils74\"\n",
    "ParcelPoint_Soils03         = memory + \"ParcelPoint_Soils03\"\n",
    "ParcelPoint_Catchment       = memory + \"ParcelPoint_Catchment\"\n",
    "ParcelPoint_HydroArea       = memory + \"ParcelPoint_HydroArea\"\n",
    "ParcelPoint_Watershed       = memory + \"ParcelPoint_Watershed\"\n",
    "ParcelPoint_FireDistrict    = memory + \"ParcelPoint_FireDistrict\"\n",
    "ParcelPoint_LocalPlan       = memory + \"ParcelPoint_LocalPlan\"\n",
    "ParcelPoint_TownCenter      = memory + \"ParcelPoint_TownCenter\"\n",
    "ParcelPoint_TownCenterBuffer= memory + \"ParcelPoint_TownCenterBuffer\"\n",
    "ParcelPoint_Zoning          = memory + \"ParcelPoint_Zoning\"\n",
    "ParcelPoint_SpecialDistrict = memory + \"ParcelPoint_SpecialDistrict\"\n",
    "ParcelPoint_Index1987       = memory + \"ParcelPoint_Index1987\"\n",
    "ParcelPoint_PstlTown        = memory + \"ParcelPoint_PstlTown\"\n",
    "ParcelPoint_PstlZip         = memory + \"ParcelPoint_PstlZip\"\n",
    "ParcelPoint_CSLT            = memory + \"ParcelPoint_CSLT\"\n",
    "ParcelPoint_TAZ             = memory + \"ParcelPoint_TAZ\"\n",
    "ParcelPoint_Design          = memory + \"ParcelPoint_Design\"\n",
    "ParcelPoint_Littoral        = memory + \"ParcelPoint_Littoral\"\n",
    "ParcelPoint_Tolerance       = memory + \"ParcelPoint_Tolerance\"\n",
    "\n",
    "# Set up fields to add to FGDB.\n",
    "baseFields = [\n",
    "# apn ppno\n",
    "['APN_TRPA', 'TEXT', 'APN', 50],\n",
    "['PPNO_TRPA', 'DOUBLE','PPNO'],\n",
    "['JURISDICTION_TRPA', 'TEXT', 'Jurisdiction', 4],\n",
    "['COUNTY_TRPA', 'TEXT', 'County', 2],\n",
    " # parcel address   \n",
    "['HSE_NUMBR_TRPA', 'TEXT', 'House Number', 25],\n",
    "['UNIT_NUMBR_TRPA', 'TEXT', 'Unit Number', 50],\n",
    "['STR_DIR_TRPA', 'TEXT','Street Direction', 5],\n",
    "['STR_NAME_TRPA', 'TEXT', 'Street Name', 100],\n",
    "['STR_SUFFIX_TRPA', 'TEXT', 'Street Suffix', 6],\n",
    "['APO_ADDRESS_TRPA', 'TEXT', 'Full Address', 100],\n",
    "['PSTL_TOWN_TRPA', 'TEXT', 'Postal Town', 25],\n",
    "['PSTL_STATE_TRPA', 'TEXT', 'Postal State', 2],\n",
    "['PSTL_ZIP5_TRPA', 'TEXT', 'Postal Zip Code', 5],\n",
    "# owner info\n",
    "['OWN_FIRST_TRPA', 'TEXT', 'Owner First Name', 255],\n",
    "['OWN_LAST_TRPA', 'TEXT', 'Owner Last Name', 255],\n",
    "['OWN_FULL_TRPA', 'TEXT', 'Owner Name', 255],\n",
    "    # swap this in soon\n",
    "# ['OWNER_NAME_TRPA', 'TEXT', 'Owner Name', 255],\n",
    "['MAIL_ADD1_TRPA', 'TEXT', 'Mailing Address', 100],\n",
    "['MAIL_CITY_TRPA', 'TEXT', 'Mailing City', 50],\n",
    "['MAIL_STATE_TRPA', 'TEXT', 'Mailing State', 25],\n",
    "['MAIL_ZIP5_TRPA', 'TEXT', 'Mailing Zip Code', 5],\n",
    "# value fields  \n",
    "['AS_LANDVALUE_TRPA', 'LONG','Assessed Land Value'],\n",
    "['AS_IMPROVALUE_TRPA', 'LONG','Assessed Improved Value'],\n",
    "['AS_SUM_TRPA', 'LONG', 'Assessed Sum Value'],\n",
    "['TAX_LANDVALUE_TRPA', 'LONG','Tax Land Value'],\n",
    "['TAX_IMPROVALUE_TRPA', 'LONG','Tax Improved Value'],\n",
    "['TAX_SUM_TRPA', 'LONG','Tax Sum'],\n",
    "['TAX_YEAR_TRPA', 'TEXT','Tax Year', 5],\n",
    "# jurisdiction land use fields\n",
    "['COUNTY_LANDUSE_CODE_TRPA', 'TEXT', 'County Landuse Code', 50],\n",
    "['COUNTY_LANDUSE_TRPA', 'TEXT', 'County Landuse', 250],\n",
    "# Fields for building info\n",
    "[\"YEAR_BUILT_TRPA\", \"SHORT\", 'Year Built', 5],\n",
    "['UNITS_TRPA', 'DOUBLE', 'Units', 5],\n",
    "[\"BEDROOMS_TRPA\", \"DOUBLE\",'Bedrooms'],\n",
    "['BATHROOMS_TRPA', 'DOUBLE', 'Bathrooms'],\n",
    "['BUILDING_SQFT_TRPA', 'DOUBLE', 'Building Size'],\n",
    "# fields to add? \n",
    "[\"VHR_TRPA\", \"TEXT\", \"Vacation Home Rental\", 3],\n",
    "[\"HOA_TRPA\", \"TEXT\", \"Home Owners Association\", 3]\n",
    "]\n",
    "\n",
    "trpaFields = [\n",
    "# land use\n",
    "['OWNERSHIP_TYPE_TRPA', 'TEXT', 'Ownership Type', 50],\n",
    "['EXISTING_LANDUSE_TRPA', 'TEXT', 'Existing Landuse', 50],\n",
    "['REGIONAL_LANDUSE_TRPA', 'TEXT', 'Regional Landuse', 50], \n",
    "# Fields for soil, watershed, etc...\n",
    "['ESTIMATED_COVERAGE_ALLOWED_TRPA', 'DOUBLE', \"Estimate of Coverage Allowed (Bailey, sq.ft.)\"],\n",
    "['ESTIMATED_PRCNT_COV_ALLOWED_TRPA', 'DOUBLE', \"Estimated Percent Coverage Allowed (Bailey, sq.ft.)\"],\n",
    "['IMPERVIOUS_SURFACE_SQFT_TRPA', 'DOUBLE', \"Impervious Surface (Remote Sensing, sq.ft.)\"],\n",
    "\n",
    "['SOIL_1974_TRPA', 'TEXT','NRCS Soils 1974', 5],\n",
    "[\"SOIL_2003_TRPA\", \"TEXT\", \"NRCS Soils 2003\", 5],\n",
    "[\"CATCHMENT_TRPA\", \"TEXT\", \"Catchment\", 150],\n",
    "[\"HRA_NAME_TRPA\", \"TEXT\", \"Hydrologic Resource Area\", 30],\n",
    "[\"WATERSHED_NUMBER_TRPA\", \"SHORT\", \"Watershed Number\"],\n",
    "[\"WATERSHED_NAME_TRPA\", \"TEXT\", \"Watershed Name\", 30],\n",
    "[\"PRIORITY_WATERSHED_TRPA\", \"TEXT\", \"Priority Watershed\", 2],\n",
    "[\"FIREPD_TRPA\", \"TEXT\", \"Fire Protection District\", 25],\n",
    "# Fields for Planning purposes\n",
    "[\"PLAN_ID_TRPA\", \"TEXT\", 'Plan ID',8],\n",
    "[\"PLAN_NAME_TRPA\", \"TEXT\", 'Plan Name', 40],\n",
    "[\"PLAN_TYPE_TRPA\", \"TEXT\", 'Plan Type', 40],\n",
    "[\"ZONING_ID_TRPA\", \"TEXT\", 'Zoning ID', 50],\n",
    "[\"ZONING_DESCRIPTION_TRPA\", \"TEXT\", 'Zoning Description',500],\n",
    "[\"TOWN_CENTER_TRPA\", \"TEXT\",'Town Center', 50],\n",
    "[\"LOCATION_TO_TOWNCENTER_TRPA\", \"TEXT\", 'Location Relative to Town Center', 50],\n",
    "[\"TOLERANCE_ID_TRPA\", \"TEXT\", 'Tolerance ID', 50],\n",
    "[\"TAZ_TRPA\", \"DOUBLE\",'Transportation Analysis Zone'],\n",
    "[\"INDEX_1987_TRPA\", \"TEXT\", \"1987 Parcel Map Index\",10],\n",
    "[\"IPES_TRPA\", \"LONG\", \"IPES Score\"],\n",
    "[\"WITHIN_TRPA_BNDY_TRPA\", \"SHORT\",\"Within TRPA Boundary?\"],\n",
    "[\"WITHIN_BONUSUNIT_BNDY_TRPA\", \"SHORT\", \"Within Bonus Unit Boundary\"],\n",
    "[\"LOCAL_PLAN_HYPERLINK_TRPA\", \"TEXT\", \"Local Plan Hyperlink\", 255],\n",
    "[\"DESIGN_GUIDELINES_HYPERLINK_TRPA\", \"TEXT\", \"Design Guidelines\", 255],\n",
    "[\"LTINFO_HYPERLINK_TRPA\", \"TEXT\", \"LTinfo Parcel Details\", 255],\n",
    "[\"INDEX_1987_HYPERLINK_TRPA\", \"TEXT\", \"Index 1987 Hyperlink\", 255],\n",
    "[\"STATUS_TRPA\",'TEXT',\"Status\",1],\n",
    "# Fields for Parcel Size\n",
    "[\"PARCEL_ACRES_TRPA\", \"DOUBLE\", \"Acres\"],\n",
    "[\"PARCEL_SQFT_TRPA\", \"DOUBLE\", \"Square Feet\"] \n",
    "]\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# LOGGING\n",
    "#----------------------------------------------------------------------\n",
    "# Configure the logging\n",
    "log_file_path = os.path.join(workspace, \"ParcelTransformation.log\")  # Specify the path to your local directory\n",
    "logging.basicConfig(level=logging.DEBUG,\n",
    "                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "                    filename=log_file_path,  # Set the log file path\n",
    "                    filemode='w')\n",
    "\n",
    "# Create a logger\n",
    "logger = logging.getLogger(__name__)\n",
    "# start a timer for the entire script run\n",
    "FIRSTstartTimer = datetime.datetime.now()\n",
    "# Log different types of messages\n",
    "logger.info(\"Script Started: \" + str(FIRSTstartTimer) + \"\\n\")\n",
    "\n",
    "##--------------------------------------------------------------------------------------------------------#\n",
    "## SETUP SEND EMAIL WITH LOG FILE ##\n",
    "##--------------------------------------------------------------------------------------------------------#\n",
    "# path to text file\n",
    "fileToSend = log_file_path\n",
    "# email parameters\n",
    "subject = \"Parcel Transformation Log File\"\n",
    "sender_email = \"infosys@trpa.org\"\n",
    "# password = ''\n",
    "receiver_email = \"gis@trpa.gov\"\n",
    "#----------------------------------------------------------------------\n",
    "# FUNCTIONS\n",
    "#----------------------------------------------------------------------\n",
    "\n",
    "### Functions ###\n",
    "# time a function function\n",
    "## use as decorator @timer\n",
    "def timer(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        print(f\"Function {func.__name__} took {end_time - start_time} seconds to execute.\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "def get_text_fields(feature_class):\n",
    "    field_list = []\n",
    "    fields = arcpy.ListFields(feature_class)\n",
    "    for field in fields:\n",
    "        if field.type == 'String':\n",
    "            field_list.append(field.name)\n",
    "    return field_list\n",
    "\n",
    "# set none to '' for all cells\n",
    "@timer\n",
    "def replace_null_values_with_blank(fc):\n",
    "    field_list = get_text_fields(fc)\n",
    "    with arcpy.da.UpdateCursor(fc, field_list) as cursor: \n",
    "        for row in cursor: \n",
    "            for i in range(len(row)): \n",
    "                if row[i] is None: \n",
    "                    row[i] = \"\" \n",
    "            cursor.updateRow(row)\n",
    "            \n",
    "@timer           \n",
    "def UpdateFieldFromDictionary(featureclass, field, update_dictionary):\n",
    "    record_count = 0\n",
    "    with arcpy.da.UpdateCursor(featureclass, field) as cursor:\n",
    "        for row in cursor:\n",
    "            key_field_value = row[0]\n",
    "            if key_field_value in update_dictionary:\n",
    "                row[0] = update_dictionary[key_field_value]\n",
    "                cursor.updateRow(row)\n",
    "                record_count+=record_count\n",
    "    logger.info(f\"{record_count} rows were updated\")\n",
    "                    \n",
    "# combine duplicate records, creating multipart and dissolved polygons \n",
    "@timer\n",
    "def CombineAPNs(fc, fld_dissolve):    \n",
    "    from time import strftime  \n",
    "    print(\"Started combining APNs: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    # get unique values from field\n",
    "    value_list = [r[0] for r in arcpy.da.SearchCursor(fc, (fld_dissolve))]\n",
    "    unique_vals = list(set(value_list))\n",
    "    if len(value_list) !=len(unique_vals):\n",
    "        seen = set()\n",
    "        dup_vals = set()\n",
    "        for x in value_list:\n",
    "            if x in seen:\n",
    "                dup_vals.add(x)\n",
    "            else:\n",
    "                seen.add(x)\n",
    "        print(dup_vals)\n",
    "        dup_vals.remove('')\n",
    "        for unique_val in dup_vals:\n",
    "            geoms = [r[0] for r in arcpy.da.SearchCursor(fc, ('SHAPE@', fld_dissolve)) if r[1] == unique_val]\n",
    "            #Probably don't need this as there will always be more than one geometry\n",
    "            if len(geoms) > 1:\n",
    "                print(unique_val)    \n",
    "                diss_geom = DissolveGeoms(geoms)\n",
    "\n",
    "                # update the first feature with new geometry and delete the others\n",
    "                where = \"{} = '{}'\".format(fld_dissolve, unique_val)\n",
    "                cnt = 0\n",
    "                with arcpy.da.UpdateCursor(fc, ('SHAPE@'), where) as curs:\n",
    "                    for row in curs:\n",
    "                        cnt += 1\n",
    "                        if cnt == 1:\n",
    "                            row[0] = diss_geom\n",
    "                            curs.updateRow(row)\n",
    "                        else:\n",
    "                            curs.deleteRow()\n",
    "    else:\n",
    "        print(\"No duplicates!\")\n",
    "    print (\"Finished combining APNs: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    \n",
    "# union all geometry inputs into one dissolved geometry\n",
    "@timer\n",
    "def DissolveGeoms(geoms):\n",
    "    cnt = 0\n",
    "    for geom in geoms:\n",
    "        cnt += 1\n",
    "        if cnt == 1:\n",
    "            diss_geom = geom\n",
    "        else:\n",
    "            diss_geom = diss_geom.union(geom)\n",
    "    return diss_geom\n",
    "\n",
    "# moves attribute values from one feature class to the other using an aspatial join\n",
    "@timer\n",
    "def fieldJoinCalc(updateFC, updateFieldsList, sourceFC, sourceFieldsList):\n",
    "    from time import strftime  \n",
    "    logger.info(\"Started data transfer: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    # Use list comprehension to build a dictionary from arcpy SearchCursor  \n",
    "    valueDict = {r[0]:(r[1:]) for r in arcpy.da.SearchCursor(sourceFC, sourceFieldsList)}  \n",
    "   \n",
    "    with arcpy.da.UpdateCursor(updateFC, updateFieldsList) as updateRows:  \n",
    "        for updateRow in updateRows:  \n",
    "            # store the Join value of the row being updated in a keyValue variable  \n",
    "            keyValue = updateRow[0]  \n",
    "            # verify that the keyValue is in the Dictionary  \n",
    "            if keyValue in valueDict:  \n",
    "                # transfer the value stored under the keyValue from the dictionary to the updated field.  \n",
    "                updateRow[1] = valueDict[keyValue][0]  \n",
    "                updateRows.updateRow(updateRow)    \n",
    "    del valueDict  \n",
    "    logger.info(\"Finished data transfer: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "# transfer attributes frome one feature class field to another while using multiple fields to create the keys\n",
    "@timer\n",
    "def fieldJoinCalc_multikey(updateFC, updateFieldsList_key, updateFieldsList_value, sourceFC, sourceFieldsList_key, sourceFieldsList_value):\n",
    "    from time import strftime  \n",
    "    print (\"Started data transfer: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    # Use list comprehension to build a dictionary from arcpy SearchCursor  \n",
    "    total_count=0\n",
    "    valueDict = {(r[0]+r[1]):(r[2]) for r in arcpy.da.SearchCursor(sourceFC, (sourceFieldsList_key + sourceFieldsList_value)) if r[0] is not None and r[1] is not None}  \n",
    "    with arcpy.da.UpdateCursor(updateFC, (updateFieldsList_key+ updateFieldsList_value)) as updateRows:  \n",
    "        for updateRow in updateRows:  \n",
    "            # store the Join value of the row being updated in a keyValue variable  \n",
    "            if updateRow[0] is not None and updateRow[1] is not None:\n",
    "                keyValue = updateRow[0]+updateRow[1]\n",
    "                # verify that the keyValue is in the Dictionary  \n",
    "                if keyValue in valueDict:\n",
    "                    total_count +=1\n",
    "                    if (total_count%1000)==0:\n",
    "                        print (f\"Updating row {total_count}\")\n",
    "                    # transfer the value stored under the keyValue from the dictionary to the updated field.  \n",
    "                    updateRow[2] = valueDict[keyValue]  \n",
    "                    updateRows.updateRow(updateRow)    \n",
    "    del valueDict  \n",
    "    logger.info(\"Finished data transfer: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "# send email with attachments\n",
    "def send_mail(body):\n",
    "    msg = MIMEMultipart()\n",
    "    msg['Subject'] = subject\n",
    "    msg['From'] = sender_email\n",
    "    msg['To'] = receiver_email\n",
    "    msgText = MIMEText('%s<br><br>Cheers,<br>GIS Team' % (body), 'html')\n",
    "    msg.attach(msgText)\n",
    "    attachment = MIMEText(open(fileToSend).read())\n",
    "    attachment.add_header(\"Content-Disposition\", \"attachment\", filename = os.path.basename(fileToSend))\n",
    "    msg.attach(attachment)\n",
    "    try:\n",
    "        with smtplib.SMTP(\"mail.smtp2go.com\", 25) as smtpObj:\n",
    "            smtpObj.ehlo()\n",
    "            smtpObj.starttls()\n",
    "#             smtpObj.login(sender_email, password)\n",
    "            smtpObj.sendmail(sender_email, receiver_email, msg.as_string())\n",
    "    except Exception as e:\n",
    "        logger.error(e)\n",
    "\n",
    "#-----------------------------------------------------------------------\n",
    "# START TRANSFORMATION\n",
    "#-----------------------------------------------------------------------\n",
    "try:\n",
    "    # start timer for the get data requests\n",
    "    startTimer = datetime.datetime.now()\n",
    "\n",
    "    #-----------------------------------------------------------------------\n",
    "    # CARSON COUNTY TRANSFORMATION\n",
    "    #-----------------------------------------------------------------------\n",
    "    # get staging feature class and name output transformed feature class\n",
    "    in_features = \"Parcel_CC_Extracted\"\n",
    "    parcel_out  = \"Parcel_CC_Transformed\"\n",
    "\n",
    "    # in-memory feature class\n",
    "    carsonParcel = r\"in_memory/inMemoryFeatureClass\"\n",
    "\n",
    "    # copy feature class into in-memory feature class to work on\n",
    "    arcpy.management.CopyFeatures(in_features, carsonParcel)\n",
    "\n",
    "    # Add TRPA base fields\n",
    "    arcpy.management.AddFields(carsonParcel, baseFields)\n",
    "\n",
    "    # Do work.\n",
    "    with arcpy.da.UpdateCursor(carsonParcel, [\n",
    "                                            ## TRPA base schema ##\n",
    "                                            'APN_TRPA',                 #0\n",
    "                                            'PPNO_TRPA',                #1\n",
    "                                            'JURISDICTION_TRPA',        #2\n",
    "                                            # parcel address   \n",
    "                                            'HSE_NUMBR_TRPA',           #3\n",
    "                                            'STR_DIR_TRPA',             #4\n",
    "                                            'STR_NAME_TRPA',            #5\n",
    "                                            'STR_SUFFIX_TRPA',          #6\n",
    "                                            'UNIT_NUMBR_TRPA',          #7\n",
    "                                            'APO_ADDRESS_TRPA',         #8\n",
    "                                            'PSTL_TOWN_TRPA',           #9\n",
    "                                            'PSTL_STATE_TRPA',          #10\n",
    "                                            'PSTL_ZIP5_TRPA',           #11\n",
    "                                            # owner fields\n",
    "                                                # no first and last fields\n",
    "                                            'OWN_FULL_TRPA',            #12\n",
    "                                            'MAIL_ADD1_TRPA',           #13\n",
    "                                            'MAIL_CITY_TRPA',           #14\n",
    "                                            'MAIL_STATE_TRPA',          #15\n",
    "                                            'MAIL_ZIP5_TRPA',           #16\n",
    "                                            # value fields  \n",
    "                                            'AS_LANDVALUE_TRPA',        #17\n",
    "                                            'AS_IMPROVALUE_TRPA',       #18\n",
    "                                            'AS_SUM_TRPA',              #19\n",
    "                                            'TAX_LANDVALUE_TRPA',       #20 \n",
    "                                            'TAX_IMPROVALUE_TRPA',      #21\n",
    "                                            'TAX_SUM_TRPA',             #22\n",
    "                                            'TAX_YEAR_TRPA',            #23\n",
    "                                            # land use fields \n",
    "                                            'COUNTY_LANDUSE_CODE_TRPA', #24\n",
    "                                            'COUNTY_LANDUSE_TRPA',      #25\n",
    "                                            # Fields for building info\n",
    "                                            \"YEAR_BUILT_TRPA\",          #26\n",
    "                                            'UNITS_TRPA',               #27\n",
    "                                            'BEDROOMS_TRPA',            #28\n",
    "                                            'BATHROOMS_TRPA',           #29\n",
    "                                            'BUILDING_SQFT_TRPA',       #30\n",
    "                                            'VHR_TRPA',                 #31\n",
    "                                            'HOA_TRPA',                 #32\n",
    "                                            ###-------------------------###\n",
    "                                            # County Fields to get data from\n",
    "                                            'APN',   # apn              #33\n",
    "                                            'APN_NUM',   # ppno         #34\n",
    "                                            'Phy_Addr', #full adr       #35\n",
    "                                            'Loc1', # house number      #36\n",
    "                                            'Dir',# street dir          #37\n",
    "                                            'Street_Name',# street name #38\n",
    "                                            'Unit',  # unite Number     #39\n",
    "                                            'Legal_Owner',  # Owner     #40\n",
    "                                            'Mail_Addr',# mail address1 #41\n",
    "                                            'Mail2_Addr',#mail address2 #42\n",
    "                                            'MCity', # Mailing City     #43\n",
    "                                            'MZip',  # Mailing Zip      #44\n",
    "                                            'Land_Value',# land value   #45\n",
    "                                            'Improv_Val',# improvedvalue#46\n",
    "                                            'LU',    # land use code    #47\n",
    "                                            'Total_DWUnits',  # units   #48\n",
    "\n",
    "    ]) as cursor:\n",
    "        # loop through each record and transform the values\n",
    "        for row in cursor:\n",
    "            # Set APN\n",
    "            apn = row[33]\n",
    "            if not (apn is None or apn == \"\" or apn.isspace() == True):\n",
    "                row[0] = (apn[:3] + \"-\" + apn[3:6] + \"-\" + apn[6:8])\n",
    "            else:\n",
    "                row[0] = ''\n",
    "                \n",
    "            #PPNO\n",
    "            ppno = row[34]\n",
    "            if not (ppno is None):\n",
    "                row[1] = int(ppno)\n",
    "            else:\n",
    "                row[1] = ''\n",
    "                \n",
    "            # Jurisdiction\n",
    "            row[2] = \"CC\"\n",
    "            \n",
    "            # APO Address\n",
    "            full_address = row[35]\n",
    "            if not (full_address is None or full_address=='' or full_address.isspace()==True):\n",
    "                row[8] = full_address\n",
    "            else:\n",
    "                row[8] = ''\n",
    "            \n",
    "            # House Number\n",
    "            house = row[36]\n",
    "            if not (house is None):\n",
    "                row[3] = str(house)\n",
    "            else:\n",
    "                row[3] = ''\n",
    "            \n",
    "            # Street Direction\n",
    "            street_direction = row[37]\n",
    "            if not (street_direction is None or street_direction=='' or street_direction.isspace()==True):\n",
    "                row[4] = street_direction\n",
    "            else:\n",
    "                row[4] = ''\n",
    "                \n",
    "            # Street Name\n",
    "            street_name = row[38]\n",
    "            if not (street_name is None or street_name =='' or street_name.isspace()==True):\n",
    "                row[5] = street_name.split(\" \",-1)[0]\n",
    "            else:\n",
    "                row[5] = ''\n",
    "                \n",
    "            # Street Suffix\n",
    "            street_suffix = row[38]\n",
    "            if not (street_suffix is None or street_suffix =='' or street_suffix.isspace()==True):\n",
    "                row[6] = street_suffix.split(\" \")[-1]\n",
    "            else:\n",
    "                row[6] = ''\n",
    "                \n",
    "            # Unit Number\n",
    "            unit= row[39]\n",
    "            if not (unit is None or unit=='' or unit.isspace()==True):\n",
    "                row[7] = unit\n",
    "            else:\n",
    "                row[7] = ''\n",
    "                        \n",
    "            # Postal Town - see Search/Update Cursor below\n",
    "            \n",
    "            # Postal State\n",
    "            row[10] = 'NV'\n",
    "            \n",
    "            # Postal Zip - See Search/Update Cursor below\n",
    "            row[11] = ''    \n",
    "            \n",
    "            # Owner Name\n",
    "            owner = row[40]\n",
    "            if not (owner is None or owner == '' or owner.isspace()==True):\n",
    "                row[12] = owner.strip()\n",
    "            else:\n",
    "                row[12] = ''\n",
    "\n",
    "            # Mailing Address\n",
    "            address1 = row[41]\n",
    "            address2 = row[42]\n",
    "            if not (address2 is None or address2 == '' or address2.isspace()==True):\n",
    "                row[13] = str(address2).strip()\n",
    "            elif (address2 is None or address2 == '' or address2.isspace()==True and address1 is None or address1 == '' or address1.isspace()==True):\n",
    "                row[13] = str(address1).strip()\n",
    "            else:\n",
    "                row[13] = '' \n",
    "            \n",
    "            # Mailing City\n",
    "            mail_city = row[43]        \n",
    "    #         mail_city.split(',',1)[0]\n",
    "            if not (mail_city is None or mail_city=='' or mail_city.isspace()==True):\n",
    "                row[14] = mail_city.strip().split(',',1)[0].strip()\n",
    "            else:\n",
    "                row[14] = ''\n",
    "                \n",
    "            # Mailing State\n",
    "            mail_state = row[43]\n",
    "            if not (mail_state is None or mail_state=='' or mail_state.isspace()==True):\n",
    "                row[15] = mail_state.strip().rsplit(',')[-1].strip()\n",
    "            else:\n",
    "                row[15] = ''\n",
    "            \n",
    "            # Mailing Zipcode\n",
    "            mail_zip = row[44] \n",
    "            if (mail_zip is not None and len(mail_zip)>=5):\n",
    "                row[16] = mail_zip[:5]\n",
    "            else:\n",
    "                row[16] = ''\n",
    "                \n",
    "            # Assessed Land Value\n",
    "            land_value = row[45]\n",
    "            if not(land_value is None):\n",
    "                row[17] = land_value\n",
    "            else:\n",
    "                row[17] = 0\n",
    "            \n",
    "            # Assessed Improved Value\n",
    "            improved_value = row[46]\n",
    "            if not (improved_value is None):\n",
    "                row[18] = improved_value\n",
    "            else:\n",
    "                row[18] = 0\n",
    "                    \n",
    "            # Assessed Sum\n",
    "            if not (land_value is None or improved_value is None):\n",
    "                assessed_sum = improved_value + land_value\n",
    "                row[19] = assessed_sum\n",
    "            else:\n",
    "                row[19] = None\n",
    "            \n",
    "            # Tax  Land Value\n",
    "            taxland_value = row[45]\n",
    "            if not(taxland_value is None):\n",
    "                row[20] = taxland_value/0.35\n",
    "            else:\n",
    "                row[20] = None\n",
    "            \n",
    "            # Tax Improved Value\n",
    "            taximproved_value = row[46]\n",
    "            if not (taximproved_value is None):\n",
    "                row[21] = taximproved_value/0.35\n",
    "            else:\n",
    "                row[21] = None\n",
    "            \n",
    "            # Tax Sum\n",
    "            if not (land_value is None or improved_value is None):\n",
    "                tax_sum = row[20]+row[21]\n",
    "                row[22] = tax_sum\n",
    "            else:\n",
    "                row[22] = None\n",
    "            \n",
    "            # Tax Year\n",
    "            tax_year =  datetime.datetime.now().year\n",
    "\n",
    "            if not (tax_year is None):\n",
    "                row[23] = tax_year\n",
    "            else:\n",
    "                row[23] = ''\n",
    "                \n",
    "            # County Land Use Code\n",
    "            county_luc = row[47]\n",
    "            if not (county_luc is None):\n",
    "                row[24] = str(county_luc)\n",
    "            else:\n",
    "                row[24] = '' \n",
    "                \n",
    "            # Units\n",
    "            units = row[48]\n",
    "            if not (units is None):\n",
    "                row[27] = units\n",
    "            else:\n",
    "                row[27] = None\n",
    "            \n",
    "    #         Update the row.\n",
    "            cursor.updateRow(row)\n",
    "    del cursor\n",
    "\n",
    "    #arcpy.management.CopyFeatures(carsonParcel, parcel_out)\n",
    "\n",
    "    out_coordinate_system = arcpy.SpatialReference('NAD 1983 UTM Zone 10N') \n",
    "    arcpy.Project_management(carsonParcel, parcel_out, out_coordinate_system)\n",
    "\n",
    "    print('New Carson Parcels transformed')\n",
    "    logger.info('New Carson Parcels transformed')\n",
    "    #-------------------------------------------------------------------------------------\n",
    "    ## DOUGLAS TRANSFORM\n",
    "    #-------------------------------------------------------------------------------------\n",
    "    # get staging feature class and name output trnasformed feature class\n",
    "    in_features = \"Parcel_DG_Extracted\"\n",
    "    parcel_out  = \"Parcel_DG_Transformed\"\n",
    "\n",
    "    # in-memory feature class\n",
    "    douglasParcel = r\"in_memory/inMemoryFeatureClass\"\n",
    "\n",
    "    # copy feature class into in-memory feature class to work on\n",
    "    arcpy.management.CopyFeatures(in_features, douglasParcel)\n",
    "\n",
    "    # Add TRPA base fields\n",
    "    arcpy.management.AddFields(douglasParcel, baseFields)\n",
    "\n",
    "\n",
    "    # Do work.\n",
    "    with arcpy.da.UpdateCursor(douglasParcel, [\n",
    "                                            ## TRPA base schema ##\n",
    "                                            'APN_TRPA',                 #0\n",
    "                                            'PPNO_TRPA',                #1\n",
    "                                            'JURISDICTION_TRPA',        #2\n",
    "                                            # parcel address   \n",
    "                                            'HSE_NUMBR_TRPA',           #3\n",
    "                                            'STR_DIR_TRPA',             #4\n",
    "                                            'STR_NAME_TRPA',            #5\n",
    "                                            'STR_SUFFIX_TRPA',          #6\n",
    "                                            'UNIT_NUMBR_TRPA',          #7\n",
    "                                            'APO_ADDRESS_TRPA',         #8\n",
    "                                            'PSTL_TOWN_TRPA',           #9\n",
    "                                            'PSTL_STATE_TRPA',          #10\n",
    "                                            'PSTL_ZIP5_TRPA',           #11\n",
    "                                            # owner fields\n",
    "                                                # no own first and last for DG\n",
    "                                            'OWN_FULL_TRPA',            #12\n",
    "                                            'MAIL_ADD1_TRPA',           #13\n",
    "                                            'MAIL_CITY_TRPA',           #14\n",
    "                                            'MAIL_STATE_TRPA',          #15\n",
    "                                            'MAIL_ZIP5_TRPA',           #16\n",
    "                                            # value fields  \n",
    "                                            'AS_LANDVALUE_TRPA',        #17\n",
    "                                            'AS_IMPROVALUE_TRPA',       #18\n",
    "                                            'AS_SUM_TRPA',              #19\n",
    "                                            'TAX_LANDVALUE_TRPA',       #20 \n",
    "                                            'TAX_IMPROVALUE_TRPA',      #21\n",
    "                                            'TAX_SUM_TRPA',             #22\n",
    "                                            'TAX_YEAR_TRPA',            #23\n",
    "                                            # land use fields \n",
    "                                            'COUNTY_LANDUSE_CODE_TRPA', #24\n",
    "                                            'COUNTY_LANDUSE_TRPA',      #25\n",
    "                                            # Fields for building info\n",
    "                                            \"YEAR_BUILT_TRPA\",          #26\n",
    "                                            'UNITS_TRPA',               #27\n",
    "                                            'BEDROOMS_TRPA',            #28\n",
    "                                            'BATHROOMS_TRPA',           #29\n",
    "                                            'BUILDING_SQFT_TRPA',       #30\n",
    "                                            'VHR_TRPA',                 #31\n",
    "                                            'HOA_TRPA',                 #32\n",
    "                                            ###-------------------------###\n",
    "                                            # County Fields to get data from\n",
    "                                            'APN',   # apn,ppno         #33\n",
    "                                            'PLOC_', # house number     #34\n",
    "                                            'PLOCDR',# street dir       #35\n",
    "                                            'PLOCNM',# street name      #36\n",
    "                                            'PLOCTP',# street suffix    #37\n",
    "                                            'PLOCU_',# unit number      #38\n",
    "                                            'PANAME',# owner name       #39\n",
    "                                            'PMADD1',# mailing addr1    #40\n",
    "                                            'PMADD2',# mailing addr2    #41\n",
    "                                            'PMCTST',# city,state       #42\n",
    "                                            'PZIP',  # zip              #43\n",
    "                                            'YYEAR', # tax year         #44\n",
    "                                            'YLDUSE',# land use code    #45\n",
    "                                            'YLANDV',# land value       #46\n",
    "                                            'YIMPRV',# improved value   #47\n",
    "                                            'YEXMP', # tax exempt value #48\n",
    "                                            'YNETV', # tax net value    #49\n",
    "                                            'PCONYR',# year built       #50\n",
    "                                            'PBEDS', # bedrooms         #51\n",
    "                                            'PBATHS',# bathrooms        #52\n",
    "\n",
    "        ### These are missing from the new service\n",
    "        #                                         'PBLDSF',# building sqft    #\n",
    "        #                                         'STREETADDR', #full adr     #\n",
    "        #                                         'P_DWEL',# units            #\n",
    "        #                                         'VHR',   # vhr yes?         #\n",
    "        #                                         'HOA',   # hoa name         #\n",
    "    ]) as cursor:\n",
    "        # loop through each record and transform the values\n",
    "        for row in cursor:\n",
    "            # APN field\n",
    "            # Get County value\n",
    "            apn = str(row[33])\n",
    "            if not (apn is None or apn == \"\"):\n",
    "                row[0] =(apn[:4] + \"-\" + apn[4:6] + \"-\" + apn[6:9] + \"-\" + apn[9:12])\n",
    "            else:\n",
    "                row[0] = \"\"\n",
    "                \n",
    "            #PPNO\n",
    "            ppno = row[33]\n",
    "            if not (ppno is None):\n",
    "                row[1] = int(ppno)\n",
    "            else:\n",
    "                row[1] = ''\n",
    "                \n",
    "            # Jurisdiction\n",
    "            row[2] = \"DG\"\n",
    "            \n",
    "            # APO Address\n",
    "            house            = str(row[34]).strip()\n",
    "            street_direction = str(row[35]).strip()\n",
    "            street_name      = str(row[36]).strip()\n",
    "            street_suffix    = str(row[37]).strip()\n",
    "            unit             = str(row[38]).strip()\n",
    "            if not (street_name is None or street_name=='' or street_name.isspace()==True):\n",
    "                row[8] = re.sub(\" +\",\" \", (house + \" \" + street_direction +\" \" + street_name+\" \" + street_suffix+\" \" + unit).strip())\n",
    "            else:\n",
    "                row[8] = ''\n",
    "            \n",
    "            # House Number\n",
    "            house = row[34]\n",
    "            if not (house is None):\n",
    "                row[3] = str(house)\n",
    "            else:\n",
    "                row[3] = ''\n",
    "            \n",
    "            # Street Direction\n",
    "            street_direction = row[35]\n",
    "            if not (street_direction is None or street_direction=='' or street_direction.isspace()==True):\n",
    "                row[4] = street_direction\n",
    "            else:\n",
    "                row[4] = ''\n",
    "                \n",
    "            # Street Name\n",
    "            street_name = row[36]\n",
    "            if not (street_name is None or street_name =='' or street_name.isspace()==True):\n",
    "                row[5] = street_name\n",
    "            else:\n",
    "                row[5] = ''\n",
    "                \n",
    "            # Street Suffix\n",
    "            street_suffix = row[37]\n",
    "            if not (street_suffix is None or street_suffix =='' or street_suffix.isspace()==True):\n",
    "                row[6] = street_suffix\n",
    "            else:\n",
    "                row[6] = ''\n",
    "                \n",
    "            # Unit Number\n",
    "            unit= row[38]\n",
    "            if not (unit is None or unit=='' or unit.isspace()==True):\n",
    "                row[7] = unit\n",
    "            else:\n",
    "                row[7] = ''\n",
    "                        \n",
    "            # Postal Town - see Search/Update Cursor below\n",
    "            \n",
    "            # Postal State\n",
    "            row[10] = 'NV'\n",
    "            \n",
    "            # Postal Zip - See Search/Update Cursor below\n",
    "            row[11] = ''    \n",
    "            \n",
    "            # Owner Name\n",
    "            owner = row[39]\n",
    "            if not (owner is None or owner == '' or owner.isspace()==True):\n",
    "                row[12] = owner.strip()\n",
    "            else:\n",
    "                row[12] = \"\"\n",
    "\n",
    "            # Mailing Address\n",
    "            address1 = row[40].strip()\n",
    "            address2 = row[41].strip()\n",
    "            if not (address1 is None or address1=='' or address1.isspace()==True):\n",
    "                row[13] = str(address1 + \" \" + address2)\n",
    "            elif (address2 is None):\n",
    "                row[13] = address1\n",
    "            else:\n",
    "                row[13] = ''\n",
    "                    \n",
    "            # Mailing City\n",
    "            mail_city = str(row[42]).split(',',1)[0].strip()\n",
    "            \n",
    "            if not (mail_city is None or mail_city=='' or mail_city.isspace()==True):\n",
    "                row[14] = mail_city\n",
    "            else:\n",
    "                row[14] = ''\n",
    "                \n",
    "            # Mailing State - Added logic to set anything that isn't 2 characters long to '' \n",
    "            mail_state = str(row[42]).rsplit(',')[-1].strip().split(' ',1)[0].strip()\n",
    "            if not (mail_state is None or mail_state=='' or mail_state.isspace()==True or len(mail_state)!=2):\n",
    "                row[15] = mail_state\n",
    "            else:\n",
    "                row[15] = ''\n",
    "            \n",
    "            # Mailing Zipcode\n",
    "            mail_zip = row[43].strip()\n",
    "            if not (mail_zip is None or mail_zip=='' or mail_zip.isspace()==True):\n",
    "                row[16] = mail_zip[:5]\n",
    "            else:\n",
    "                row[16] = ''\n",
    "                \n",
    "            # Assessed Land Value\n",
    "            land_value = row[46]\n",
    "            if not(land_value is None):\n",
    "                row[17] = land_value\n",
    "            else:\n",
    "                row[17] = ''\n",
    "            \n",
    "            # Assessed Improved Value\n",
    "            improved_value = row[47]\n",
    "            if not (improved_value is None):\n",
    "                row[18] = improved_value\n",
    "            else:\n",
    "                row[18] = None\n",
    "                    \n",
    "            # Assessed Sum\n",
    "            if not (land_value is None or improved_value is None):\n",
    "                assessed_sum = improved_value + land_value\n",
    "                row[19] = assessed_sum\n",
    "            else:\n",
    "                row[19] = None\n",
    "            \n",
    "            # Tax  Land Value\n",
    "            taxland_value = row[46]\n",
    "            if not(taxland_value is None):\n",
    "                row[20] = taxland_value/0.35\n",
    "            else:\n",
    "                row[20] = None\n",
    "            \n",
    "            # Tax Improved Value\n",
    "            taximproved_value = row[47]\n",
    "            if not (taximproved_value is None):\n",
    "                row[21] = taximproved_value/0.35\n",
    "            else:\n",
    "                row[21] = None\n",
    "            \n",
    "            # Tax Sum\n",
    "            if not (land_value is None or improved_value is None):\n",
    "                tax_sum = row[49]\n",
    "                row[22] = tax_sum\n",
    "            else:\n",
    "                row[22] = None\n",
    "            \n",
    "            # Tax Year\n",
    "            tax_year = row[44]\n",
    "            if not (tax_year is None):\n",
    "                row[23] = tax_year\n",
    "            else:\n",
    "                row[23] = ''\n",
    "                \n",
    "            # County Land Use Code\n",
    "            county_luc = row[45]\n",
    "            if not (county_luc is None):\n",
    "                row[24] = str(county_luc)\n",
    "            else:\n",
    "                row[24] = '' \n",
    "            \n",
    "            # Year Built\n",
    "            year_built = row[50]\n",
    "            if not (year_built is None or year_built==''):\n",
    "                row[26] = year_built\n",
    "            else:\n",
    "                row[26] = None\n",
    "            \n",
    "            # Bedrooms\n",
    "            bedrooms = row[51]\n",
    "            if not (bedrooms is None or bedrooms==''):\n",
    "                row[28] = bedrooms\n",
    "            else:\n",
    "                row[28] = None\n",
    "            # Bathrooms\n",
    "            baths = row[52]\n",
    "            if not (baths is None or baths==''):\n",
    "                row[29] = baths\n",
    "            else:\n",
    "                row[29] = None\n",
    "                \n",
    "    #         Update the row.\n",
    "            cursor.updateRow(row)\n",
    "    del cursor\n",
    "\n",
    "    out_coordinate_system = arcpy.SpatialReference('NAD 1983 UTM Zone 10N') \n",
    "    arcpy.Project_management(douglasParcel, parcel_out, out_coordinate_system)\n",
    "\n",
    "    print('New Douglas Parcels transformed')\n",
    "    logger.info('New Douglas Parcels Transformed')\n",
    "    #-------------------------------------------------------------------------------------------\n",
    "    # ELDORADO TRANSFORM\n",
    "    #-------------------------------------------------------------------------------------------\n",
    "    # get staging feature class to transform\n",
    "    in_features = \"Parcel_EL_Extracted\"\n",
    "    parcel_out  = \"Parcel_EL_Transformed\"\n",
    "\n",
    "    # in-memory feature class\n",
    "    eldoradoParcel = r\"in_memory/inMemoryFeatureClass\"\n",
    "\n",
    "    # copy feature class into in-memory feature class to work on\n",
    "    arcpy.management.CopyFeatures(in_features, eldoradoParcel)\n",
    "\n",
    "    # Add TRPA base fields\n",
    "    arcpy.management.AddFields(eldoradoParcel, baseFields)\n",
    "\n",
    "    # Set up the regex queries for the data.\n",
    "    # cityStateZipRegex = r'(.+?)\\s([A-Z]{1,2})\\s(.+?)$' - Keep in case new one doesn't work out long term.\n",
    "    cityStateZipRegex = r'(.+?)\\s([A-Z]{1,2})\\s(?=\\d)(.*)'\n",
    "    poBoxRegex = r'([^x]+)\\W(P\\s*O BOX\\W*[0-9]{1,6})'\n",
    "    addressRegex = r'(\\d{1,5}\\D+.+)'\n",
    "    canadaRegex = r'(.+?)\\s([A-Z]{1,2})\\s(CANADA)\\s(.*)'\n",
    "    brazilRegex = r'(.+?)\\s(BRAZIL)\\s(.*)'\n",
    "\n",
    "    # Set up list for addresses with a country name in the mail_addr4 column.\n",
    "    countriesList = ['japan','canada', 'australia']\n",
    "\n",
    "    # Transform County data to TRPA Schema\n",
    "    with arcpy.da.UpdateCursor(eldoradoParcel, [\n",
    "                                            ## TRPA base schema ##\n",
    "                                            'APN_TRPA',                 #0\n",
    "                                            'PPNO_TRPA',                #1\n",
    "                                            'JURISDICTION_TRPA',        #2\n",
    "                                            # parcel address   \n",
    "                                            'HSE_NUMBR_TRPA',           #3\n",
    "                                            'STR_DIR_TRPA',             #4\n",
    "                                            'STR_NAME_TRPA',            #5\n",
    "                                            'STR_SUFFIX_TRPA',          #6\n",
    "                                            'UNIT_NUMBR_TRPA',          #7\n",
    "                                            'APO_ADDRESS_TRPA',         #8\n",
    "                                            'PSTL_TOWN_TRPA',           #9\n",
    "                                            'PSTL_STATE_TRPA',          #10\n",
    "                                            'PSTL_ZIP5_TRPA',           #11\n",
    "                                            # owner fields\n",
    "                                                # no first and last fields\n",
    "                                            'OWN_FULL_TRPA',            #12\n",
    "                                            'MAIL_ADD1_TRPA',           #13\n",
    "                                            'MAIL_CITY_TRPA',           #14\n",
    "                                            'MAIL_STATE_TRPA',          #15\n",
    "                                            'MAIL_ZIP5_TRPA',           #16\n",
    "                                            # value fields  \n",
    "                                            'AS_LANDVALUE_TRPA',        #17\n",
    "                                            'AS_IMPROVALUE_TRPA',       #18\n",
    "                                            'AS_SUM_TRPA',              #19\n",
    "                                            'TAX_LANDVALUE_TRPA',       #20 \n",
    "                                            'TAX_IMPROVALUE_TRPA',      #21\n",
    "                                            'TAX_SUM_TRPA',             #22\n",
    "                                            'TAX_YEAR_TRPA',            #23\n",
    "                                            # land use fields \n",
    "                                            'COUNTY_LANDUSE_CODE_TRPA', #24\n",
    "                                            'COUNTY_LANDUSE_TRPA',      #25\n",
    "                                            # Fields for building info\n",
    "                                            \"YEAR_BUILT_TRPA\",          #26\n",
    "                                            'UNITS_TRPA',               #27\n",
    "                                            'BEDROOMS_TRPA',            #28\n",
    "                                            'BATHROOMS_TRPA',           #29\n",
    "                                            'BUILDING_SQFT_TRPA',       #30\n",
    "                                            'VHR_TRPA',                 #31\n",
    "                                            'HOA_TRPA',                 #32\n",
    "                                            ###-------------------------###\n",
    "                                            # County Fields to get data from\n",
    "                                            'PRCL_ID',                  #33\n",
    "                                            'OWNER_NAME',               #34\n",
    "                                            'MAIL_ADDR1',               #35\n",
    "                                            'MAIL_ADDR2',               #36\n",
    "                                            'MAIL_ADDR3',               #37\n",
    "                                            'MAIL_ADDR4',               #38\n",
    "                                            'ADDRSTNBR',                #39\n",
    "                                            'ADDRSTDIR',                #40\n",
    "                                            'ADDRSTNAME',               #41\n",
    "                                            'ADDRSTTYPE',               #42\n",
    "                                            'ADDRUNITNB',               #43\n",
    "                                            'PRCL_ADDR',                #44\n",
    "                                            'USECD_1',                  #45\n",
    "                                            'USECDLIT_1',               #46\n",
    "                                            'STRUCT_VAL',               #47\n",
    "                                            'LAND_VAL',                 #48\n",
    "                                            'YR_BUILT',                 #49\n",
    "                                            'DWELLUNITS',               #50\n",
    "                                            'BEDROOMS',                 #51\n",
    "                                            'ADDRSTPRFX'                 #52\n",
    "    ]) as cursor:\n",
    "        # transform each row\n",
    "        for row in cursor:   \n",
    "            # Set APN\n",
    "            apn = row[33]\n",
    "            if not (apn is None or apn == \"\" or apn.isspace() == True or 'UN' in apn):\n",
    "                row[0] = (apn[:3] + \"-\" + apn[3:6] + \"-\" + apn[6:9])\n",
    "            else:\n",
    "                row[0] = ''\n",
    "                \n",
    "            # Set PPNO\n",
    "            ppno = row[33]\n",
    "            if not (apn is None or apn == \"\" or apn.isspace() == True or 'UN' in apn or 'NP' in apn):\n",
    "                try:\n",
    "                    row[1] = float(ppno)\n",
    "                except ValueError:\n",
    "                    row[1] = 0\n",
    "            else:\n",
    "                row[1] = 0\n",
    "            # Set County\n",
    "            row[2] = 'EL'\n",
    "            \n",
    "            # APO Address\n",
    "            full_address = row[44]\n",
    "            if not (full_address is None or full_address=='' or full_address.isspace()==True):\n",
    "                \n",
    "                row[8] = full_address\n",
    "            else:\n",
    "                row[8] = ''\n",
    "            \n",
    "            # House Number\n",
    "            house = row[39]\n",
    "            if not (house is None):\n",
    "                # convert house number to integer type\n",
    "                row[3] = str(int(house))\n",
    "            else:\n",
    "                row[3] = ''\n",
    "            \n",
    "            # Street Direction\n",
    "            street_direction = row[40]\n",
    "            if not (street_direction is None or street_direction=='' or street_direction.isspace()==True\n",
    "                    or street_direction == 'UNASSIGNED'):\n",
    "                # get the first character\n",
    "                row[4] = street_direction[0]\n",
    "            else:\n",
    "                row[4] = ''\n",
    "                \n",
    "            # Street Name\n",
    "            street_name = row[41]\n",
    "            street_prefix = row[52]\n",
    "            if not (street_name is None or street_name =='' or street_name.isspace()==True):\n",
    "                if not (street_prefix is None or street_prefix =='' or street_prefix.isspace()==True\n",
    "                    or street_prefix == 'UNASSIGNED'):\n",
    "                    row[5]= street_prefix + ' ' + street_name\n",
    "                else:\n",
    "                    row[5] = street_name\n",
    "            else:\n",
    "                row[5] = ''\n",
    "                \n",
    "            # Street Suffix\n",
    "            street_suffix = row[42]\n",
    "            if not (street_suffix is None or street_suffix =='' or street_suffix.isspace()==True               \n",
    "                    or street_direction == 'UNASSIGNED'):\n",
    "                row[6] = street_suffix\n",
    "            else:\n",
    "                row[6] = ''\n",
    "                \n",
    "            # Unit Number\n",
    "            unit= row[43]\n",
    "            if not (unit is None or unit=='' or unit.isspace()==True):\n",
    "                row[7] = (\"#\" + str(unit))\n",
    "            else:\n",
    "                row[7] = ''\n",
    "                        \n",
    "            # Postal Town - see Search/Update Cursor below\n",
    "            row[9] = ''\n",
    "            \n",
    "            # Postal State\n",
    "            row[10] = 'CA'\n",
    "            \n",
    "            # Postal Zip - See Search/Update Cursor below\n",
    "            row[11] = ''    \n",
    "            \n",
    "            # Set Mailing Owner, Address, City, State, Zip\n",
    "            if row[38] != ' ':\n",
    "    #             print(\"Working on MAIL_ADDR4\")\n",
    "                if row[38] != 'UNKNOWN' and row[38].lower() not in countriesList:\n",
    "                    # Parse out city, state, and zip code and assign variables.\n",
    "                    cityStateZip = re.search(cityStateZipRegex, str(row[38]))\n",
    "                    if cityStateZip is not None:\n",
    "                        city = cityStateZip.group(1)\n",
    "                        state = cityStateZip.group(2)\n",
    "                        zipCode = cityStateZip.group(3)\n",
    "                        country = ''\n",
    "                    else:\n",
    "                        continue\n",
    "                    # Check to see if address starts with PO Box and assign variable.\n",
    "                    if str(row[37]).startswith('PO') or str(row[37]).startswith('P O'):\n",
    "                        address = str(row[37])\n",
    "                    elif \"PO BOX\" in str(row[37]) or \"P O BOX\" in str(row[37]) or \"P.O. BOX\" in str(row[37]):\n",
    "                        address = str(row[37])\n",
    "\n",
    "                    # Parse out address that doesn't have PO Box and assign variable.\n",
    "                    else:\n",
    "                        add = re.search(addressRegex,str(row[37]))\n",
    "                        address = add.group(1)\n",
    "\n",
    "                    # Assign owner variable.\n",
    "                    owner = str(row[34])+' '+str(row[35])+' '+str(row[36])\n",
    "                elif row[38].lower() in countriesList:\n",
    "                    country = str(row[38])\n",
    "                    state = str(row[37])\n",
    "                    city = str(row[36])\n",
    "                    address = str(row[35])\n",
    "                    owner = str(row[34])\n",
    "                    zipCode = ''\n",
    "                elif row[38] == \"CANADA\": # temporary patch for incorrectly entered Canadian address\n",
    "                    canadaZip = re.search(r'[ABCEGHJKLMNPRSTVXY][0-9][ABCEGHJKLMNPRSTVWXYZ] ?[0-9][ABCEGHJKLMNPRSTVWXYZ][0-9]', str(row[3]))\n",
    "                    canadaProvZip = re.search(r'(.*?)\\s(N[BLSTU]|[AMN]B|[BQ]C|ON|PE|SK)',str(row[36]))\n",
    "                    if canadaZip != None:\n",
    "                        zipCode = str(canadaZip.group(0))\n",
    "                    else:\n",
    "                        zipCode =''\n",
    "                        address = str(row[35])\n",
    "                        city = str(canadaProvZip.group(1))\n",
    "                        state = str(canadaProvZip.group(2))\n",
    "                        country = str(row[38])\n",
    "                else:\n",
    "                    owner = str(row[34])\n",
    "                    address = ''\n",
    "                    city = ''\n",
    "                    state = ''\n",
    "                    zipCode = ''\n",
    "                    country = ''\n",
    "\n",
    "            # If mail_addr4 is \"empty\".\n",
    "            elif row[37] != ' ':\n",
    "    #             print(\"Working on MAIL_ADDR3\")\n",
    "                # Parse out city, state, and zip code.\n",
    "                cityStateZip = re.search(cityStateZipRegex, str(row[37]))\n",
    "\n",
    "                # Foreign addresses won't parse so assign country, owner, address, and city variables. Set state and zip to blanks.\n",
    "                if cityStateZip is None:\n",
    "                    country = str(row[37])\n",
    "                    owner = str(row[34])\n",
    "                    address = str(row[35])\n",
    "                    city = str(row[36])\n",
    "                    state = ''\n",
    "                    zipCode = ''\n",
    "                else:\n",
    "                    country = ''\n",
    "                    row2 = str(row[2])\n",
    "\n",
    "                    # Sanitize rows that start with a space.\n",
    "                    if str(row[36]).startswith(' '):\n",
    "                        row2 = str(row[36])[1:]\n",
    "\n",
    "                    # Parse out city, state, and zip code and assign variables.\n",
    "                    city = cityStateZip.group(1)\n",
    "                    state = cityStateZip.group(2)\n",
    "                    zipCode = cityStateZip.group(3)\n",
    "\n",
    "                    # Check to see if address starts with PO Box and assign variable.\n",
    "                    if row2.startswith('PO') or row2.startswith('P O') or row2.startswith('P.O.'):\n",
    "                        address = row2\n",
    "\n",
    "                    # Sometimes there may be a word in front of PO Box and parse that out and assign variable.\n",
    "                    elif \"PO BOX\" in row2 or \"P O BOX\" in row2 or row2.startswith('ONE ') or row2.startswith('TWO '):\n",
    "                        address = row2\n",
    "                    else:\n",
    "                        # Parse out address that doesn't have PO Box and assign variable, sometimes there no address so set variable to None.\n",
    "                        add = re.search(addressRegex,row2)\n",
    "                        if add is None:\n",
    "                            address = 'None'\n",
    "                        else:\n",
    "                            address = add.group(1)\n",
    "\n",
    "                    # Assign owner variable.\n",
    "                    owner = str(row[34])+' '+str(row[35])\n",
    "\n",
    "            # Before moving to mail_addr2 must capture \"blanks\" and USA owned parcels and insert blanks.\n",
    "            elif row[0] == 'UNITED STATES OF AMERICA':\n",
    "                cityStateZip = re.search(cityStateZipRegex, str(row[36]))\n",
    "                owner = str(row[34])\n",
    "                address = str(row[35])\n",
    "                if cityStateZip is None:\n",
    "                    city = ''\n",
    "                    state = ''\n",
    "                    zipCode = ''\n",
    "                else:\n",
    "                    city = cityStateZip.group(1)\n",
    "                    state = cityStateZip.group(2)\n",
    "                    zipCode = cityStateZip.group(3)\n",
    "                country = ''\n",
    "            elif row[34] == ' ':\n",
    "                owner = ''\n",
    "                address = ''\n",
    "                city = ''\n",
    "                state = ''\n",
    "                zipCode = ''\n",
    "                country = ''\n",
    "            elif row[35] == ' ':\n",
    "                owner = str(row[34])\n",
    "                address = ''\n",
    "                city = ''\n",
    "                state = ''\n",
    "                zipCode = ''\n",
    "                country = ''\n",
    "\n",
    "            # Parse the rest of the address info.\n",
    "            else:\n",
    "    #             print(\"Working on MAIL_ADDR2\")\n",
    "                if str(row[36]) == ' ':\n",
    "                    owner = str(row[34])\n",
    "                    address = str(row[35])\n",
    "                    city = ''\n",
    "                    state = ''\n",
    "                    zipCode = ''\n",
    "                    country = ''\n",
    "                else:\n",
    "                    row2 = str(row[36])\n",
    "\n",
    "                    # Parse out city, state, and zip code and assign variables.\n",
    "                    cityStateZip = re.search(cityStateZipRegex, row2)\n",
    "\n",
    "                    # if it can't parse it's a foreign address and assign country variable.\n",
    "                    if cityStateZip is None:\n",
    "                        if \"CANADA\" in row2:\n",
    "                            cityStateZip = re.search(canadaRegex, row2)\n",
    "                            city = cityStateZip.group(1)\n",
    "                            state = cityStateZip.group(2)\n",
    "                            zipCode = cityStateZip.group(4)\n",
    "                            country = cityStateZip.group(3)\n",
    "                        if \"BRAZIL\" in row2:\n",
    "                            cityStateZip = re.search(brazilRegex, row2)\n",
    "                            city = cityStateZip.group(1)\n",
    "                            state = ''\n",
    "                            zipCode = cityStateZip.group(3)\n",
    "                            country = cityStateZip.group(2)\n",
    "                    else:\n",
    "                        row1 = str(row[35])\n",
    "                        country = ''\n",
    "                        city = cityStateZip.group(1)\n",
    "                        state = cityStateZip.group(2)\n",
    "                        zipCode = cityStateZip.group(3)\n",
    "\n",
    "                        # Sanitize rows that start with a space.\n",
    "                        if row1.startswith(' '):\n",
    "                            row1 = row1[1:]\n",
    "\n",
    "                        # Check to see if address starts with PO Box and assign variable.\n",
    "                        if row1.startswith('PO') or row1.startswith('P.O.') or row1.startswith('P O') or row1.startswith('P  O'):\n",
    "                            address = str(row[35])\n",
    "\n",
    "                        # Sometimes there may be a word in front of PO Box and parse that out and assign variable.\n",
    "                        elif \"PO BOX\" in row1 or \"P O BOX\" in row1:\n",
    "                            poBox = re.search(poBoxRegex,row1)\n",
    "\n",
    "                            # If it can't be parsed assign variable.\n",
    "                            if poBox is None:\n",
    "                                address = row1\n",
    "                            else:\n",
    "                                address = poBox.group(2)\n",
    "                        else:\n",
    "                            # Parse out address that doesn't have PO Box and assign variable, sometimes there no address so set variable to None.\n",
    "                            add = re.search(addressRegex,row1)\n",
    "\n",
    "                            # Have exception for addresses that spell out 'one' instead of '1'.\n",
    "                            if add is None or row1.startswith('ONE'):\n",
    "                                address = row1\n",
    "                            else:\n",
    "                                address = add.group(1)\n",
    "\n",
    "                    # Set owner variable.\n",
    "                    owner = str(row[34])\n",
    "\n",
    "            # Set Owner\n",
    "            row[12] = owner\n",
    "            \n",
    "            # Set Mailing Address\n",
    "            row[13] = address\n",
    "            \n",
    "            # Set Mailing City\n",
    "            row[14] = city\n",
    "            \n",
    "            # Set Mailing State\n",
    "            row[15] = state\n",
    "            \n",
    "            # Set Mailing ZIP\n",
    "            row[16] = zipCode[:5]\n",
    "    #         row[10] = country\n",
    "\n",
    "            # Assessed Land Value\n",
    "            land_value = row[48]\n",
    "            if not(land_value is None):\n",
    "                row[17] = land_value\n",
    "            else:\n",
    "                row[17] = ''\n",
    "            \n",
    "            # Assessed Improved Value\n",
    "            improved_value = row[47]\n",
    "            if not (improved_value is None):\n",
    "                row[18] = improved_value\n",
    "            else:\n",
    "                row[18] = None\n",
    "                    \n",
    "            # Assessed Sum\n",
    "            if not (land_value is None or improved_value is None):\n",
    "                assessed_sum = improved_value + land_value\n",
    "                row[19] = assessed_sum\n",
    "            else:\n",
    "                row[19] = None\n",
    "            \n",
    "            # Tax  Land Value\n",
    "            taxland_value = row[48]\n",
    "            if not(taxland_value is None):\n",
    "                row[20] = taxland_value\n",
    "            else:\n",
    "                row[20] = None\n",
    "            \n",
    "            # Tax Improved Value\n",
    "            taximproved_value = row[47]\n",
    "            if not (taximproved_value is None):\n",
    "                row[21] = taximproved_value\n",
    "            else:\n",
    "                row[21] = None\n",
    "            \n",
    "            # Tax Sum\n",
    "            if not (land_value is None or improved_value is None):\n",
    "                tax_sum = taximproved_value + taxland_value\n",
    "                row[22] = tax_sum\n",
    "            else:\n",
    "                row[22] = None\n",
    "            \n",
    "            # Tax Year\n",
    "            row[23] = datetime.datetime.now().year # get current year\n",
    "                \n",
    "            # County Land Use Code\n",
    "            county_luc = row[45]\n",
    "            if not (county_luc is None):\n",
    "                row[24] = str(county_luc)\n",
    "            else:\n",
    "                row[24] = '' \n",
    "            \n",
    "            # County Land Use - See Search/Update Cursor Below\n",
    "            county_landuse = row[46]\n",
    "            if not (county_landuse is None or county_landuse=='' or county_landuse.isspace()==True):\n",
    "                row[25] = county_landuse\n",
    "            else:\n",
    "                row[25] = '' \n",
    "            \n",
    "            # Year Built\n",
    "            year_built = row[49]\n",
    "            if not (year_built is None):\n",
    "                row[26] = year_built\n",
    "            else:\n",
    "                row[26] = None\n",
    "                \n",
    "            # Units\n",
    "            units = row[50]\n",
    "            if not (units is None):\n",
    "                row[27] = units\n",
    "            else:\n",
    "                row[27] = None\n",
    "            \n",
    "            # Bedrooms\n",
    "            bedrooms = row[51]\n",
    "            if not (bedrooms is None):\n",
    "                row[28] = bedrooms\n",
    "            else:\n",
    "                row[28] = None\n",
    "\n",
    "            # Update the row.\n",
    "            cursor.updateRow(row)\n",
    "    del cursor\n",
    "\n",
    "    out_coordinate_system = arcpy.SpatialReference('NAD 1983 UTM Zone 10N') \n",
    "\n",
    "    CombineAPNs(eldoradoParcel, 'APN_TRPA')\n",
    "\n",
    "    arcpy.Project_management(eldoradoParcel, parcel_out, out_coordinate_system)\n",
    "    print('New El Dorado Parcels transformed')\n",
    "    logger.info(\"New El Dorado Parcels Transformed\")\n",
    "    #---------------------------------------------------------------------------------\n",
    "    # PLACER COUNTY TRANSFORM\n",
    "    #---------------------------------------------------------------------------------\n",
    "    in_features = \"Parcel_PL_Extracted\"\n",
    "    parcel_out  = \"Parcel_PL_Transformed\"\n",
    "\n",
    "    # in-memory feature class\n",
    "    placerParcel = r\"in_memory/inMemoryFeatureClass\"\n",
    "\n",
    "    # copy feature class into in-memory feature class to work on\n",
    "    arcpy.management.CopyFeatures(in_features, placerParcel)\n",
    "\n",
    "    # Add TRPA base fields\n",
    "    arcpy.management.AddFields(placerParcel, baseFields)\n",
    "\n",
    "    # Transform County data to TRPA data.\n",
    "    with arcpy.da.UpdateCursor(placerParcel, ['APN_TRPA',               #0\n",
    "                                            'PPNO_TRPA',                #1\n",
    "                                            'JURISDICTION_TRPA',        #2\n",
    "                                            # parcel address   \n",
    "                                            'HSE_NUMBR_TRPA',           #3\n",
    "                                            'STR_DIR_TRPA',             #4\n",
    "                                            'STR_NAME_TRPA',            #5\n",
    "                                            'STR_SUFFIX_TRPA',          #6\n",
    "                                            'UNIT_NUMBR_TRPA',          #7\n",
    "                                            'APO_ADDRESS_TRPA',         #8\n",
    "                                            'PSTL_TOWN_TRPA',           #9\n",
    "                                            'PSTL_STATE_TRPA',          #10\n",
    "                                            'PSTL_ZIP5_TRPA',           #11\n",
    "                                            # owner fields\n",
    "                                            'OWN_FIRST_TRPA',           #12\n",
    "                                            'OWN_LAST_TRPA',            #13\n",
    "                                            'OWN_FULL_TRPA',            #14\n",
    "                                            'MAIL_ADD1_TRPA',           #15\n",
    "                                            'MAIL_CITY_TRPA',           #16\n",
    "                                            'MAIL_STATE_TRPA',          #17\n",
    "                                            'MAIL_ZIP5_TRPA',           #18\n",
    "                                            # value fields  \n",
    "                                            'AS_LANDVALUE_TRPA',        #19\n",
    "                                            'AS_IMPROVALUE_TRPA',       #20\n",
    "                                            'AS_SUM_TRPA',              #21\n",
    "                                            'TAX_LANDVALUE_TRPA',       #22 \n",
    "                                            'TAX_IMPROVALUE_TRPA',      #23\n",
    "                                            'TAX_SUM_TRPA',             #24\n",
    "                                            'TAX_YEAR_TRPA',            #25\n",
    "                                            # land use fields \n",
    "                                            'COUNTY_LANDUSE_CODE_TRPA', #26\n",
    "                                            'COUNTY_LANDUSE_TRPA',      #27\n",
    "                                            # Fields for building info\n",
    "                                            \"YEAR_BUILT_TRPA\",          #28\n",
    "                                            'UNITS_TRPA',               #29\n",
    "                                            'BEDROOMS_TRPA',            #30\n",
    "                                            'BATHROOMS_TRPA',           #31\n",
    "                                            'BUILDING_SQFT_TRPA',       #32\n",
    "                                            'VHR_TRPA',                 #33\n",
    "                                            'HOA_TRPA',                 #34\n",
    "                                            ###-------------------------###\n",
    "                                            # County Fields to get data from\n",
    "                                            'APN',   # apn                #35\n",
    "                                            'FEEPARCEL',   # ppno            #36\n",
    "                                            'STREETNUM', # house number   #37\n",
    "                                            'STREETDIR',# street dir      #38\n",
    "                                            'STREETNAME',# street name    #39\n",
    "                                            'STREETTYPE',# street suffix  #40\n",
    "                                            'SP_APT',  # unit number      #41\n",
    "                                            'OWNER1',# owner name         #42\n",
    "                                            'OWNER2',# owner 2            #43\n",
    "                                            'ADR1',  # mailing addr1      #44\n",
    "                                            'ADR2',  # mailing addr2      #45\n",
    "                                            'CITY',  # city               #46 \n",
    "                                            'STATE', # state              #47\n",
    "                                            'ZIP',  # zip                 #48\n",
    "                                            'USE_CD', # land use code     #49\n",
    "                                            'USE_CD_N', # land use desc   #50\n",
    "                                            'LANDVALUE',# land value      #51\n",
    "                                            'STRUCTURE',# improved value  #52\n",
    "                                            'EffectiveYr',# year built     #53\n",
    "                                            'StructureSF'  # build sqft      #54\n",
    "                                        \n",
    "    ]) as cursor:   \n",
    "        # loop through each record to transform values to TRPA schema values\n",
    "        for row in cursor:\n",
    "            # set APN\n",
    "            apn = row[35]\n",
    "            if not (apn is None or apn == \"\" or apn.isspace() == True or \"ROW\" in apn or len(apn) < 8):\n",
    "                row[0] =apn[:11]\n",
    "            else:\n",
    "                row[0] = \"\"\n",
    "                \n",
    "            # set PPNO\n",
    "            # Changed it to 9 rather than 8\n",
    "            ppno = row[36]\n",
    "            if not (ppno is None or ppno == \"\" or \"ROW\" in ppno or len(ppno) < 8):\n",
    "                row[1] = ppno[:9]\n",
    "            else:\n",
    "                row[1] = 0\n",
    "                \n",
    "            # Jurisdiction\n",
    "            row[2] = \"PL\"\n",
    "            \n",
    "            # House Number\n",
    "            house = row[37]\n",
    "            if not (house is None or house=='' or house.isspace()==True):\n",
    "                row[3] = house\n",
    "            else:\n",
    "                row[3] = ''\n",
    "            \n",
    "            # Street Direction\n",
    "            street_direction = row[38]\n",
    "            if not (street_direction is None or street_direction=='' or street_direction.isspace()==True):\n",
    "                row[4] = street_direction\n",
    "            else:\n",
    "                row[4] = ''\n",
    "                \n",
    "            # Street Name\n",
    "            street_name = row[39]\n",
    "            if not (street_name is None or street_name =='' or street_name.isspace()==True):\n",
    "                row[5] = street_name\n",
    "            else:\n",
    "                row[5] = ''\n",
    "                \n",
    "            # Street Suffix\n",
    "            street_suffix = row[40]\n",
    "            if not (street_suffix is None or street_suffix =='' or street_suffix.isspace()==True):\n",
    "                row[6] = street_suffix\n",
    "            else:\n",
    "                row[6] = ''\n",
    "                \n",
    "            # Unit Number\n",
    "            unit= row[41]\n",
    "            if not (unit is None or unit=='' or unit.isspace()==True):\n",
    "                row[7] = str(unit)\n",
    "            else:\n",
    "                row[7] = ''\n",
    "            \n",
    "            # APO Address\n",
    "            full_address = [house, street_direction, street_name, street_suffix, unit]\n",
    "            adr = str(' '.join(filter(None, full_address))).strip()\n",
    "            \n",
    "            if not (adr is None or adr=='' or adr.isspace()==True):\n",
    "                row[8] = adr\n",
    "            else:\n",
    "                row[8] = ''\n",
    "                \n",
    "            # Postal Town - See TRPA ATTRIBUTION section\n",
    "                \n",
    "            # Postal State\n",
    "            row[10] = 'CA'\n",
    "\n",
    "            # Postal City - See TRPA ATTRIBUTION section\n",
    "            \n",
    "            # Owner Name\n",
    "            owner1 = row[42]\n",
    "            owner2 = row[43]\n",
    "            # own first\n",
    "            if not (owner1 is None or owner1 == \"\" or owner1.isspace() == True):\n",
    "                row[12] = owner1.strip()\n",
    "            else:\n",
    "                row[12] = ''\n",
    "            # own last\n",
    "            if not (owner2 is None or owner2 == \"\" or owner2.isspace() == True):\n",
    "                row[13] = owner2.strip()\n",
    "            else:\n",
    "                row[13] = ''    \n",
    "            # own full\n",
    "            if not (owner2 is None or owner2 == \"\" or owner2.isspace() == True):\n",
    "                row[14] = (owner1+\" \" + owner2).strip()\n",
    "            elif not (owner1 is None or owner1 == \"\"):\n",
    "                row[14] = owner1.strip()\n",
    "            else:\n",
    "                row[14] = ''\n",
    "                \n",
    "            # Mailing Address\n",
    "            address1 = row[44]\n",
    "            address2 = row[45]\n",
    "            if not (address1 is None or address1=='' or address1.isspace()==True):\n",
    "                row[15] = str(address1).strip()\n",
    "            else:\n",
    "                row[15] = ''\n",
    "                    \n",
    "            # Mailing City\n",
    "            mail_city = row[46]\n",
    "            \n",
    "            if not (mail_city is None or mail_city=='' or mail_city.isspace()==True):\n",
    "                row[16] = mail_city\n",
    "            else:\n",
    "                row[16] = ''\n",
    "                \n",
    "            # Mailing State\n",
    "            mail_state = row[47]\n",
    "            if not (mail_state is None or mail_state=='' or mail_state.isspace()==True):\n",
    "                row[17] = mail_state\n",
    "            else:\n",
    "                row[17] = ''\n",
    "            \n",
    "            # Mailing Zipcode\n",
    "            mail_zip = row[48]\n",
    "            if not (mail_zip is None or mail_zip=='' or mail_zip.isspace()==True):\n",
    "                row[18] = mail_zip[:5]\n",
    "            else:\n",
    "                row[18] = ''\n",
    "                \n",
    "            # Assessed Land Value\n",
    "            land_value = row[51]\n",
    "            if not(land_value is None or land_value==''):\n",
    "                row[19] = int(land_value)\n",
    "            else:\n",
    "                row[19] = None\n",
    "        \n",
    "            # Assessed Improved Value    \n",
    "            improved_value = row[52]\n",
    "            if not (improved_value is None or improved_value==''):\n",
    "                row[20] = int(improved_value)\n",
    "            else:\n",
    "                row[20] = None\n",
    "\n",
    "            # Assessed Sum\n",
    "            if not (row[19] is None and row[20] is None):\n",
    "                assessed_sum = improved_value + land_value\n",
    "                row[21] = assessed_sum\n",
    "            else:\n",
    "                row[21] = None\n",
    "            \n",
    "            # Tax Land Value\n",
    "            taxland_value = row[51]\n",
    "            if not(taxland_value is None):\n",
    "                row[22] = int(taxland_value)\n",
    "            else:\n",
    "                row[22] = None\n",
    "            \n",
    "            # Tax Improved Value\n",
    "            taximproved_value = row[52]\n",
    "            if not (taximproved_value is None):\n",
    "                row[23] = int(taximproved_value)\n",
    "            else:\n",
    "                row[23] = None\n",
    "            \n",
    "            # Tax Sum\n",
    "            if not (row[22] is None and row[23] is None):\n",
    "                tax_sum = taximproved_value + taxland_value\n",
    "                row[24] = tax_sum\n",
    "            else:\n",
    "                row[24] = None\n",
    "            \n",
    "            # Tax Year\n",
    "            row[25] = datetime.datetime.now().year # get current year\n",
    "                \n",
    "            # County Land Use Code\n",
    "            county_luc = row[49]\n",
    "            if not (county_luc is None or county_luc=='' or county_luc.isspace()==True):\n",
    "                row[26] = county_luc\n",
    "            else:\n",
    "                row[26] = '' \n",
    "            \n",
    "            # County Land Use\n",
    "            county_landuse = row[50]\n",
    "            if not (county_landuse is None or county_landuse=='' or county_landuse.isspace()==True):\n",
    "                row[27] = county_landuse\n",
    "            else:\n",
    "                row[27] = ''\n",
    "                \n",
    "            # Year Built\n",
    "            year_built = row[53]\n",
    "            if not (year_built is None):\n",
    "                row[28] = year_built\n",
    "            else:\n",
    "                row[28] = None\n",
    "                \n",
    "            # Building SQFT\n",
    "            bldsqft = row[54]\n",
    "            if not (bldsqft is None):\n",
    "                row[32] = bldsqft\n",
    "            else:\n",
    "                row[32] = None\n",
    "                \n",
    "            # Update the row.\n",
    "            cursor.updateRow(row)\n",
    "    del cursor\n",
    "\n",
    "    # combine duplicate APNs \n",
    "    ### some shoreline parcels are split by the highway and have two features for the same APN\n",
    "    CombineAPNs(placerParcel, 'APN_TRPA')\n",
    "\n",
    "    # project to our projected coordinate system\n",
    "    out_coordinate_system = arcpy.SpatialReference('NAD 1983 UTM Zone 10N') \n",
    "    arcpy.Project_management(placerParcel, parcel_out, out_coordinate_system)\n",
    "\n",
    "    # done with the transormations for Placer\n",
    "    print('New Placer Parcels transformed')\n",
    "    logger.info('New Placer Parcels Transformed')\n",
    "    #-------------------------------------------------------------------------------------------\n",
    "    # WASHOE COUNTY TRANSFORM\n",
    "    #-------------------------------------------------------------------------------------------\n",
    "    # input/output\n",
    "    in_features = \"Parcel_WA_Extracted\"\n",
    "    parcel_out  = \"Parcel_WA_Transformed\"\n",
    "\n",
    "    # in-memory feature class\n",
    "    washoeParcels = r\"in_memory/inMemoryFeatureClass\"\n",
    "\n",
    "    # copy features to in-memory feature class\n",
    "    arcpy.CopyFeatures_management(in_features, washoeParcels)\n",
    "\n",
    "    # Add TRPA base fields\n",
    "    arcpy.management.AddFields(washoeParcels,baseFields)\n",
    "\n",
    "    # Tansform County Data to TRPA Data.\n",
    "    with arcpy.da.UpdateCursor(washoeParcels, ['APN_TRPA',              #row[0]\n",
    "                                            'PPNO_TRPA',                #row[1]\n",
    "                                            'JURISDICTION_TRPA',        #row[2]\n",
    "                                            # parcel address   \n",
    "                                            'HSE_NUMBR_TRPA',           #3\n",
    "                                            'STR_DIR_TRPA',             #4\n",
    "                                            'STR_NAME_TRPA',            #5\n",
    "                                            'STR_SUFFIX_TRPA',          #6\n",
    "                                            'UNIT_NUMBR_TRPA',          #7\n",
    "                                            'APO_ADDRESS_TRPA',         #8\n",
    "                                            'PSTL_TOWN_TRPA',           #9\n",
    "                                            'PSTL_STATE_TRPA',          #10\n",
    "                                            'PSTL_ZIP5_TRPA',           #11\n",
    "                                            # owner fields\n",
    "                                            'OWN_FIRST_TRPA',           #12\n",
    "                                            'OWN_LAST_TRPA',            #13\n",
    "                                            'OWN_FULL_TRPA',            #14\n",
    "                                            'MAIL_ADD1_TRPA',           #15\n",
    "                                            'MAIL_CITY_TRPA',           #16\n",
    "                                            'MAIL_STATE_TRPA',          #17\n",
    "                                            'MAIL_ZIP5_TRPA',           #18\n",
    "                                            # value fields  \n",
    "                                            'AS_LANDVALUE_TRPA',        #19\n",
    "                                            'AS_IMPROVALUE_TRPA',       #20\n",
    "                                            'AS_SUM_TRPA',              #21\n",
    "                                            'TAX_LANDVALUE_TRPA',       #22 \n",
    "                                            'TAX_IMPROVALUE_TRPA',      #23\n",
    "                                            'TAX_SUM_TRPA',             #24\n",
    "                                            'TAX_YEAR_TRPA',            #25\n",
    "                                            # land use fields \n",
    "                                            'COUNTY_LANDUSE_CODE_TRPA', #26\n",
    "                                            'COUNTY_LANDUSE_TRPA',      #27\n",
    "                                            # Fields for building info\n",
    "                                            \"YEAR_BUILT_TRPA\",          #28\n",
    "                                            'UNITS_TRPA',               #29\n",
    "                                            'BEDROOMS_TRPA',            #30\n",
    "                                            'BATHROOMS_TRPA',           #31\n",
    "                                            'BUILDING_SQFT_TRPA',       #32\n",
    "                                            'VHR_TRPA',                 #33\n",
    "                                            'HOA_TRPA',                 #34\n",
    "                                            ###-------------------------###\n",
    "                                            # County Fields to get data from\n",
    "                                            'PIN',   # apn              #35\n",
    "                                            'APN',   # ppno             #36\n",
    "                                            'FullAddress',#full adrress #37\n",
    "                                            'STREETNUM', # house number #38\n",
    "                                            'STREETDIR',# street dir    #39\n",
    "                                            'STREET',# street name      #40\n",
    "                                            'CITY',    # postal town    #41\n",
    "                                            'SITUSZIP', # postal zip    #42\n",
    "                                            'SQFEET',# building sqft    #43\n",
    "                                            'FIRSTNAME',# first name    #44\n",
    "                                            'LASTNAME', # last name     #45\n",
    "                                            'MAILING1',# mailing addr1  #46\n",
    "                                            'MAILING2',# mailing addr2  #47\n",
    "                                            'MAILCITY',# city           #48\n",
    "                                            'MAILSTATE', # mailing state#49\n",
    "                                            'MAILZIP',  # zip           #50\n",
    "                                            'TAXYEAR', # tax year       #51\n",
    "                                            'LAND_USE',# land use code  #52\n",
    "                                            'LANDASS',# land value      #53\n",
    "                                            'BUILDASS',# improved value #54\n",
    "                                            'TOTALASS', # total assesed #55\n",
    "                                            'LANDAPR',  # land apr      #56\n",
    "                                            'BUILDAPR', # building apr  #57\n",
    "                                            'TOTALAPR', # total apr     #58\n",
    "                                            'YEARBLT',# year built      #59\n",
    "                                            'STORIES',# stories         #60\n",
    "                                            'BEDROOMS', # bedrooms      #61      \n",
    "                                            'BATHS',# bathrooms         #62\n",
    "                                            'UNITS'   # units           #63\n",
    "    ]) as cursor:\n",
    "        # loop through each record and transform the values\n",
    "        for row in cursor:\n",
    "            # APN field\n",
    "            # Get County value\n",
    "            apn  = row[35]\n",
    "            if not (apn is None or apn == \"\" or apn.isspace() == True):\n",
    "                # set TRPA value\n",
    "                row[0] = apn\n",
    "            else:\n",
    "                row[0] = ''\n",
    "                \n",
    "            #PPNO\n",
    "            ppno = row[36]\n",
    "            if not (ppno is None or ppno == \"\"):\n",
    "                row[1] = int(ppno)\n",
    "            else:\n",
    "                row[1] = None\n",
    "                \n",
    "            # Jurisdiction\n",
    "            row[2] = \"WA\"\n",
    "                    \n",
    "            # APO Address\n",
    "            fulladdress = row[37]\n",
    "            if not (fulladdress is None or fulladdress=='' or fulladdress.isspace()==True):\n",
    "                row[8] = fulladdress\n",
    "            else:\n",
    "                row[8] = ''\n",
    "            \n",
    "            # House Number\n",
    "            house = row[38]\n",
    "            if not (house is None or house=='' or house.isspace()==True):\n",
    "                row[3] = house\n",
    "            else:\n",
    "                row[3] = ''\n",
    "                \n",
    "            \n",
    "            # Unit Number\n",
    "            if not (fulladdress is None or fulladdress == \"\"):\n",
    "                if fulladdress.strip()[-1].isdigit():\n",
    "                    if not ('STATE ROUTE 28' in fulladdress):\n",
    "                        row[7] = (fulladdress.rsplit(' ')[-1].strip())\n",
    "                    else:\n",
    "                        if not (fulladdress.strip().rsplit(' ')[-1] == '28'):\n",
    "                            row[7] = (fulladdress.rsplit(' ')[-1].strip())\n",
    "                        else:\n",
    "                            if not ('STATE ROUTE 28 28' in fulladdress): \n",
    "                                row[7] = \"\"\n",
    "                            else:\n",
    "                                row[7] = (fulladdress.rsplit(' ')[-1].strip())\n",
    "                else:\n",
    "                    if not ('US HIGHWAY 395' in fulladdress):\n",
    "                        if len(fulladdress.rsplit(' ')[-1]) == 1:\n",
    "                            row[7] = (fulladdress.rsplit(' ')[-1].strip())\n",
    "                        elif not (len(fulladdress.rsplit(' ')[-1]) == 1):\n",
    "                            if fulladdress[-2].isdigit():\n",
    "                                row[7] = (fulladdress.rsplit(' ')[-1].strip())\n",
    "                            else:\n",
    "                                row[7] = \"\"\n",
    "                        else:\n",
    "                            row[7] = \"\"\n",
    "                    else:\n",
    "                        row[7] = \"\"\n",
    "            else:\n",
    "                row[7] = \"\"\n",
    "                \n",
    "            # Street Direction\n",
    "            stdir = row[39]\n",
    "            if not (stdir is None):\n",
    "                row[4] = (stdir.strip())\n",
    "            else:\n",
    "                row[4] = \"\"\n",
    "                \n",
    "            # Street Name    \n",
    "            stname = row[40]\n",
    "            if not (stname is None or stname in ('CROSS BOW', 'ENTERPRISE', 'STATE ROUTE 28', 'UNSPECIFIED', 'US HIGHWAY 395', '')):\n",
    "                if stname[:2] in ('N ', 'S ', 'E ', 'W '):\n",
    "                    row[5] = stname.rsplit(' ',1)[0].strip().split(' ',1)[1].strip()\n",
    "                elif not (stname is None or stname == \"\" or stname.isspace() == True):\n",
    "                    row[5] = (stname.rsplit(' ',1)[0].strip())\n",
    "                #Currently the only example of this is two blanks in Incline Village with no info\n",
    "                elif stname is None or stname == \"\" or stname.isspace() == True:\n",
    "                    if fulladdress[0].isdigit():\n",
    "                        row[5] = (fulladdress.rsplit(' ')[-1].strip())\n",
    "                    else:\n",
    "                        row[5] = \"\"\n",
    "                else:\n",
    "                    logging.info(\"Error parsing washoe street name\")\n",
    "            elif stname in ('CROSS BOW', 'ENTERPRISE', 'STATE ROUTE 28', 'UNSPECIFIED', ''):\n",
    "                    row[5] = (stname.strip())\n",
    "            else:\n",
    "                row[5] = \"\"\n",
    "                \n",
    "            # Street Suffix\n",
    "            if not stname in ('CROSS BOW', 'ENTERPRISE', 'STATE ROUTE 28', 'UNSPECIFIED', 'US HIGHWAY 395', ''):\n",
    "                if not (stname is None or stname == \"\" or stname.isspace() == True):\n",
    "                    row[6] = (stname.rsplit(' ')[-1].strip())\n",
    "                elif stname is None or stname == \"\" or stname.isspace() == True:\n",
    "                    if not (fulladdress is None or fulladdress[0].isdigit()):\n",
    "                        row[6] = (fulladdress.rsplit(' ')[-1].strip())\n",
    "                    else:\n",
    "                        row[6] = \"\"\n",
    "                else:\n",
    "                    logging.info(\"Error parsing washoe street suffix\")\n",
    "            else:\n",
    "                row[11] = \"\"\n",
    "\n",
    "            # Postal Town\n",
    "            postal_town = row[41]\n",
    "            if not (postal_town is None or postal_town == '' or postal_town.isspace()==True):\n",
    "                row[9] = postal_town\n",
    "            else:\n",
    "                row[9] = ''\n",
    "                \n",
    "            # Postal State\n",
    "            row[10] = 'NV'\n",
    "            \n",
    "            # Postal Zip\n",
    "            postal_zip = row[42]\n",
    "            if not (postal_zip is None or postal_zip == '' or postal_zip.isspace()==True):\n",
    "                row[11] = postal_zip\n",
    "            else:\n",
    "                row[11] = ''\n",
    "                \n",
    "            # Owner Name\n",
    "            # set owner first name\n",
    "            ownfirst = row[44]\n",
    "            if not (ownfirst is None or ownfirst.isspace() == True):\n",
    "                row[12] = ownfirst\n",
    "            else:\n",
    "                row[12] = \"\"\n",
    "            \n",
    "            # own last\n",
    "            ownlast = row[45]\n",
    "            if not (ownlast is None or ownlast.isspace() == True):\n",
    "                row[13] = ownlast\n",
    "            else:\n",
    "                row[13] = \"\"\n",
    "            \n",
    "            # own full\n",
    "            if not (ownfirst is None and ownlast is None):\n",
    "                row[14] = (ownfirst + \" \" + ownlast).strip()\n",
    "            else:\n",
    "                row[14] = \"\"\n",
    "                \n",
    "            # Mailing Address\n",
    "            if not (row[46] is None):  \n",
    "                address1 = row[46].strip()\n",
    "            if not (row[47] is None):\n",
    "                address2 = row[47].strip()\n",
    "            if not (address1 is None or address1=='' or address1.isspace()==True):\n",
    "                row[15] = str((address1 + \" \" + address2).strip())\n",
    "            elif (address2 is None):\n",
    "                row[15] = address1\n",
    "            else:\n",
    "                row[15] = ''\n",
    "            \n",
    "            # Mailing City\n",
    "            mail_city = row[48]\n",
    "            if not (mail_city is None or mail_city=='' or mail_city.isspace()==True):\n",
    "                row[16] = mail_city\n",
    "            else:\n",
    "                row[16] = ''\n",
    "                \n",
    "            # Mailing State\n",
    "            mail_state = row[49]\n",
    "            if not (mail_state is None or mail_state=='' or mail_state.isspace()==True):\n",
    "                row[17] = mail_state\n",
    "            else:\n",
    "                row[17] = ''\n",
    "            \n",
    "            # Mailing Zipcode\n",
    "            if not (row[50] is None):\n",
    "                mail_zip = row[50].strip()\n",
    "            if not (mail_zip is None or mail_zip=='' or mail_zip.isspace()==True):\n",
    "                row[18] = mail_zip[:5]\n",
    "            else:\n",
    "                row[18] = ''\n",
    "                \n",
    "            # Assessement Value\n",
    "            land_value = row[53]\n",
    "            if not(land_value is None or land_value==''):\n",
    "                row[19] = land_value\n",
    "            else:\n",
    "                row[19] = None\n",
    "            \n",
    "            improved_value = row[54]\n",
    "            if not (improved_value is None or improved_value==''):\n",
    "                row[20] = improved_value\n",
    "            else:\n",
    "                row[20] = None\n",
    "                    \n",
    "            assessed_sum = row[55]\n",
    "            if not (assessed_sum is None or assessed_sum==''):\n",
    "                row[21] = assessed_sum\n",
    "            else:\n",
    "                row[21] = None\n",
    "            \n",
    "            # Tax Value\n",
    "            taxland_value = row[56]\n",
    "            if not(taxland_value is None or taxland_value==''):\n",
    "                row[22] = taxland_value\n",
    "            else:\n",
    "                row[22] = None\n",
    "            \n",
    "            taximproved_value = row[57]\n",
    "            if not (taximproved_value is None or taximproved_value==''):\n",
    "                row[23] = taximproved_value\n",
    "            else:\n",
    "                row[23] = None\n",
    "            \n",
    "            tax_sum = row[58]\n",
    "            if not (tax_sum is None or tax_sum==''):\n",
    "                row[24] = tax_sum\n",
    "            else:\n",
    "                row[24] = None\n",
    "            \n",
    "            # Tax Year\n",
    "            tax_year = row[51]\n",
    "            if not (tax_year is None or tax_year=='' or tax_year.isspace()==True):\n",
    "                row[25] = tax_year\n",
    "            else:\n",
    "                row[25] = None\n",
    "                \n",
    "            # County Land Use Code\n",
    "            county_luc = row[52]\n",
    "            if not (county_luc is None or county_luc=='' or county_luc.isspace()==True):\n",
    "                row[26] = int(county_luc.split(\",\",1)[0].strip())\n",
    "            else:\n",
    "                row[26] = None \n",
    "            \n",
    "            # Year Built\n",
    "            year_built = row[59]\n",
    "            if not (year_built is None or year_built==''):\n",
    "                row[28] = year_built\n",
    "            else:\n",
    "                row[28] = None\n",
    "                \n",
    "            # Units\n",
    "            units = row[63]\n",
    "            if not (units is None or units==''):\n",
    "                row[29] = int(units)\n",
    "            else:\n",
    "                row[29] = None\n",
    "            \n",
    "            # Bedrooms\n",
    "            bedrooms = row[61]\n",
    "            if not (bedrooms is None or bedrooms==''):\n",
    "                row[30] = bedrooms\n",
    "            else:\n",
    "                row[30] = None\n",
    "            \n",
    "            # Bathrooms\n",
    "            bathrooms = row[62]\n",
    "            if not (bathrooms is None or bathrooms==''):\n",
    "                row[31] = bathrooms\n",
    "            else:\n",
    "                row[31] = None\n",
    "                \n",
    "            # Building Square Feet\n",
    "            building_sqft = row[43]\n",
    "            if not (building_sqft is None or building_sqft==''):\n",
    "                row[32] = building_sqft\n",
    "            else:\n",
    "                row[32] = None\n",
    "\n",
    "            # Update the row.\n",
    "            cursor.updateRow(row)\n",
    "    del cursor\n",
    "\n",
    "    # create a spatial reference object for the output coordinate system \n",
    "    out_coordinate_system = arcpy.SpatialReference('NAD 1983 UTM Zone 10N') \n",
    "    arcpy.Project_management(washoeParcels, parcel_out, out_coordinate_system)\n",
    "\n",
    "    print('New Washoe Parcels transformed')\n",
    "    logger.info('New Washoe Parcels Transformed')\n",
    "    #--------------------------------------\n",
    "    # MERGE\n",
    "    #--------------------------------------\n",
    "    # delete in-memory\n",
    "    arcpy.Delete_management(\"memory\")\n",
    "    print(\"Deleted Memory Workspace: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    logger.info('Deleted Memory Workspace')\n",
    "    # out merge fc\n",
    "    parcel_out = \"Parcel_Staging\"\n",
    "\n",
    "    # input feature classes\n",
    "    ccParcel = \"Parcel_CC_Transformed\"\n",
    "    dgParcel = \"Parcel_DG_Transformed\"\n",
    "    elParcel = \"Parcel_EL_Transformed\"\n",
    "    plParcel = \"Parcel_PL_Transformed\"\n",
    "    waParcel = \"Parcel_WA_Transformed\"\n",
    "\n",
    "    # Create FieldMappings object to manage merge output fields\n",
    "    fieldMappings = arcpy.FieldMappings()\n",
    "    # Add all fields from all parcel staging layers\n",
    "    fieldMappings.addTable(ccParcel)\n",
    "    fieldMappings.addTable(dgParcel)\n",
    "    fieldMappings.addTable(elParcel)\n",
    "    fieldMappings.addTable(plParcel)\n",
    "    fieldMappings.addTable(waParcel)\n",
    "\n",
    "    # Remove all output fields from the field mappings, except fields in field_master list\n",
    "    for field in fieldMappings.fields:\n",
    "        if field.name not in [  'OBJECTID',\n",
    "                                'APN_TRPA',                 #0\n",
    "                                'PPNO_TRPA',                #1\n",
    "                                'JURISDICTION_TRPA',        #2\n",
    "                                'COUNTY_TRPA',\n",
    "                                # parcel address   \n",
    "                                'HSE_NUMBR_TRPA',           #3\n",
    "                                'STR_DIR_TRPA',             #4\n",
    "                                'STR_NAME_TRPA',            #5\n",
    "                                'STR_SUFFIX_TRPA',          #6\n",
    "                                'UNIT_NUMBR_TRPA',          #7\n",
    "                                'APO_ADDRESS_TRPA',         #8\n",
    "                                'PSTL_TOWN_TRPA',           #9\n",
    "                                'PSTL_STATE_TRPA',          #10\n",
    "                                'PSTL_ZIP5_TRPA',           #11\n",
    "                                # owner fields\n",
    "                                'OWN_FIRST_TRPA',           #12\n",
    "                                'OWN_LAST_TRPA',            #13\n",
    "                                'OWN_FULL_TRPA',            #14\n",
    "                                'MAIL_ADD1_TRPA',           #15\n",
    "                                'MAIL_CITY_TRPA',           #16\n",
    "                                'MAIL_STATE_TRPA',          #17\n",
    "                                'MAIL_ZIP5_TRPA',           #18\n",
    "                                # value fields  \n",
    "                                'AS_LANDVALUE_TRPA',        #19\n",
    "                                'AS_IMPROVALUE_TRPA',       #20\n",
    "                                'AS_SUM_TRPA',              #21\n",
    "                                'TAX_LANDVALUE_TRPA',       #22 \n",
    "                                'TAX_IMPROVALUE_TRPA',      #23\n",
    "                                'TAX_SUM_TRPA',             #24\n",
    "                                'TAX_YEAR_TRPA',            #25\n",
    "                                # land use fields \n",
    "                                'COUNTY_LANDUSE_CODE_TRPA', #26\n",
    "                                'COUNTY_LANDUSE_TRPA',      #27\n",
    "                                # Fields for building info\n",
    "                                \"YEAR_BUILT_TRPA\",          #28\n",
    "                                'UNITS_TRPA',               #29\n",
    "                                'BEDROOMS_TRPA',            #30\n",
    "                                'BATHROOMS_TRPA',           #31\n",
    "                                'BUILDING_SQFT_TRPA',       #32\n",
    "                                'VHR_TRPA',                 #33\n",
    "                                'HOA_TRPA',                 #34\n",
    "                                'SHAPE@']:\n",
    "            # remove everything else\n",
    "            fieldMappings.removeFieldMap(fieldMappings.findFieldMapIndex(field.name)) \n",
    "        \n",
    "    # Use Merge tool to move features into single dataset\n",
    "    arcpy.management.Merge([ccParcel, dgParcel, elParcel, plParcel, waParcel ], parcel_out, fieldMappings)\n",
    "    print(\"Transformed Parcel Datasets Merged\")\n",
    "    logger.info(\"Transformed Parcel Datasets Merged\")\n",
    "    # out merge fc\n",
    "    parcel_out = \"Parcel_Staging\"\n",
    "    result = arcpy.GetCount_management(parcel_out)\n",
    "    print('{} has {} records'.format(parcel_out, result[0]))\n",
    "    logger.info(f'{parcel_out} has {result[0]} records')\n",
    "    # out merge fc\n",
    "    parcel_out = \"Parcel_Staging\"\n",
    "\n",
    "    # delete unneccesary parcels\n",
    "    parcelDelete = \"ParcelDelete\"\n",
    "\n",
    "    # Run MakeFeatureLayer\n",
    "    arcpy.management.MakeFeatureLayer(parcel_out, parcelDelete)\n",
    "    \n",
    "    arcpy.management.SelectLayerByAttribute(parcelDelete, 'NEW_SELECTION', \n",
    "                                            \"APN_TRPA = '' Or APN_TRPA LIKE '920%' Or APN_TRPA LIKE '910%' OR APN_TRPA LIKE '%NP%' OR APN_TRPA LIKE '%ROW%' OR APN_TRPA LIKE '%UN%'\")\n",
    "\n",
    "    # Run GetCount and if some features have been selected, then \n",
    "    #  run DeleteFeatures to remove the selected features.\n",
    "    deleteCount = arcpy.management.GetCount(parcelDelete)[0]\n",
    "    if int(deleteCount) > 0:\n",
    "        arcpy.management.DeleteFeatures(parcelDelete)\n",
    "        print('{} records deleted'.format(deleteCount))\n",
    "        logger.info(f'{deleteCount} records deleted')\n",
    "    result = arcpy.GetCount_management(parcel_out)\n",
    "    print('{} has {} records now.'.format(parcel_out, result[0]))\n",
    "    logger.info(f'{parcel_out} has {result[0]} records now')\n",
    "    #------------------------------------------------------\n",
    "    # ADDITIONAL TRANSFORMATION\n",
    "    #------------------------------------------------------\n",
    "\n",
    "\n",
    "    suffix_dict = {\n",
    "        'CI':'CIR',\n",
    "        'BL':'BLVD',\n",
    "        'TR':'TRL',\n",
    "        'WY':'WAY',\n",
    "        'E': '',\n",
    "        'L':'',\n",
    "        'AV':'AVE',\n",
    "        'LP':'LOOP',\n",
    "        'HY':'HWY',\n",
    "        'PY':'PKWY',\n",
    "        'PKY':'PKWY',\n",
    "        'DRIVE': 'DR'\n",
    "    }\n",
    "\n",
    "    suffix_field = ['STR_SUFFIX_TRPA']\n",
    "\n",
    "    UpdateFieldFromDictionary('Parcel_Staging', suffix_field, suffix_dict)\n",
    "\n",
    "    replacement_values = ['UNIT','SUITE','SPACE','NULL']\n",
    "    set_to_blank_values = ['0', '0 NULL']\n",
    "\n",
    "    with arcpy.da.UpdateCursor('Parcel_Staging', [\"STR_NAME_TRPA\"]) as cursor:\n",
    "        for row in cursor:\n",
    "            if not row[0] is None:\n",
    "                row[0]=row[0].upper()\n",
    "            else:\n",
    "                row[0] = ''      \n",
    "            for replacement_value in replacement_values:\n",
    "                row[0] = row[0].replace(replacement_value, '')\n",
    "            row[0] = row[0].replace('  ', ' ')\n",
    "            if row[0] in set_to_blank_values:\n",
    "                row[0]=''\n",
    "            if row[0].startswith('0 '):\n",
    "                row[0]=row[0][2:]\n",
    "            if (row[0] == '0 NO ADDRESS ON FILE')| (row[0] == 'NO ADDRESS ON FILE'):\n",
    "                NewStreet='NO ADDRESS ON FILE'\n",
    "                \n",
    "            cursor.updateRow(row)\n",
    "\n",
    "    #----------------------------------------------------------------------------------\n",
    "    # TRPA ATTRIBUTION\n",
    "    #----------------------------------------------------------------------------------\n",
    "    print(\"Starting TRPA Attribution: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    logger.info(\"Starting TRPA Attribution\")\n",
    "    # log.info(\"Starting TRPA Attribution: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "    # in and out with the same name overwrite == True\n",
    "    ParcelStaging = \"Parcel_Staging\"\n",
    "    ParcelPoint   = \"Parcel_Point\"\n",
    "    ParcelNew     = 'Parcel_Staging_Attributed'\n",
    "\n",
    "    # copy data into an in_memory feature class for warp speed.\n",
    "    ParcelLayer = r\"memory/ParcelLayer\"\n",
    "    arcpy.CopyFeatures_management(ParcelStaging, ParcelLayer)\n",
    "\n",
    "    # Add TRPA fields.\n",
    "    arcpy.management.AddFields(ParcelLayer,trpaFields)\n",
    "\n",
    "    # ### County Atribute Update -------------------------------------------------------------------------------------###\n",
    "\n",
    "    print(\"Starting the County attribute update: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    # log.info(\"Starting the County attribute update: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "    with arcpy.da.UpdateCursor(ParcelLayer, [\"JURISDICTION_TRPA\", \"COUNTY_TRPA\"]) as cursor:\n",
    "        for row in cursor:\n",
    "            # set county field before changing EL to CSLT in Jurisdiction field\n",
    "            row[1] = row[0] \n",
    "            cursor.updateRow(row)\n",
    "    del cursor\n",
    "    print(\"County Attribute Updated\")\n",
    "\n",
    "    #### Featurs to Points to use in speedy spatial joins\n",
    "    # copy shapes to points in new parcel point layer\n",
    "    arcpy.FeatureToPoint_management(ParcelLayer, ParcelPoint, \"INSIDE\")\n",
    "    print(\"Copied features to points: \"+ strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    # log.info(\"Copied features to points: \"+ strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "    ### Ownership Type Attribute Update ------------------------------------------------------------------------------###\n",
    "    print(\"Starting the Ownership Type attribute update: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    # log.info(\"Starting the Ownership Type attribute update: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "    # owner name lists - this is a stupid way to figure this out\n",
    "    fedOwnList = (\"UNITED STATES OF AMERICA C/O USDA FOREST SERVICE\",\"USA FOREST SERVICE\", \n",
    "                \"USDA FOREST SERVICE\", \"USDA - FOREST SERVICE\", \"UNITED STATES POSTAL\", \n",
    "                \"UNITED STATES OF AMERICA\", \"UNITED STATES FOREST SERVICE\", \"U S POSTAL SERVICE\", \"U S COAST GUARD\",\n",
    "                \"U S A FOREST SERVICE``\", \"U S A FOREST SERVICE\", \"LAKE VALLEY RANGER STA\", \"DEPT OF VETRANS AFFAIRS%\", \n",
    "                \"DEPT OF VETERANS AFFAIRS%\", \"DEPT OF VETERANS AFFAIRS %\", \"BUREAU OF LAND MANAGEMENT\", \"U S FOREST SERVICE\",\n",
    "                \"DEPT OF VETERANS AFFAIRS  & ERSKINE NEIL H TR\", \"DEPT OF VETERANS AFFAIRS  & MASTERS DANE C\", \n",
    "                \"DEPT OF VETERANS AFFAIRS  & SLEZAK FRANK J CO TR\", \"DEPT OF VETERANS AFFAIRS & RIVES DONALD E JR\"\n",
    "                \"DEPT OF VETERANS AFFAIRS & WILLIAMS MATTHEW G DBA WILLIAMS VACATION HOME\", \"DEPT OF VETRANS AFFAIRS & WILSON VIVIAN M\",\n",
    "                \"DEPARTMENT OF TRANSPORTATION\", \"USA FOREST SERVICE & OWNERSHIP UNVERIFIED\", \"U S A FOREST SERVICE & LAKE TAHOE BASIN MNGMT UNIT\",\n",
    "                \"U S A FOREST SERVICE & OWNERSHIP UNVERIFIED\", \"U S D A FOREST SERVICE\", \"UNITED STATES & DEPT OF AGRICULTURE\",\n",
    "                \"UNITED STATES OF AMERICA & ATTN RICHARD T FLYNN\", \"UNITED STATES OF AMERICA & DEPARTMENT OF AGRICULTU\", \"UNITED STATES OF AMERICA & F/S DEPT OF AGRICULTURE\",\n",
    "                \"UNITED STATES OF AMERICA & FOREST SER. DEPT OF AG.\", \"UNITED STATES OF AMERICA & FOREST SERVICE\", \"UNITED STATES OF AMERICA & FOREST SERVICE (USDA)\",\n",
    "                \"UNITED STATES OF AMERICA & FOREST SERVICE DEPT OF\", \"UNITED STATES OF AMERICA & FOREST SERVICE TAHOE BA\", \"UNITED STATES OF AMERICA & FOREST SERVICE USDA\",\n",
    "                \"UNITED STATES OF AMERICA & FOREST SVC/DEPT OF AGRI\", \"UNITED STATES OF AMERICA & LAKE TAHOE BASIN MANAGM\",\n",
    "                \"UNITED STATES OF AMERICA & LAKE TAHOE BASIN MGT UN\", \"UNITED STATES OF AMERICA & REGIONAL LAND ADJUSTMEN\",\n",
    "                \"UNITED STATES OF AMERICA & U S FOREST SERVICE\", \"UNITED STATES OF AMERICA & U S FOREST SERVIE\",\n",
    "                \"UNITED STATES OF AMERICA & USDA FOREST SER LAKE TA\", \"UNITED STATES OF AMERICA & USDA FOREST SERVICE\",\n",
    "                \"USDA - FOREST SERVICE & LAKE TAHOE BASIN MGMT UNIT\")\n",
    "\n",
    "    stateOwnList = (\"TAHOE CONSERVANCY\", \"STATE OF NEVADA FOREST SERVICE\", \"STATE OF NEVADA\", \"STATE OF CALIFORNIA THE\", \n",
    "                    \"STATE OF CALIFORNIA (EASEMENT)\", \"STATE OF CALIFORNIA\", \"STATE OF CA\", \"REGENTS OF UNIV OF CALIF\",\n",
    "                    \"UNIVERSITY CALIFORNIA REGENTS\", \"UNIVERSITY OF NEVADA RENO\", \"NEVADA, STATE OF\", \"NEVADA STATE OF\", \n",
    "                    \"CALIFORNIA TAHOE CONSERVANCY ET AL\", \"CALIFORNIA TAHOE CONSERVANCY\", \"CALIFORNIA STATE OF THE\", \n",
    "                    \"CALIFORNIA STATE OF ET AL\", \"CALIFORNIA STATE OF\", \"CA STATE DEPT TRANSPORTATION\", \n",
    "                    \"CA TAHOE CONSERVANCY\", \"CALIFORNIA STATE OF TAHOE CONSERVANCY\", \"CALIFORNIA STATE OF THE\", \n",
    "                    \"NEVADA DEPT OF TRANSPORTATION\", \"STATE OF CALIFORNIA & CALIFORNIA TAHOE CONSERVANCY\", \"STATE OF CALIFORIA & CALIFORNIA TAHOE CONSERVANCY\",\n",
    "                    \"STATE OF CALIFORNIA & CA TAHOE CONSERVANCY\", \"STATE OF CALIFORNIA & CALIFORNIA TAHOE CONSERVANCY CALIFORNIA TAHOE CONSERVANCY\",\n",
    "                    \"STATE OF CALIFORNIA & CALIFORNIA TAHOE CONSEVANCY\", \"STATE OF CALIFORNIA & DEPART OF TRANSPORTATION\", \"STATE OF CALIFORNIA & DEPARTMENT OF GENERAL SERVIC\", \n",
    "                    \"STATE OF CALIFORNIA & DEPARTMENT OF TRANSPORTATION\", \"STATE OF CALIFORNIA & DEPT OF GEN SRVS R E DIV\", \"STATE OF CALIFORNIA & DEPT OF GENERAL SERVICES\",\n",
    "                    \"STATE OF CALIFORNIA & DEPT OF PARKS & RECREATION\", \"STATE OF CALIFORNIA & DEPT OF TRANSPORTATION\", \"STATE OF CALIFORNIA & PARKS & RECREATION\",\n",
    "                    \"STATE OF CALIFORNIA (EASEMENT) & CALIFORNIA TAHOE\", \"CALIFORNIA STATE PARKS AND RECREATION\",\n",
    "                    \"CALIFORNIA STATE OF & DEPT GEN SERVICES REAL ESTAT\")\n",
    "\n",
    "    localOwnList = (\"ZEPHYR COVE GENERAL IMP DIST\", \"WASHOE COUNTY SCHOOL DISTRICT BOARD\", \"WASHOE COUNTY\", \"WASHOE TRIBE OF NV & CA\", \n",
    "                    \"TALMONT RESORT IMPROVEMENT DISTRICT\", \"TALMONT RESORT IMPR DIST\", \"TALMONT RESORT IMP DISTRICT\",\n",
    "                    \"TALMONT RESORT IMP DIST\", \"TAHOE PARADISE RESORT IMP DIST\", \"TAHOE PARADISE RES IMP DST\",\n",
    "                    \"TAHOE FOREST HOSPITAL DISTRICT\", \"TAHOE TRUCKEE UNIFIED SCHOOL DISTRICT\", \"TAHOE TRUCKEE UNIFIED SCH DIST\", \n",
    "                    \"TAHOE DOUGLAS FIRE PROTECT DIST\", \"TAHOE DOUGLAS SEWER DIST\", \"TAHOE DOUGLAS DISTRICT\", \n",
    "                    \"TAHOE CITY PUBLIC UTILITY DISTRICT\", \"TAHOE CITY PUBLIC UTILITY DIST\", \"TAHOE CITY PUBLIC UTILDIST\", \n",
    "                    \"TAHOE CITY PUB UTILITY DST\", \"TAHOE CITY PUB UTILITY DIS\", \"TAHOE CITY P U D\", \"TAHOE CITY CEMETERY DIST\", \n",
    "                    \"SOUTH TAHOE REDEVELP AGENCY\", \"SOUTH TAHOE REFUSE CO\", \"SOUTH TAHOE PUD\", \"SOUTH TAHOE PUBLIC UTL DST\",\n",
    "                    \"SOUTH TAHOE PUBLIC UTILITYDIST\", \"SOUTH TAHOE PUBLIC UTILITY DST\", \"SOUTH TAHOE PUBLIC UTILITY DIS\", \n",
    "                    \"SOUTH TAHOE PUBLIC UTILITY\", \"SOUTH TAHOE PUBLIC UTIL DT\", \"SOUTH TAHOE PUBLIC UTIL DIST\", \n",
    "                    \"SOUTH TAHOE PUBLIC\", \"SOUTH TAHOE PUB UTIL DIST\", \"SOUTH LAKE TAHOE CTYOF 1/3\", \"SOUTH LAKE TAHOE CITY OF\", \n",
    "                    \"SO TAHOE PUBLIC UTILITY DIST\", \"SO TAHOE PUB UTIL DIST\", \"SIERRA NEVADA COLLEGE\", \"ROUND HILL GEN IMP DIST\",\n",
    "                    \"PLACER COUNTY REDEVELOPMENT AGENCY\", \"PLACER COUNTY OF\", \"PLACER COUNTY\", \"NORTH TAHOE PUBLIC UTL DIST\",\n",
    "                    \"NORTH TAHOE PUBLIC UTILITY DISTRICT\", \"NORTH TAHOE PUBLIC UTILITY DIST\", \"NORTH TAHOE PUBLIC UTILITY DIS\", \n",
    "                    \"NORTH TAHOE PUBLIC UTILITIES DIST\", \"NORTH TAHOE PUBLIC UTILIITY DISTRICT\", \"NORTH TAHOE P U D\",\n",
    "                    \"NORTH TAHOE FIRE PROTECTION DISTRICT\", \"NORTH TAHOE FIRE PROTECTION\", \"NORTH TAHOE FIRE DIST\",\n",
    "                    \"NORTH LAKE TAHOE FIRE PROTECTION DIST\", \"N TAHOE FIRE PROTECTION DIST\", \"MEEKS BAY FIRE PROT DIST\", \n",
    "                    \"LAKERIDGE GENERAL IMP DIST\", \"LAKE VALLEY FIRE PROTECTION\", \"LAKE VALLEY FIRE PROT DST\", \"LAKE VALLEY FIRE PROT DIST\", \n",
    "                    \"LAKE VALLEY FIRE DISTRICT\", \"LAKE TAHOE UNIFIED SCHOOL DIST\", \"LAKE TAHOE SCHOOL\", \"LAKERIDGE GENERAL IMP DIST\", \n",
    "                    \"LAKE TAHOE FIRE PROTECTION DIST\", \"LAKE TAHOE FIRE PROTECT DIST\", \"LAKE TAHOE COMM COLLEGE DIST\",\n",
    "                    \"LAKE TAHOE COMM COL DIST\", \"KINGSBURY GENERAL IMP DISTRICT\", \"KINGSBURY GENERAL IMP DIST\",\n",
    "                    \"INCLINE VILLAGE GENERAL IMPROVEMENT DISTRICT\", \"INCLINE VILLAGE GENERAL IMPROVEMENT DIST\", \n",
    "                    \"DOUGLAS COUNTY SEWER DIST\", \"DOUGLAS COUNTY SCHOOL DIST\", \"DOUGLAS COUNTY\", \"DOUGLAS CO SEWER IMP DIST #1\", \n",
    "                    \"COUNTY OF EL DORADO\", \"CITY OF SOUTH LAKE TAHOE\", \"EL DORADO IRRIGATION DISTRICT\", \n",
    "                    \"HAPPY HOMESTEAD CEMETERY DIST\", \"WASHOE TRIBE\", \"SOUTHTAHOE PUBLIC UTILITY DIST\", \"DOUGLAS COUNTY TRUSTEE\", \n",
    "                    \"DOUGLAS COUNTY TRUSTEE (HOLD)\", \"WASHOE TRIBE OF NEVADA AND CALIFORNIA\", \"ALPINE SPRINGS CO WATER DIST\", \n",
    "                    \"ALPINE SPRINGS COUNTY WATER DISTRICT\", \"ALPINE SPRINGS WATER DISTRICT\", \"NORTHSTAR COMMUNITY SERVICE DISTRICT\",\n",
    "                    \"SQUAW VALLEY CO WATER DIST\", \"SQUAW VALLEY PUBLIC SERVICE DISTRICT\", \"TRUCKEE TAHOE AIRPORT DISTRICT\", \n",
    "                    \"COUNTY OF EL DORADO & ATTEN: PAUL MCINTOSH\", \"COUNTY OF EL DORADO & BOARD OF SUPERVISORS\", \n",
    "                    \"COUNTY OF EL DORADO & BOARD OF SUPERVISORS\", \"COUNTY OF EL DORADO & C/O BOARD OF SUPERVISORS\", \"COUNTY OF EL DORADO & COUNSEL\",\n",
    "                    \"COUNTY OF EL DORADO & COUNSEL'S OFFICE\", \"COUNTY OF EL DORADO & DEPARTMENT OF PUBLIC WORKS\", \"COUNTY OF EL DORADO & DEPARTMENT OF TRANSPORTATION\",\n",
    "                    \"COUNTY OF EL DORADO & DEPT OF PUBLIC WORKS\", \"COUNTY OF EL DORADO & DEPT OF TRANSPORTATION\", \"COUNTY OF EL DORADO & GENERAL SERVICES DEPARTMENT\",\n",
    "                    \"COUNTY OF EL DORADO & OF EL DORADO\", \"COUNTY OF EL DORADO & PUBLIC WORKS DEPARTMENT\", \"EL DORADO CO OFFICE EDUCATION\", \"EL DORADO COUNTY & SUPERINTENDENT OF SCHOOLS\",\n",
    "                    \"EL DORADO COUNTY & BOARD OF SUPERVISORS\", \"LAKE TAHOE COMMUNITY COLLEGE DIST\", \"LAKE VALLEY RANGER STA & U S FOREST SERVICE\",\n",
    "                    \"LAKE VALLEY FIRE PROTECTION & DISTRICT POLITICAL S\", \"SOUTH TAHOE PUBLIC & UTILITY DISTRICT\",\n",
    "                    \"SOUTH TAHOE PUBLIC UTILITY &  DISTRIC\", \"SOUTH TAHOE PUBLIC UTIL DIST & CA MUNICIPAL CORP\", \"TAHOE CITY PUBLIC UTIL DST\",\n",
    "                    \"TAHOE RESOURCE CONSERVATION &  DISTRIC\", \"TAHOE RESOURCE CONSERVATION DIST  C/O DISTRICT MANAGER\", \"FALLEN LEAF COMM SERVICES DIST\",\n",
    "                    \"FALLEN LEAF LAKE COMM SERVDIST\", \"TAHOE DOUGLAS VISITORS AUTH\", \"KINGSBURY GENARAL IMP DIST\", \"ALPINE SPRINGS CO WTR DIST FIN CORP\",\n",
    "                    \"COUNTY OF PLACER\", \"MCKINNEY WATER DISTRICT\", \"NORTHSTAR COMMUNITY SERVICES DISTRICT\", \"PLACER COUNTY PUBLIC WORKS\",\n",
    "                    \"REDEVELOPMENT AGENCY OF THE COUNTY OF PL\", \"TRUCKEE DONNER PUBLIC UTILITY DISTRICT\", \"TRUCKEE SANITARY DISTRICT\",\n",
    "                    \"TAHOE TRANSPORTATION DISTRICT\") \n",
    "\n",
    "    with arcpy.da.UpdateCursor(ParcelLayer, [\"OWN_FULL_TRPA\", \"OWNERSHIP_TYPE_TRPA\"]) as cursor:\n",
    "        for row in cursor:\n",
    "            # set ownership type\n",
    "            own = row[0]\n",
    "            if not (own is None or own == \"\" or own.isspace() == True):\n",
    "                if own in fedOwnList:\n",
    "                    row[1] = \"Federal\"\n",
    "                elif own in localOwnList:\n",
    "                    row[1] = \"Local\"\n",
    "                elif own in stateOwnList:\n",
    "                    row[1] = \"State\"\n",
    "                elif not own in (fedOwnList, localOwnList, stateOwnList):\n",
    "                    row[1] = \"Private\" \n",
    "                cursor.updateRow(row)\n",
    "    del cursor\n",
    "    print (\"The 'OWNERSHIP_TYPE' field in the parcel data has been updated\")\n",
    "    # log.info(\"The 'Owernshipe Type' field in the parcel data has been updated\")\n",
    "\n",
    "    ### Existing Landuse Attribute Update ----------------------------------------------------------------------------###\n",
    "    fields = (\"COUNTY_LANDUSE_CODE_TRPA\",\n",
    "            \"COUNTY_LANDUSE_TRPA\",  \n",
    "            \"EXISTING_LANDUSE_TRPA\", \n",
    "            'JURISDICTION_TRPA')\n",
    "\n",
    "    with arcpy.da.UpdateCursor(ParcelLayer, fields) as cursor:\n",
    "        for row in cursor:\n",
    "            ctyluc = str(row[0])\n",
    "            cty = row[3]\n",
    "            # set Washoe county land use\n",
    "            # set TRPA Land Use Description\n",
    "            if (row[0] != None or row[0] != \"\") and (row[3] == 'WA'):\n",
    "                if ctyluc in ('400', '410', '440', '500', '510', '520', '630', '640', '670', '720'):\n",
    "                    row[2] = \"Commercial\"\n",
    "                elif ctyluc in ('210', '250'):\n",
    "                    row[2] = \"Condominium\"\n",
    "                elif ctyluc in ('240'):\n",
    "                    row[2] = \"Condominium Common Area\"\n",
    "                elif ctyluc in ('220', '230', '300', '310', '320', '330', '340', '350', '360'):\n",
    "                    row[2] = \"Multi-Family Residential\"\n",
    "                elif ctyluc in ('600', '620'):\n",
    "                    row[2] = \"Open Space\"\n",
    "                elif ctyluc in ('700', '710', 'PBRD'):\n",
    "                    row[2] = \"Public Service\"\n",
    "                elif ctyluc in ('190'):\n",
    "                    row[2] = \"Recreation\"\n",
    "                elif ctyluc in ('200'):\n",
    "                    row[2] = \"Single Family Residential\"     \n",
    "                elif ctyluc in ('420', '430'):\n",
    "                    row[2] = \"Tourist Accommodation\"\n",
    "                elif ctyluc in ('100', '110', '120', '130', '140', '150', '160', '170', '180'):\n",
    "                    row[2] = \"Vacant\"            \n",
    "                elif ctyluc is None:\n",
    "                    row[2] == ''\n",
    "            if (row[0] != None or row[0] != \"\") and (row[3] == 'WA'):\n",
    "                if ctyluc in ('710'):\n",
    "                    row[1] = \"Intracounty public utility\"\n",
    "                elif ctyluc == '700':\n",
    "                    row[1] = 'Centrally assessed public utility'\n",
    "                elif ctyluc == '510':\n",
    "                    row[1] = 'Commercial Industrial: retail or office with Indus'\n",
    "                elif ctyluc == '500':\n",
    "                    row[1] = 'General industrial: light indust, trucking, warehs'\n",
    "                elif ctyluc == '440':\n",
    "                    row[1] = 'Resort commercial: ski, golf, sports, etc.'\n",
    "                elif ctyluc == '430':\n",
    "                    row[1] = 'Commercial hotel or motel'\n",
    "                elif ctyluc == '420':\n",
    "                    row[1] = 'Casino or hotel casino'\n",
    "                elif ctyluc == '410':\n",
    "                    row[1] = 'Offices, professional and business, banks, etc.'\n",
    "                elif ctyluc == '400':\n",
    "                    row[1] = 'General Commercial: retail, mixed, parking, school'\n",
    "                elif ctyluc == '340':\n",
    "                    row[1] = 'Ten or more units'\n",
    "                elif ctyluc == '330':\n",
    "                    row[1] = 'Five to Nine Units'\n",
    "                elif ctyluc == '320':\n",
    "                    row[1] = 'Three or four Units'\n",
    "                elif ctyluc == '310':\n",
    "                    row[1] = 'Two Single Family Units'\n",
    "                elif ctyluc == '300':\n",
    "                    row[1] = 'Duplex'\n",
    "                elif ctyluc == '250':\n",
    "                    row[1] = 'Condo or Townhouse valued as apartment use'\n",
    "                elif ctyluc == '240':\n",
    "                    row[1] = 'Common Area'\n",
    "                elif ctyluc == '210':\n",
    "                    row[1] = 'Condominium or Townhouse'\n",
    "                elif ctyluc == '200':\n",
    "                    row[1] = 'Single Family Residence'\n",
    "                elif ctyluc == '190':\n",
    "                    row[1] = 'Public Parks: vacant or improved'\n",
    "                elif ctyluc == '170':\n",
    "                    row[1] = 'Other, unbuildable: roads, restrictions, terrain'\n",
    "                elif ctyluc == '160':\n",
    "                    row[1] = 'Splinter, unbuildable: small size or shape'\n",
    "                elif ctyluc == '140':\n",
    "                    row[1] = 'Vacant, commercial'\n",
    "                elif ctyluc == '130':\n",
    "                    row[1] = 'Vacant, multi-residential'\n",
    "                elif ctyluc == '120':\n",
    "                    row[1] = 'Vacant, single family'\n",
    "                elif ctyluc == '110':\n",
    "                    row[1] = 'Vacant, under development'\n",
    "                elif ctyluc == '100':\n",
    "                    row[1] = 'Vacant, other or unknown'            \n",
    "                elif ctyluc is None:\n",
    "                    row[1] == ''\n",
    "                cursor.updateRow(row)\n",
    "            # Set Carson City County Land Use Descriptions\n",
    "            if (row[0] != None or row[0] != \"\") and (row[3] == 'CC'):\n",
    "                if ctyluc in ('400', '401', '402', '403', '404', '408', '410', '411', \n",
    "                            '412', '440', '441', '460', '470', '480', '482', '490', \n",
    "                            '500', '501', '510', '511', '512', '513', '520', '521', \n",
    "                            '560', '570', '580', '582', '590', '624', '625', '694', \n",
    "                            '800', '820', '830', '840', '880', '882', '890', '920', \n",
    "                            '921', '930', '960', '980', '990'):\n",
    "                    row[2] = \"Commercial\"\n",
    "                elif ctyluc in ('210', '211'):\n",
    "                    row[2] = \"Condominium\"\n",
    "                elif ctyluc == '970':\n",
    "                    row[2] = \"Condominium Common Area\"\n",
    "                elif ctyluc in ('240', '241', '300', '301', '310', '311', '313', '320', \n",
    "                                '321', '330', '331', '333', '340', '341', '350', '360', \n",
    "                                '370', '380', '382', '390', '698'):\n",
    "                    row[2] = \"Multi-Family Residential\"\n",
    "                elif ctyluc in ('190', '600', '610', '612', '613', '614', '615', '616', \n",
    "                                '618', '620', '695', '696', '697', '810'):\n",
    "                    row[2] = \"Open Space\"\n",
    "                elif ctyluc in ('190', '700', '710', '711', '720', '731', '732', '733', '780', \n",
    "                                '790', '910', '922'):\n",
    "                    row[2] = \"Public Service\"\n",
    "                elif ctyluc in ('450', '900'):\n",
    "                    row[2] = \"Recreation\"\n",
    "                elif ctyluc in ('200', '201', '220', '222', '230', '231', '232', '260', \n",
    "                                '270', '280', '282', '290', '622', '692', '693'):\n",
    "                    row[2] = \"Single Family Residential\"     \n",
    "                elif ctyluc in ('420', '421', '430', '431', '432', '514'):\n",
    "                    row[2] = \"Tourist Accommodation\"\n",
    "                elif ctyluc in ('100', '108', '110', '117', '120', '130', '140', '150', '160'):\n",
    "                    row[2] = \"Vacant\"\n",
    "                elif ctyluc is None:\n",
    "                    row[2] == ''\n",
    "            if (row[0] != None or row[0] != \"\") and (row[3] == 'CC'):\n",
    "                if ctyluc == '980':\n",
    "                    row[1] = 'Special Purpose with Minor Improvements'\n",
    "                elif ctyluc == '320':\n",
    "                    row[1] = 'Three to Four Units'\n",
    "                elif ctyluc == '280':\n",
    "                    row[1] = 'Single Family Residential with Minor Improvements'\n",
    "                elif ctyluc == '190':\n",
    "                    row[1] = 'Vacant - Public Use Lands'\n",
    "                elif ctyluc == '120':\n",
    "                    row[1] = 'Vacant - Single Family Residential' \n",
    "                elif ctyluc is None:\n",
    "                    row[1] == ''\n",
    "                cursor.updateRow(row)           \n",
    "            # update Douglas Land Use descriptions        \n",
    "            if (row[0] != None or row[0] != \"\") and (row[3] == 'DG'):\n",
    "                if ctyluc in ('400', '402', '410', '411', '412', \n",
    "                            '440', '460', '470', '480', '500', \n",
    "                            '510', '560', '580', '582'):\n",
    "                    row[2] = \"Commercial\"\n",
    "                elif ctyluc in ('210', '211'):\n",
    "                    row[2] = \"Condominium\"\n",
    "                elif ctyluc == '270':\n",
    "                    row[2] = \"Condominium Common Area\"\n",
    "                elif ctyluc in ('300', '310', '320', '330', '350', '390'):\n",
    "                    row[2] = \"Multi-Family Residential\"\n",
    "                elif ctyluc == '190':\n",
    "                    row[2] = \"Open Space\"\n",
    "                elif ctyluc in ('700', '710', '711', '910', '980', '970'):\n",
    "                    row[2] = \"Public Service\"\n",
    "                elif ctyluc in ('450', '900', '970'):\n",
    "                    row[2] = \"Recreation\"\n",
    "                elif ctyluc in ('200', '220', '230', '236', '240', '280', '282'):\n",
    "                    row[2] = \"Single Family Residential\"     \n",
    "                elif ctyluc in ('420', '430'):\n",
    "                    row[2] = \"Tourist Accommodation\"\n",
    "                elif ctyluc in ('100', '110', '117', '120', '130', '140'):\n",
    "                    row[2] = \"Vacant\"\n",
    "                elif ctyluc is None:\n",
    "                    row[2] == ''\n",
    "            if (row[0] != None or row[0] != \"\" or ctyluc.isspace() != True) and (row[3] == 'DG'):\n",
    "                if ctyluc == '980':\n",
    "                    row[1] = 'Special Purpose with Minor Improvements'\n",
    "                elif ctyluc == '970':\n",
    "                    row[1] = 'Special Purpose Common Area'\n",
    "                elif ctyluc == '910':\n",
    "                    row[1] = 'Cemeteries'\n",
    "                elif ctyluc == '900':\n",
    "                    row[1] = 'Parks for Public Use'\n",
    "                elif ctyluc == '711':\n",
    "                    row[1] = 'Communication, Transportation, and Utility Property of a Local Nature Under Construction'\n",
    "                elif ctyluc == '710':\n",
    "                    row[1] = 'Communication, Transportation, and Utility Property of a Local Nature'\n",
    "                elif ctyluc == '700':\n",
    "                    row[1] = 'Operating Communication, Transportation, and Utility Property of an Interstate or Intercounty Nature'\n",
    "                elif ctyluc == '582':\n",
    "                    row[1] = 'Industrial with Minor Improvements - with structures insufficient to determine intended use'\n",
    "                elif ctyluc == '580':\n",
    "                    row[1] = 'Industrial with Minor Improvements'\n",
    "                elif ctyluc == '560':\n",
    "                    row[1] = 'Industrial Auxiliary Area'\n",
    "                elif ctyluc == '510':\n",
    "                    row[1] = 'Commercial Industrial - retail or office use combined with Industrial use'\n",
    "                elif ctyluc == '500':\n",
    "                    row[1] = 'General Industrial - light industry, trucking and warehousing, service, repair, etc.'\n",
    "                elif ctyluc == '480':\n",
    "                    row[1] = 'Commercial with Minor Improvements'\n",
    "                elif ctyluc == '470':\n",
    "                    row[1] = 'Commercial Common Area'\n",
    "                elif ctyluc == '460':\n",
    "                    row[1] = 'Commercial Auxiliary Area'\n",
    "                elif ctyluc == '450':\n",
    "                    row[1] = 'Golf Course'\n",
    "                elif ctyluc == '440':\n",
    "                    row[1] = 'Commercial Recreation'\n",
    "                elif ctyluc == '430':\n",
    "                    row[1] = 'Commercial Living Accommodations'\n",
    "                elif ctyluc == '420':\n",
    "                    row[1] = 'Casino or Hotel Casino'\n",
    "                elif ctyluc == '410':\n",
    "                    row[1] = 'Offices, Professional and Business Services'\n",
    "                elif ctyluc == '402':\n",
    "                    row[1] = 'Parking and/or Parking Structures'\n",
    "                elif ctyluc == '400':\n",
    "                    row[1] = 'General Commercial'\n",
    "                elif ctyluc == '390':\n",
    "                    row[1] = 'Mixed Use with Multi-Family Residential as primary use'\n",
    "                elif ctyluc == '382':\n",
    "                    row[1] = 'Multi-Family Residential with Minor Improvements - No livable structures'\n",
    "                elif ctyluc == '380':\n",
    "                    row[1] = 'Multi-Family Residential with Minor Improvements'\n",
    "                elif ctyluc == '370':\n",
    "                    row[1] = 'Multi-Family Residential Common Area'\n",
    "                elif ctyluc == '360':\n",
    "                    row[1] = 'Multi-Family Residential Auxiliary Area'\n",
    "                elif ctyluc == '350':\n",
    "                    row[1] = 'Manufactured Home Park - Ten or More Manufactured Home Units'\n",
    "                elif ctyluc == '341':\n",
    "                    row[1] = 'Five or More Units - High Rise Under Construction'\n",
    "                elif ctyluc == '340':\n",
    "                    row[1] = 'Five or More Units - High Rise'\n",
    "                elif ctyluc == '333':\n",
    "                    row[1] = 'Exempt or Partially Exempt Apartment Building'\n",
    "                elif ctyluc == '331':\n",
    "                    row[1] = 'Five or More Units - Low Rise Under Construction'\n",
    "                elif ctyluc == '330':\n",
    "                    row[1] = 'Five or More Units - Low Rise'\n",
    "                elif ctyluc == '321':\n",
    "                    row[1] = 'Three to Four Units Under Construction'\n",
    "                elif ctyluc == '320':\n",
    "                    row[1] = 'Three to Four Units'\n",
    "                elif ctyluc == '313':\n",
    "                    row[1] = 'Multi-Family Residence with Manufactured Home Conversion'\n",
    "                elif ctyluc == '311':\n",
    "                    row[1] = 'Two Single Family Units Under Construction'\n",
    "                elif ctyluc == '310':\n",
    "                    row[1] = 'Two Single Family Units'\n",
    "                elif ctyluc == '301':\n",
    "                    row[1] = 'Duplex Under Construction'\n",
    "                elif ctyluc == '300':\n",
    "                    row[1] = 'Duplex'\n",
    "                elif ctyluc == '290':\n",
    "                    row[1] = 'Mixed Use with Single Family Residential as primary use'\n",
    "                elif ctyluc == '282':\n",
    "                    row[1] = 'Single Family Residential with Minor Improvements - No livable structures'\n",
    "                elif ctyluc == '280':\n",
    "                    row[1] = 'Single Family Residential with Minor Improvements'\n",
    "                elif ctyluc == '270':\n",
    "                    row[1] = 'Single Family Residential Common Area'\n",
    "                elif ctyluc == '260':\n",
    "                    row[1] = 'Single Family Residential Auxiliary Area'\n",
    "                elif ctyluc == '240':\n",
    "                    row[1] = 'Individual Residential Unit - Townhouse or Row House'\n",
    "                elif ctyluc == '236':\n",
    "                    row[1] = 'Personal Property Manufactured Home Secured'\n",
    "                elif ctyluc == '233':\n",
    "                    row[1] = 'Secured Manufactured Home with Site Built Additions (Not Converted)'\n",
    "                elif ctyluc == '232':\n",
    "                    row[1] = 'Manufactured Home - Unsecured with Site Built Additions'\n",
    "                elif ctyluc == '231':\n",
    "                    row[1] = 'Manufacture Home Conversions Pending'\n",
    "                elif ctyluc == '230':\n",
    "                    row[1] = 'Personal Property Manufactured Home on the Unsecured Roll'\n",
    "                elif ctyluc == '222':\n",
    "                    row[1] = 'Manufactured Home (Converted) with Site Built Additions'\n",
    "                elif ctyluc == '220':\n",
    "                    row[1] = 'Manufactured Home Converted to Real Property'\n",
    "                elif ctyluc == '211':\n",
    "                    row[1] = 'Individual Unit in a Multiple Unit Building Under Construction'\n",
    "                elif ctyluc == '210':\n",
    "                    row[1] = 'Individual Unit in a Multiple Unit Building'\n",
    "                elif ctyluc == '201':\n",
    "                    row[1] = 'Single Family Residence Under Construction'\n",
    "                elif ctyluc == '200':\n",
    "                    row[1] = 'Single Family Residence'\n",
    "                elif ctyluc == '190':\n",
    "                    row[1] = 'Vacant - Public Use Lands'\n",
    "                elif ctyluc == '150':\n",
    "                    row[1] = 'Vacant - Industrial'\n",
    "                elif ctyluc == '140':\n",
    "                    row[1] = 'Vacant - Commercial'\n",
    "                elif ctyluc == '130':\n",
    "                    row[1] = 'Vacant - Multi-Residential'\n",
    "                elif ctyluc == '120':\n",
    "                    row[1] = 'Vacant - Single Family Residential'\n",
    "                elif ctyluc == '117':\n",
    "                    row[1] = 'Vacant - Roads/Easements'\n",
    "                elif ctyluc == '110':\n",
    "                    row[1] = 'Vacant - Splinter and Other Unbuildable'\n",
    "                elif ctyluc == '108':\n",
    "                    row[1] = 'Vacant - Patented Mining Claim, Not Mined'\n",
    "                elif ctyluc == '100':\n",
    "                    row[1] = 'Vacant - Unknown/Other'\n",
    "                elif ctyluc is None:\n",
    "                    row[1] == ''\n",
    "                cursor.updateRow(row)        \n",
    "            # Set El Dorado County Land Use Description fields\n",
    "            if (row[0] != None or row[0] != \"\") and (row[3] == 'EL'):\n",
    "                if ctyluc in ('03', '29', '31', '32', '34', '36', '37', '38', '39', '41', '42', '43', '44', '45', '46', '47', '48', \n",
    "                            '65', '67', '68', '82', '91', '93'):\n",
    "                    row[2] = \"Commercial\"\n",
    "                elif ctyluc == '14':\n",
    "                    row[2] = \"Condominium\"\n",
    "                elif ctyluc == '89':\n",
    "                    row[2] = \"Condominium Common Area\"\n",
    "                elif ctyluc in ('01', '07', '12', '13', '16', '18', '19', '28', '35'):\n",
    "                    row[2] = \"Multi-Family Residential\"\n",
    "                elif ctyluc in ('25', '26', '50', '51', '52', '55', '56', '60', '70', '75', '79'):\n",
    "                    row[2] = \"Open Space\"\n",
    "                elif ctyluc in ('90', '92', '94', '96', '97', '98', '99'):\n",
    "                    row[2] = \"Public Service\"\n",
    "                elif ctyluc in ('61', '62', '63', '64'):\n",
    "                    row[2] = \"Recreation\"\n",
    "                elif ctyluc in ('06', '11', '15', '22', '23'):\n",
    "                    row[2] = \"Single Family Residential\"     \n",
    "                elif ctyluc in ('33', '80', '81'):\n",
    "                    row[2] = \"Tourist Accommodation\"\n",
    "                elif ctyluc in ('00', '02', '05', '17', '21', '24', '30', '40'):\n",
    "                    row[2] = \"Vacant\"\n",
    "                elif ctyluc is None:\n",
    "                    row[2] == ''\n",
    "            if (row[0] != None or row[0] != \"\") and (row[3] == 'EL'):\n",
    "                if ctyluc == '98':\n",
    "                    row[1] = 'DEV MSC FIRE SUPPRESSION FACILITIES'\n",
    "                elif ctyluc == '96':\n",
    "                    row[1] = 'DEV MSC CEMETERIES'\n",
    "                elif ctyluc == '94':\n",
    "                    row[1] = 'DEV MSC SCHOOLS - LARGE (101+ STUDENTS)'\n",
    "                elif ctyluc == '93':\n",
    "                    row[1] = 'DEV MSC SCHOOLS - MEDIUM (13-100 STUDENTS)'\n",
    "                elif ctyluc == '92':\n",
    "                    row[1] = 'DEV MSC SCHOOLS - SMALL (1-12 STUDENTS)'\n",
    "                elif ctyluc == '90':\n",
    "                    row[1] = 'UTL IND PUBLIC UTILITY (ON STATE ASSESSED ROLL)'\n",
    "                elif ctyluc == '84':\n",
    "                    row[1] = 'DEV MSC TEMPORARY USE CODE FOR PROJECT 184'\n",
    "                elif ctyluc == '82':\n",
    "                    row[1] = 'DEV COM PARKING LOT'\n",
    "                elif ctyluc == '81':\n",
    "                    row[1] = 'DEV MSC UNDERLYING INTEREST IN TIME SHARE PROJ'\n",
    "                elif ctyluc == '79':\n",
    "                    row[1] = 'RLU MSC ENV. SENSITIVE LAND - RESTRICTED USE'\n",
    "                elif ctyluc == '68':\n",
    "                    row[1] = 'DEV COM MARINAS'\n",
    "                elif ctyluc == '65':\n",
    "                    row[1] = 'DEV COM RESTAURANT'\n",
    "                elif ctyluc == '64':\n",
    "                    row[1] = 'DEV MSC SKI RESORTS'\n",
    "                elif ctyluc == '63':\n",
    "                    row[1] = 'DEV MSC CAMPGROUNDS'\n",
    "                elif ctyluc == '62':\n",
    "                    row[1] = 'DEV MSC COMMUNITY ORIENTED FACILITIES'\n",
    "                elif ctyluc == '61':\n",
    "                    row[1] = 'DEV MSC MISC. IMPROVED RECREATIONAL'\n",
    "                elif ctyluc == '60':\n",
    "                    row[1] = 'VAC MSC VACANT RECREATIONAL LAND'\n",
    "                elif ctyluc == '50':\n",
    "                    row[1] = 'TPZ MSC TIMBER PRESERVE ZONING - ACTIVE'\n",
    "                elif ctyluc == '48':\n",
    "                    row[1] = 'DEV IND OFFICES'\n",
    "                elif ctyluc == '47':\n",
    "                    row[1] = 'DEV IND HOSPITALS & CONVALESCENT HOSPITALS'\n",
    "                elif ctyluc == '46':\n",
    "                    row[1] = 'DEV IND MEDICAL/DENTAL/VET OFFICES'\n",
    "                elif ctyluc == '45':\n",
    "                    row[1] = 'DEV IND LIGHT MANUFACTURING'\n",
    "                elif ctyluc == '43':\n",
    "                    row[1] = 'DEV IND WAREHOUSES'\n",
    "                elif ctyluc == '42':\n",
    "                    row[1] = 'DEV IND MINI-WAREHOUSES (MINI-STORAGE)'\n",
    "                elif ctyluc == '41':\n",
    "                    row[1] = 'DEV IND MISC. IMPROVED INDUSTRIAL PROPERTY'\n",
    "                elif ctyluc == '40':\n",
    "                    row[1] = 'VAC IND VACANT INDUSTRIAL LAND'\n",
    "                elif ctyluc == '39':\n",
    "                    row[1] = 'DEV COM SUPERMARKETS'\n",
    "                elif ctyluc == '38':\n",
    "                    row[1] = 'DEV COM RETAIL STORES >15,000 SQ. FT.'\n",
    "                elif ctyluc == '37':\n",
    "                    row[1] = 'DEV COM RETAIL STORES 5,001-15,000 SQ. FT.'\n",
    "                elif ctyluc == '36':\n",
    "                    row[1] = 'DEV COM RETAIL STORES <=5,000 SQ. FT.'\n",
    "                elif ctyluc == '35':\n",
    "                    row[1] = 'DEV COM MOBILE HOME PARKS'\n",
    "                elif ctyluc == '34':\n",
    "                    row[1] = 'DEV COM SERVICE STATION'\n",
    "                elif ctyluc == '33':\n",
    "                    row[1] = 'DEV COM MOTEL, HOTEL'\n",
    "                elif ctyluc == '31':\n",
    "                    row[1] = 'DEV COM MISC. IMPROVED COMMERCIAL'\n",
    "                elif ctyluc == '30':\n",
    "                    row[1] = 'VAC COM VACANT COMMERCIAL LAND'\n",
    "                elif ctyluc == '29':\n",
    "                    row[1] = 'DEV MSC RURAL NON-RES. IMPROVEMENT 2.51-20.0 AC.'\n",
    "                elif ctyluc == '26':\n",
    "                    row[1] = 'AGP MSC RURAL RESTRICTIVE ZONING - NON-RENEWAL'\n",
    "                elif ctyluc == '25':\n",
    "                    row[1] = 'AGP MSC RURAL RESTRICTIVE ZONING - CLCA (ACTIVE)'\n",
    "                elif ctyluc == '24':\n",
    "                    row[1] = 'VAC RES RURAL RES. LAND 20+ MINOR NON-RES IMPR'\n",
    "                elif ctyluc == '23':\n",
    "                    row[1] = 'DEV RES RURAL RES. 20+ AC. 1 RES. UNIT'\n",
    "                elif ctyluc == '22':\n",
    "                    row[1] = 'DEV RES RURAL RES. 2.51-20.0 AC. 1 SF UNIT'\n",
    "                elif ctyluc == '21':\n",
    "                    row[1] = 'VAC RES VAC RURAL RES LAND 2.51-20.0 AC. 1 UNIT'\n",
    "                elif ctyluc == '17':\n",
    "                    row[1] = 'VAC MSC SUBJ. TO OPEN SPACE CONTRACT (NOT CLCA)'\n",
    "                elif ctyluc == '16':\n",
    "                    row[1] = 'DEV RES MOBILE HOME ON RENTED LAND'\n",
    "                elif ctyluc == '15':\n",
    "                    row[1] = 'DEV RES RESIDENCE ON LEASED LAND'\n",
    "                elif ctyluc == '14':\n",
    "                    row[1] = 'DEV MFR CONDOMINIUMS & TOWNHOUSES'\n",
    "                elif ctyluc == '13':\n",
    "                    row[1] = 'DEV MFR MULTI-RESIDENTIAL 4+ UNITS'\n",
    "                elif ctyluc == '12':\n",
    "                    row[1] = 'DEV MFR MULTI-RESIDENTIAL 2-3 UNITS'\n",
    "                elif ctyluc == '11':\n",
    "                    row[1] = 'DEV RES SINGLE FAM. RES. <=2.5 AC.(INC. MAN. HMS'\n",
    "                elif ctyluc == '07':\n",
    "                    row[1] = 'DEV MFR RETIREMENT HOUSING'\n",
    "                elif ctyluc == '05':\n",
    "                    row[1] = 'VAC MFR VACANT MULTI-RES. LAND 4+ UNITS ALLOWED'\n",
    "                elif ctyluc == '03':\n",
    "                    row[1] = 'DEV COM PLACE OF WORSHIP'\n",
    "                elif ctyluc == '02':\n",
    "                    row[1] = 'VAC RES NON-RES. IMPROVEMENTS <=2.5 AC.'\n",
    "                elif ctyluc == '00':\n",
    "                    row[1] = 'VAC RES VACANT RES. LAND <=2.5 AC. 1-3 UNITS'\n",
    "                elif ctyluc is None:\n",
    "                    row[1] == ''\n",
    "                cursor.updateRow(row)\n",
    "            # set Placer TRPA land use description\n",
    "            if (row[0] != None or row[0] != \"\") and (row[3] == 'PL'):\n",
    "                if ctyluc in ('07', '11', '12', '13', '14', '15', '17', '19', '21', '22', '23', \n",
    "                            '24', '25', '26', '27', '29', '31', '32', '36', '37', '38', \n",
    "                            '39', '62', '63', '71', '88'):\n",
    "                    row[2] = \"Commercial\"\n",
    "                elif ctyluc == ('04'):\n",
    "                    row[2] = \"Condominium\"\n",
    "                elif ctyluc == '89':\n",
    "                    row[2] = \"Condominium Common Area\"\n",
    "                elif ctyluc in ('02', '03', '04', '05', '09', '28'):\n",
    "                    row[2] = \"Multi-Family Residential\"\n",
    "                elif ctyluc in ('56', '55', '60', '61', '87', '90'):\n",
    "                    row[2] = \"Open Space\"\n",
    "                elif ctyluc in ('72', '76', '77', '81'):\n",
    "                    row[2] = \"Public Service\"\n",
    "                elif ctyluc in ('65', '66', '67', '68', '69'):\n",
    "                    row[2] = \"Recreation\"\n",
    "                elif ctyluc in ('01', '08', '16'):\n",
    "                    row[2] = \"Single Family Residential\"     \n",
    "                elif ctyluc in ('06', '18', '64'):\n",
    "                    row[2] = \"Tourist Accommodation\"\n",
    "                elif ctyluc in ('00', '10', '20', '30'):\n",
    "                    row[2] = \"Vacant\"\n",
    "                elif ctyluc is None:\n",
    "                    row[2] == ''\n",
    "            if (row[0] != None or row[0] != \"\") and (row[3] == 'PL'):\n",
    "                if ctyluc == '90':\n",
    "                    row[1] = 'GREENBELT'\n",
    "                elif ctyluc == '89':\n",
    "                    row[1] = 'COMMON AREA'\n",
    "                elif ctyluc == '88':\n",
    "                    row[1] = 'HIGHWAYS, ROADS, STREETS'\n",
    "                elif ctyluc == '87':\n",
    "                    row[1] = 'RIVERS, LAKES, RESERVOIR, CANAL'\n",
    "                elif ctyluc == '81':\n",
    "                    row[1] = 'UTILITIES, PUBLIC & PRIVATE'\n",
    "                elif ctyluc == '77':\n",
    "                    row[1] = 'CEMETERIES'\n",
    "                elif ctyluc == '76':\n",
    "                    row[1] = 'MISC. PUBLIC BUILDINGS'\n",
    "                elif ctyluc == '72':\n",
    "                    row[1] = 'SCHOOLS'\n",
    "                elif ctyluc == '71':\n",
    "                    row[1] = 'CHURCHES'\n",
    "                elif ctyluc == '69':\n",
    "                    row[1] = 'MISCELLANEOUS RECREATIONAL'\n",
    "                elif ctyluc == '68':\n",
    "                    row[1] = 'CAMPS & PARKS, GENERAL'\n",
    "                elif ctyluc == '67':\n",
    "                    row[1] = 'SKI FACILITY'\n",
    "                elif ctyluc == '66':\n",
    "                    row[1] = 'GOLF COURSE'\n",
    "                elif ctyluc == '65':\n",
    "                    row[1] = 'TENNIS, SWIMMING CLUBS'\n",
    "                elif ctyluc == '64':\n",
    "                    row[1] = 'LODGES, HALLS'\n",
    "                elif ctyluc == '63':\n",
    "                    row[1] = 'MARINA, PIER'\n",
    "                elif ctyluc == '62':\n",
    "                    row[1] = 'THEATER, BOWLING ALLEY'\n",
    "                elif ctyluc == '61':\n",
    "                    row[1] = 'NON-PROFIT CAMPS/PARKS'\n",
    "                elif ctyluc == '60':\n",
    "                    row[1] = 'CONSERVATION EASEMENT RESTRICTIONS'\n",
    "                elif ctyluc == '56':\n",
    "                    row[1] = 'TIMBERLAND, ZONED TPZ'\n",
    "                elif ctyluc == '55':\n",
    "                    row[1] = 'TIMBERLAND, UNRESTRICTED'\n",
    "                elif ctyluc == '39':\n",
    "                    row[1] = 'MISCELLANEOUS INDUSTRIAL'\n",
    "                elif ctyluc == '38':\n",
    "                    row[1] = 'WAREHOUSE'\n",
    "                elif ctyluc == '37':\n",
    "                    row[1] = 'MINI-STORAGE, COVERED STORAGE'\n",
    "                elif ctyluc == '36':\n",
    "                    row[1] = 'UNCOVERED STORAGE, WRECKING YARD'\n",
    "                elif ctyluc == '32':\n",
    "                    row[1] = 'HEAVY INDUSTRIAL'\n",
    "                elif ctyluc == '31':\n",
    "                    row[1] = 'LIGHT INDUSTRIAL'\n",
    "                elif ctyluc == '30':\n",
    "                    row[1] = 'VACANT INDUSTRIAL'\n",
    "                elif ctyluc == '29':\n",
    "                    row[1] = \"MISCELLANEOUS COMM'L\"\n",
    "                elif ctyluc == '28':\n",
    "                    row[1] = 'MOBILE HOME PARK'\n",
    "                elif ctyluc == '27':\n",
    "                    row[1] = 'PARKING LOTS'\n",
    "                elif ctyluc == '26':\n",
    "                    row[1] = 'AUTO SALES, REPAIR'\n",
    "                elif ctyluc == '25':\n",
    "                    row[1] = 'SERVICE STATION'\n",
    "                elif ctyluc == '24':\n",
    "                    row[1] = 'MINI-MARKET WITH GAS'\n",
    "                elif ctyluc == '23':\n",
    "                    row[1] = \"BANKS, S&L'S, CREDIT UNION\"\n",
    "                elif ctyluc == '22':\n",
    "                    row[1] = 'FAST FOOD RESTAURANT'\n",
    "                elif ctyluc == '21':\n",
    "                    row[1] = 'RESTAURANTS, COCKTAIL LOUNGES'\n",
    "                elif ctyluc == '20':\n",
    "                    row[1] = 'VACANT, COMMERCIAL'\n",
    "                elif ctyluc == '19':\n",
    "                    row[1] = 'OFFICE MEDICAL/DENTAL'\n",
    "                elif ctyluc == '18':\n",
    "                    row[1] = 'HOTELS, MOTELS, RESORTS'\n",
    "                elif ctyluc == '17':\n",
    "                    row[1] = 'OFFICE GENERAL'\n",
    "                elif ctyluc == '16':\n",
    "                    row[1] = 'RESIDENCE ON COMMERCIAL LAND'\n",
    "                elif ctyluc == '15':\n",
    "                    row[1] = 'SHOPPING CENTER'\n",
    "                elif ctyluc == '14':\n",
    "                    row[1] = 'OFFICE CONDO'\n",
    "                elif ctyluc == '13':\n",
    "                    row[1] = 'MINI-MARKETS, NO GAS'\n",
    "                elif ctyluc == '12':\n",
    "                    row[1] = 'SUBURBAN STORE'\n",
    "                elif ctyluc == '11':\n",
    "                    row[1] = 'COMMERCIAL STORE'\n",
    "                elif ctyluc == '10':\n",
    "                    row[1] = 'VACANT, SUBDIVIDED RESIDENTIAL'\n",
    "                elif ctyluc == '09':\n",
    "                    row[1] = 'MOBILE HOME IN M H PARK'\n",
    "                elif ctyluc == '08':\n",
    "                    row[1] = 'MOBILE HOME OUTSIDE OF PARK'\n",
    "                elif ctyluc == '07':\n",
    "                    row[1] = 'RESIDENTIAL, AUXILIARY IMP'\n",
    "                elif ctyluc == '06':\n",
    "                    row[1] = 'TIMESHARES'\n",
    "                elif ctyluc == '05':\n",
    "                    row[1] = 'APARTMENTS, 4 UNITS OR MORE'\n",
    "                elif ctyluc == '04':\n",
    "                    row[1] = 'SINGLE FAM RES, CONDO'\n",
    "                elif ctyluc == '03':\n",
    "                    row[1] = '3 SINGLE FAM RES, TRIPLEX'\n",
    "                elif ctyluc == '02':\n",
    "                    row[1] = '2 SINGLE FAM RES, DUPLEX'\n",
    "                elif ctyluc == '01':\n",
    "                    row[1] = 'SINGLE FAM RES, HALF PLEX'\n",
    "                elif ctyluc == '00':\n",
    "                    row[1] = 'VACANT, ALL TYPES-NOT ASGND'\n",
    "                elif ctyluc is None:\n",
    "                    row[1] == ''\n",
    "                cursor.updateRow(row)\n",
    "    # delete cursor\n",
    "    del cursor\n",
    "    print (\"The 'EXISTING_LANDUSE' field in the parcel data has been updated\")\n",
    "    # log.info(\"The 'EXISTING_LANDUSE' field in the parcel data has been updated\")\n",
    "    result = arcpy.GetCount_management(ParcelLayer)\n",
    "    print('{} has {} records now.'.format(ParcelLayer, result[0]))\n",
    "\n",
    "    ### Regional Landuse Update --------------------------------------------------------------------------------------###\n",
    "    print(\"Starting the Regional Land Use Spatial Join: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    # log.info(\"Starting the Regional Land Use Spatial Join: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "    # Spatial Join\n",
    "    arcpy.SpatialJoin_analysis(ParcelPoint, sde_RegionalLandUse, ParcelPoint_RegionalLandUse, \n",
    "                            \"JOIN_ONE_TO_ONE\", \"KEEP_ALL\", \"\", \"HAVE_THEIR_CENTER_IN\", \"\", \"\")\n",
    "    print (\"Finished the Regional Land Use Spatial Join: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    # log.info(\"Finished the Regional Land Use Spatial Join: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "        # Create an expression to find records with null values in either field\n",
    "    print('Checking For Nulls')\n",
    "\n",
    "    expression = f\"{'APN_TRPA'} IS NULL OR {'COUNTY_TRPA'} IS NULL\"\n",
    "\n",
    "    # Use an UpdateCursor to delete records with null values\n",
    "    with arcpy.da.UpdateCursor(ParcelLayer, ['APN_TRPA', 'COUNTY_TRPA'], where_clause=expression) as cursor:\n",
    "        for row in cursor:\n",
    "            cursor.deleteRow()\n",
    "            print(\"One row dropped from tHE PARCEL LAYER\")\n",
    "\n",
    "    with arcpy.da.UpdateCursor(ParcelPoint_RegionalLandUse, ['APN_TRPA', 'COUNTY_TRPA'], where_clause=expression) as cursor:\n",
    "        for row in cursor:\n",
    "            cursor.deleteRow()\n",
    "            print(\"One row dropped from regional Land Use\")\n",
    "    \n",
    "\n",
    "    # transfer attributes to Parcel Layer\n",
    "    fieldJoinCalc_multikey(ParcelLayer, ['APN_TRPA', 'COUNTY_TRPA'],['REGIONAL_LANDUSE_TRPA'], \n",
    "                ParcelPoint_RegionalLandUse, ['APN_TRPA', 'COUNTY_TRPA'],['Description'])\n",
    "    print (\"The 'REGIONAL_LANDUSE' field in the parcel data has been updated\")\n",
    "    # log.info(\"The 'REGIONAL_LANDUSE' field in the parcel data has been updated\")\n",
    "\n",
    "    ## Estimated Coverage Allowed Attirbute Update ------------------------------------------------------------------###\n",
    "    print(\"Starting the Estimated Coverage Allowed Identity Overlay: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    # log.info(\"Starting the Estimated Coverage Allowed Identity Overlay: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "    # create out table for the stats sum\n",
    "    outTable =  memory + \"id_Parcel_Bailey_Table\"\n",
    "\n",
    "    # Create Identity Output Layer\n",
    "    id_ParcelLyr_BaileyLyr = memory + \"id_Parcel_Bailey\"\n",
    "\n",
    "    # Create Impervious Layer\n",
    "    Bailey_lyr = memory + \"Bailey_lyr\"\n",
    "\n",
    "    # Create Identity Layer\n",
    "    identity_layer = memory + \"bailey_identity_layer\"\n",
    "\n",
    "    # Make a layer from the feature class Impervious that only passes Ftype = 'building' and 'other'\n",
    "    arcpy.MakeFeatureLayer_management(sde_Bailey, Bailey_lyr)\n",
    "    print (\"Created feature layer of Bailey Soils\")\n",
    "\n",
    "    # Process: Use the Identity function\n",
    "    print (\"Starting Identity: \"+ strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    arcpy.Identity_analysis (ParcelLayer, Bailey_lyr, id_ParcelLyr_BaileyLyr)\n",
    "    print (\"Finished Identity: \"+ strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "    # Add SqFt field\n",
    "    arcpy.management.AddField(id_ParcelLyr_BaileyLyr, \"SqFt\", \"DOUBLE\", \"\", \"\", \"\", \n",
    "                            \"Square Feet\", \"NULLABLE\", \"NON_REQUIRED\", \"\")\n",
    "\n",
    "    # Make a layer from the feature class Impervious that only passes Ftype = 'building' and 'other'\n",
    "    arcpy.MakeFeatureLayer_management(id_ParcelLyr_BaileyLyr, identity_layer, \n",
    "                                    where_clause = \"NOT CAPABILITY in ('WB', '-1', '0')\")\n",
    "\n",
    "    # calculate geometry of output identity\n",
    "    arcpy.CalculateField_management(identity_layer, \"SqFt\", \"!shape.area@SQUAREFEET!\", \"PYTHON3\", \"\")\n",
    "\n",
    "    # multiply square footage by bailey coefficents\n",
    "    with arcpy.da.UpdateCursor(identity_layer, ['CAPABILITY', 'SqFt', 'PERCENT_COVERAGE_ALLOWED']) as cur:\n",
    "        for row in cur:\n",
    "            if row[0] != ('','WB'):\n",
    "                row[1] = row[1]*row[2]\n",
    "            else:\n",
    "                row[1] == 0\n",
    "            cur.updateRow(row)\n",
    "    del cur    \n",
    "    # Sum the square footage\n",
    "    arcpy.Statistics_analysis(identity_layer, outTable, [[\"SqFt\", \"SUM\"]], [\"APN_TRPA\",\"COUNTY_TRPA\"])\n",
    "\n",
    "    print(\"Finsished the Estimated Coverage Allowed Identity Overlay: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    # log.info(\"Finsished the Estimated Coverage Allowed Identity Overlay: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "    ## Join parcel sums back to parcel layer and calculate field\n",
    "\n",
    "    # transfer attributes to Parcel Layer\n",
    "    fieldJoinCalc_multikey(ParcelLayer, ['APN_TRPA', 'COUNTY_TRPA'],['ESTIMATED_COVERAGE_ALLOWED_TRPA'], \n",
    "                outTable, ['APN_TRPA', 'COUNTY_TRPA'],['SUM_SqFt'])\n",
    "    print (\"The 'ESTIMATED_COVERAGE_ALLOWED' field in the parcel data has been updated\")\n",
    "\n",
    "    ### Impervious Surface Attrigute Update --------------------------------------------------------------------------###\n",
    "    # create out table for the stats sum\n",
    "    outTable =  memory +\"id_Parcel_Imp_Table\"\n",
    "\n",
    "    # Create Identity Output Layer\n",
    "    id_ParcelLyr_ImperviousLyr = memory + \"id_Parcel_Impervious\"\n",
    "\n",
    "    # Create Impervious Layer\n",
    "    Impervious_lyr = memory + \"Impervious_lyr\"\n",
    "\n",
    "    # Create Identity Layer\n",
    "    identity_layer = memory + \"identity_layer\"\n",
    "        \n",
    "    # Make a layer from the feature class Impervious that only passes Ftype = 'building' and 'other'\n",
    "    arcpy.MakeFeatureLayer_management(sde_Impervious, Impervious_lyr)\n",
    "\n",
    "    # Process: Use the Identity function\n",
    "    print (\"Starting Identity of Imperviuos Surface by parcel: \"+ strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    arcpy.Identity_analysis (ParcelLayer, Impervious_lyr, id_ParcelLyr_ImperviousLyr)\n",
    "    print (\"Finished Identity of Imperviuos Surface by parcel:: \"+ strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "    # Add SqFt field\n",
    "    arcpy.management.AddField(id_ParcelLyr_ImperviousLyr, \n",
    "                            \"SqFt\", \"DOUBLE\", \"\", \"\", \"\", \"Square Feet\", \"NULLABLE\", \"NON_REQUIRED\", \"\")\n",
    "\n",
    "    # Make a layer from the feature class Impervious that only passes Ftype = 'building' and 'other'\n",
    "    arcpy.MakeFeatureLayer_management(id_ParcelLyr_ImperviousLyr, identity_layer, \n",
    "                                    where_clause = \"Feature IN ('Building', 'Road', 'Other', 'Driveway')\")\n",
    "\n",
    "    # calculate geometry of output identity\n",
    "    arcpy.CalculateField_management(identity_layer, \"SqFt\", \"!shape.area@SQUAREFEET!\", \"PYTHON3\", \"\")\n",
    "                                                            \n",
    "    # Sum the square footage of buildings and other by APN\n",
    "    arcpy.Statistics_analysis(identity_layer, outTable, [[\"SqFt\", \"SUM\"]], [\"APN_TRPA\",\"COUNTY_TRPA\"])\n",
    "\n",
    "    # Join parcel sums back to parcel layer and calculate field \"Impervious Surface Sq Ft\"\n",
    "    # transfer attributes to Parcel Layer\n",
    "    fieldJoinCalc_multikey(ParcelLayer, ['APN_TRPA', 'COUNTY_TRPA'],['IMPERVIOUS_SURFACE_SQFT_TRPA'], \n",
    "                outTable, ['APN_TRPA', 'COUNTY_TRPA'],['SUM_SqFt'])\n",
    "    print (\"The 'ImperviousCoverage_SqFt' field in the parcel data has been updated\")\n",
    "\n",
    "    ### Fire District Attribute Update -------------------------------------------------------------------------------###\n",
    "    print(\"Starting the Fire District Spatial Join: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    # log.info(\"Starting the Fire District Spatial Join: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    # Process Fire District Spatial Join\n",
    "    arcpy.SpatialJoin_analysis(ParcelPoint, sde_FireDistrict, ParcelPoint_FireDistrict, \n",
    "                            \"JOIN_ONE_TO_ONE\", \"KEEP_ALL\", \"\", \"HAVE_THEIR_CENTER_IN\", \"\", \"\")\n",
    "    print (\"Finished the Fire District Spatial Join: \"  + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    # log.info(\"Finished the Fire District Spatial Join: \"  + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "    # transfer attributes to Parcel Layer\n",
    "    fieldJoinCalc_multikey(ParcelLayer, ['APN_TRPA', 'COUNTY_TRPA'],['FIREPD_TRPA'], \n",
    "                ParcelPoint_FireDistrict, ['APN_TRPA', 'COUNTY_TRPA'],['DISTRICT'])\n",
    "    print (\"The 'FIRE_PD' field has been updated\")\n",
    "    # log.info(\"The 'FIRE_PD' field has been updated\")\n",
    "\n",
    "    ### Soil 1974 Attribute Update ------------------------------------------------------------------------------------### \n",
    "    print(\"Starting the SOIL_1974 Spatial Join: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    # log.info(\"Starting the SOIL_1974 Spatial Join: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    # Spatial Join\n",
    "    arcpy.SpatialJoin_analysis(ParcelPoint, sde_NRCSSoils1974, ParcelPoint_Soils74, \n",
    "                            \"JOIN_ONE_TO_ONE\", \"KEEP_ALL\", \"\", \"HAVE_THEIR_CENTER_IN\", \"\", \"\")\n",
    "    print (\"Finished the SOIL_1974 Spatial Join: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    # log.info(\"Finished the SOIL_1974 Spatial Join: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "    # transfer attributes to Parcel Layer\n",
    "    fieldJoinCalc_multikey(ParcelLayer, ['APN_TRPA', 'COUNTY_TRPA'],['SOIL_1974_TRPA'], \n",
    "                ParcelPoint_Soils74, ['APN_TRPA', 'COUNTY_TRPA'],['MUSYM_74'])\n",
    "    print (\"The 'SOIL_1974' field in the parcel data has been updated\")\n",
    "    # log.info(\"The 'SOIL_1974' field in the parcel data has been updated\")\n",
    "\n",
    "    ### Soil 2003 Attribute Update -----------------------------------------------------------------------------------###\n",
    "    print(\"Starting the SOIL_2003 Spatial Join: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    # log.info(\"Starting the SOIL_2003 Spatial Join: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "    # Spatial Join\n",
    "    arcpy.SpatialJoin_analysis(ParcelPoint, sde_NRCSSoils2003, ParcelPoint_Soils03, \n",
    "                            \"JOIN_ONE_TO_ONE\", \"KEEP_ALL\", \"\", \"HAVE_THEIR_CENTER_IN\", \"\", \"\")\n",
    "    print (\"Finished the SOIL_2003 Spatial Join: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    # log.info(\"Finished the SOIL_2003 Spatial Join: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "    # transfer attributes to Parcel Layer\n",
    "    fieldJoinCalc_multikey(ParcelLayer, ['APN_TRPA', 'COUNTY_TRPA'],['SOIL_2003_TRPA'], \n",
    "                ParcelPoint_Soils03, ['APN_TRPA', 'COUNTY_TRPA'],['MUSYM_03'])\n",
    "    print (\"The 'SOIL_2003' field in the parcel data has been updated.\")\n",
    "    # log.info(\"The 'SOIL_2003' field in the parcel data has been updated: \"  + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "    ### HRA Attribute Upate -------------------------------------------------------------------------------------###\n",
    "    print(\"Starting the Hydrologic Area Spatial Join: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    # log.info(\"Starting the Hydrologic Area Spatial Join: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "    # Spatial Join\n",
    "    arcpy.SpatialJoin_analysis(ParcelPoint, sde_HydroArea, ParcelPoint_HydroArea, \n",
    "                            \"JOIN_ONE_TO_ONE\", \"KEEP_ALL\", \"\", \"HAVE_THEIR_CENTER_IN\", \"\", \"\")\n",
    "    print (\"Finished the Hydrologic Area Spatial Join: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    # log.info(\"Finished the Hydrologic Area Spatial Join: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "    # transfer attributes to Parcel Layer\n",
    "    fieldJoinCalc_multikey(ParcelLayer, ['APN_TRPA', 'COUNTY_TRPA'],['HRA_NAME_TRPA'], \n",
    "                ParcelPoint_HydroArea, ['APN_TRPA', 'COUNTY_TRPA'],['HRA_NAME'])\n",
    "    print (\"The 'HRA_NAME' field in the parcel data has been updated\")\n",
    "    # log.info(\"The 'HRA_NAME' field in the parcel data has been updated\")\n",
    "\n",
    "    ### Watshed Attribute Update -------------------------------------------------------------------------------###\n",
    "    print(\"Starting the Watershed Spatial Join: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    # log.info(\"Starting the Watershed Spatial Join: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "    # Spatial Join\n",
    "    arcpy.SpatialJoin_analysis(ParcelPoint, sde_Watershed, ParcelPoint_Watershed, \n",
    "                            \"JOIN_ONE_TO_ONE\", \"KEEP_ALL\", \"\", \"HAVE_THEIR_CENTER_IN\", \"\", \"\")\n",
    "    print (\"Finished the Watershed Spatial Join: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    # log.info(\"Finished the Watershed Spatial Join: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "    # transfer attributes to Parcel Layer\n",
    "    fieldJoinCalc_multikey(ParcelLayer, ['APN_TRPA', 'COUNTY_TRPA'],['WATERSHED_NUMBER_TRPA'], \n",
    "                ParcelPoint_Watershed, ['APN_TRPA', 'COUNTY_TRPA'],['NUMBER'])\n",
    "    # replace null with 0\n",
    "    with arcpy.da.UpdateCursor(ParcelLayer, ['WATERSHED_NUMBER_TRPA']) as cursor:\n",
    "        for row in cursor:\n",
    "            if row[0] is None:\n",
    "                # If the value is null, replace it with 0\n",
    "                row[0] = 0\n",
    "                cursor.updateRow(row)\n",
    "    del cursor   \n",
    "    print (\"The 'WATERSHED_NUMBER' field in the parcel data has been updated\")\n",
    "    # log.info(\"The 'WATERSHED_NUMBER' field in the parcel data has been updated\")\n",
    "\n",
    "    # transfer attributes to Parcel Layer\n",
    "    fieldJoinCalc_multikey(ParcelLayer, ['APN_TRPA', 'COUNTY_TRPA'],['WATERSHED_NAME_TRPA'], \n",
    "                ParcelPoint_Watershed, ['APN_TRPA', 'COUNTY_TRPA'],['NAME'])\n",
    "    print (\"The 'WATERSHED_NAME' field in the parcel data has been updated\")\n",
    "    # log.info(\"The 'WATERSHED_NAME' field in the parcel data has been updated\")\n",
    "\n",
    "    # transfer attributes to Parcel Layer\n",
    "    fieldJoinCalc_multikey(ParcelLayer, ['APN_TRPA', 'COUNTY_TRPA'],['PRIORITY_WATERSHED_TRPA'], \n",
    "                ParcelPoint_Watershed, ['APN_TRPA', 'COUNTY_TRPA'],['PRIORITY'])\n",
    "    # replace null with 0\n",
    "    with arcpy.da.UpdateCursor(ParcelLayer, ['PRIORITY_WATERSHED_TRPA']) as cursor:\n",
    "        for row in cursor:\n",
    "            if row[0] is None:\n",
    "                # If the value is null, replace it with 0\n",
    "                row[0] = 0\n",
    "                cursor.updateRow(row)\n",
    "    del cursor\n",
    "    print (\"The 'PRIORITY_WATERSHED' field in the parcel data has been updated\")\n",
    "    # log.info(\"The 'PRIORITY_WATERSHED' field in the parcel data has been updated\")\n",
    "\n",
    "    ### Local Plan Attribute Update -----------------------------------------------------------------------------###\n",
    "    print(\"Starting the Local Plan Spatial Join: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    # log.info(\"Starting the Local Plan Spatial Join: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    # Spatial Join\n",
    "    arcpy.SpatialJoin_analysis(ParcelPoint, sde_LocalPlan, ParcelPoint_LocalPlan, \n",
    "                            \"JOIN_ONE_TO_ONE\", \"KEEP_ALL\", \"\", \"HAVE_THEIR_CENTER_IN\", \"\", \"\")\n",
    "    print (\"Finished the Local Plan Spatial Join: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    # log.info(\"Finished the Local Plan Spatial Join: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "    # transfer attributes to Parcel Layer\n",
    "    fieldJoinCalc_multikey(ParcelLayer, ['APN_TRPA', 'COUNTY_TRPA'],['PLAN_ID_TRPA'], \n",
    "                ParcelPoint_LocalPlan, ['APN_TRPA', 'COUNTY_TRPA'],['PLAN_ID'])\n",
    "    print (\"The 'PLAN_ID' field in the parcel data has been updated\")\n",
    "    # log.info(\"The 'PLAN_ID' field in the parcel data has been updated\")\n",
    "\n",
    "    # transfer attributes to Parcel Layer\n",
    "    fieldJoinCalc_multikey(ParcelLayer, ['APN_TRPA', 'COUNTY_TRPA'],['PLAN_NAME_TRPA'], \n",
    "                ParcelPoint_LocalPlan, ['APN_TRPA', 'COUNTY_TRPA'],['PLAN_NAME'])\n",
    "    print (\"The 'PLAN_NAME' field in the parcel data has been updated\")\n",
    "    # log.info(\"The 'PLAN_NAME' field in the parcel data has been updated\")\n",
    "\n",
    "    # transfer attributes to Parcel Layer\n",
    "    fieldJoinCalc_multikey(ParcelLayer, ['APN_TRPA', 'COUNTY_TRPA'],['PLAN_TYPE_TRPA'], \n",
    "                ParcelPoint_LocalPlan, ['APN_TRPA', 'COUNTY_TRPA'],['PLAN_TYPE'])\n",
    "    print (\"The 'PLAN_TYPE' field in the parcel data has been updated\")\n",
    "    # log.info(\"The 'PLAN_NAME' field in the parcel data has been updated\")\n",
    "\n",
    "    # transfer attributes to Parcel Layer\n",
    "    fieldJoinCalc_multikey(ParcelLayer, ['APN_TRPA', 'COUNTY_TRPA'],['LOCAL_PLAN_HYPERLINK_TRPA'], \n",
    "                ParcelPoint_LocalPlan, ['APN_TRPA', 'COUNTY_TRPA'],['File_URL'])\n",
    "    print (\"The 'LOCAL_PLAN_HYPERLINK' field in the parcel data has been updated\")\n",
    "    # log.info(\"The 'LOCAL_PLAN_HYPERLINK' field in the parcel data has been updated\")\n",
    "\n",
    "    ### Town Center Attribute Update --------------------------------------------------------------------------------### \n",
    "    print(\"Starting the Town Center Spatial Join: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    # log.info(\"Starting the Town Center Spatial Join: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    # Spatial Join\n",
    "    arcpy.SpatialJoin_analysis(ParcelPoint, sde_TownCenter, ParcelPoint_TownCenter, \n",
    "                            \"JOIN_ONE_TO_ONE\", \"KEEP_ALL\", \"\", \"HAVE_THEIR_CENTER_IN\", \"\", \"\")\n",
    "\n",
    "    print(\"Finished the Town Center Spatial Join: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    # log.info(\"Finished the Town Center Spatial Join: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "    # transfer attributes to Parcel Layer\n",
    "    fieldJoinCalc_multikey(ParcelLayer, ['APN_TRPA', 'COUNTY_TRPA'],['TOWN_CENTER_TRPA'], \n",
    "                ParcelPoint_TownCenter, ['APN_TRPA', 'COUNTY_TRPA'],['NAME'])\n",
    "    print(\"The 'TOWN_CENTER' field in the parcel data has been updated\")\n",
    "    # log.info(\"The 'TOWN_CENTER' field in the parcel data has been updated\")\n",
    "\n",
    "    ### Town Center Buffer Attribute Update --------------------------------------------------------------------------###\n",
    "    print(\"Starting the Town Center Buffer Spatial Join: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    # log.info(\"Starting the Town Center Buffer Spatial Join: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "    # Spatial Join\n",
    "    arcpy.SpatialJoin_analysis(ParcelPoint, sde_TownCenterBuffer, ParcelPoint_TownCenterBuffer, \n",
    "                            \"JOIN_ONE_TO_ONE\", \"KEEP_ALL\", \"\", \"HAVE_THEIR_CENTER_IN\", \"\", \"\")\n",
    "    print (\"Finished the Town Center Buffer Spatial Join: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    # log.info(\"Finished the Town Center Buffer Spatial Join: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "    # transfer attributes to Parcel Layer\n",
    "    fieldJoinCalc_multikey(ParcelLayer, ['APN_TRPA', 'COUNTY_TRPA'],['LOCATION_TO_TOWNCENTER_TRPA'], \n",
    "                ParcelPoint_TownCenterBuffer, ['APN_TRPA', 'COUNTY_TRPA'],['BUFFER_NAME'])\n",
    "    print (\"The 'LOCATION_TO_TOWNCENTER' field in the parcel data has been updated\")\n",
    "    # log.info(\"The 'LOCATION_TO_TOWNCENTER' field in the parcel data has been updated\")\n",
    "    \n",
    "    ### Catchment Attribute Update ------------------------------------------------------------------------------------### \n",
    "    print(\"Starting the Catchment Spatial Join: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    # log.info(\"Starting the Catchment Spatial Join: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    # Spatial Join\n",
    "    arcpy.SpatialJoin_analysis(ParcelPoint, sde_Catchment, ParcelPoint_Catchment, \n",
    "                            \"JOIN_ONE_TO_ONE\", \"KEEP_ALL\", \"\", \"HAVE_THEIR_CENTER_IN\", \"\", \"\")\n",
    "    print(\"Finished the Catchment Spatial Join: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    # log.info(\"Finished the Catchment Spatial Join: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "    # transfer attributes to Parcel Layer\n",
    "    fieldJoinCalc_multikey(ParcelLayer, ['APN_TRPA', 'COUNTY_TRPA'],['CATCHMENT_TRPA'], \n",
    "                ParcelPoint_Catchment, ['APN_TRPA', 'COUNTY_TRPA'],['Name'])\n",
    "    print (\"The 'Catchment' field in the parcel data has been updated\")\n",
    "    # log.info(\"The 'Catchment' field in the parcel data has been updated\")\n",
    "\n",
    "    ### Tolerance ID -------------------------------------------------------------------------------------------------###\n",
    "    print(\"Starting the Tolerance District Spatial Join: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    # Spatial Join\n",
    "    arcpy.SpatialJoin_analysis(ParcelPoint, sde_Tolerance, ParcelPoint_Tolerance, \n",
    "                            \"JOIN_ONE_TO_ONE\", \"KEEP_ALL\", \"\", \"INTERSECT\", \"\", \"\")\n",
    "    print (\"Finished the Tolerance District Spatial Join: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "    # transfer attributes to Parcel Layer\n",
    "    fieldJoinCalc_multikey(ParcelLayer, ['APN_TRPA', 'COUNTY_TRPA'],['TOLERANCE_ID_TRPA'], \n",
    "                ParcelPoint_Tolerance, ['APN_TRPA', 'COUNTY_TRPA'],['DISTRICT'])\n",
    "    print (\"The Tolerance ID field in the parcel data has been updated\")\n",
    "\n",
    "    ### Index 1987 Attribute Update ----------------------------------------------------------------------------------###\n",
    "    print(\"Starting the 1987 Index Spatial Join: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    # log.info(\"Starting the 1987 Index Spatial Join: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "    # Spatial Join\n",
    "    arcpy.SpatialJoin_analysis(ParcelPoint, sde_Index1987, ParcelPoint_Index1987, \n",
    "                            \"JOIN_ONE_TO_ONE\", \"KEEP_ALL\", \"\", \"HAVE_THEIR_CENTER_IN\", \"\", \"\")\n",
    "    print (\"Finished the 1987 Index Spatial Join: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    # log.info(\"Finished the 1987 Index Spatial Join: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "    # transfer attributes to Parcel Layer\n",
    "    fieldJoinCalc_multikey(ParcelLayer, ['APN_TRPA', 'COUNTY_TRPA'],['INDEX_1987_TRPA'], \n",
    "                ParcelPoint_Index1987, ['APN_TRPA', 'COUNTY_TRPA'],['MAP_NUMBER'])\n",
    "    print(\"The 'INDEX_1987' field in the parcel data has been updated\")\n",
    "    # log.info(\"The 'INDEX_1987' field in the parcel data has been updated\")\n",
    "\n",
    "    # transfer attributes to Parcel Layer\n",
    "    fieldJoinCalc_multikey(ParcelLayer, ['APN_TRPA', 'COUNTY_TRPA'],['INDEX_1987_HYPERLINK_TRPA'], \n",
    "                ParcelPoint_Index1987, ['APN_TRPA', 'COUNTY_TRPA'],['URL'])\n",
    "    print (\"The 'INDEX_1987_HYPERLINK' field in the parcel data has been updated\")\n",
    "    # log.info(\"The 'INDEX_1987_HYPERLINK' field in the parcel data has been updated\")\n",
    "\n",
    "    ### Postal Town Field --------------------------------------------------------------------------------------------### \n",
    "    print(\"Starting the Postal Town Spatial Join: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    # log.info(\"Starting the Postal Town Spatial Join: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "    # Spatial Join\n",
    "    arcpy.SpatialJoin_analysis(ParcelPoint, sde_Zip, ParcelPoint_PstlTown, \n",
    "                            \"JOIN_ONE_TO_ONE\", \"KEEP_ALL\", \"\", \"HAVE_THEIR_CENTER_IN\", \"\", \"\")\n",
    "    print (\"Finished the Postal Town Spatial Join: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    # log.info(\"Finished the Postal Town Spatial Join: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "    # transfer attributes to Parcel Layer\n",
    "    fieldJoinCalc_multikey(ParcelLayer, ['APN_TRPA', 'COUNTY_TRPA'],['PSTL_TOWN_TRPA'], \n",
    "                ParcelPoint_PstlTown, ['APN_TRPA', 'COUNTY_TRPA'],['PO_NAME'])\n",
    "    print (\"The 'PSTL_TOWN' field in the parcel data has been updated\")\n",
    "    # log.info(\"The 'PSTL_TOWN' field in the parcel data has been updated\")\n",
    "\n",
    "    ### Postal ZIP ---------------------------------------------------------------------------------------------------###\n",
    "\n",
    "    # transfer attributes to Parcel Layer\n",
    "    fieldJoinCalc_multikey(ParcelLayer, ['APN_TRPA', 'COUNTY_TRPA'],['PSTL_ZIP5_TRPA'], \n",
    "                ParcelPoint_PstlTown, ['APN_TRPA', 'COUNTY_TRPA'],['ZIP_CODE'])\n",
    "    print(\"The 'PSTL_ZIP5' field in the parcel data has been updated\")\n",
    "    # log.info(\"The 'PSTL_ZIP5' field in the parcel data has been updated\")\n",
    "\n",
    "    ### CSLT Jurisdiction Update -------------------------------------------------------------------------------------###\n",
    "    print(\"Starting to select parcels within City of South Lake Tahoe: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    # log.info(\"Starting to select parcels within City of South Lake Tahoe: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "    # select by location\n",
    "    csltParcels = arcpy.SelectLayerByLocation_management(ParcelLayer, \"HAVE_THEIR_CENTER_IN\", sde_CSLT, 0,   \n",
    "                                                        \"NEW_SELECTION\")\n",
    "    # update jurisdcition field\n",
    "    with arcpy.da.UpdateCursor(csltParcels, [\"JURISDICTION_TRPA\"]) as cursor:\n",
    "        for row in cursor:\n",
    "            row[0] = \"CSLT\"\n",
    "            # update all rows\n",
    "            cursor.updateRow(row)\n",
    "    del cursor \n",
    "    print(\"Finished updating parcels within City of South Lake Tahoe: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    # log.info(\"Finished updating parcels within City of South Lake Tahoe:  \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    print(\"JURISDCITION field update with 'CSLT' values \")\n",
    "    # log.info(\"JURISDCITION field update with 'CSLT' values \")\n",
    "\n",
    "    ### Zoning Attribute Update --------------------------------------------------------------------------------------###\n",
    "    # Spatial Join\n",
    "    print(\"Starting the Zoning Spatial Join: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    # log.info(\"Starting the Zoning Spatial Join: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    arcpy.SpatialJoin_analysis(ParcelPoint, sde_Zoning, ParcelPoint_Zoning, \n",
    "                            \"JOIN_ONE_TO_ONE\", \"KEEP_ALL\", \"\", \"HAVE_THEIR_CENTER_IN\", \"\", \"\")\n",
    "    print(\"Finished the Zoning Spatial Join: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    # log.info(\"Finished the Zoning Spatial Join: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "    # transfer attributes to Parcel Layer\n",
    "    fieldJoinCalc_multikey(ParcelLayer, ['APN_TRPA', 'COUNTY_TRPA'],['ZONING_ID_TRPA'], \n",
    "                ParcelPoint_Zoning, ['APN_TRPA', 'COUNTY_TRPA'],['ZONING_ID'])\n",
    "    print(\"The Zoning ID field in the parcel data has been updated\")\n",
    "    # log.info(\"The Zoning ID field in the parcel data has been updated\")\n",
    "\n",
    "    # transfer attributes to Parcel Layer\n",
    "    fieldJoinCalc_multikey(ParcelLayer, ['APN_TRPA', 'COUNTY_TRPA'],['ZONING_DESCRIPTION_TRPA'], \n",
    "                ParcelPoint_Zoning, ['APN_TRPA', 'COUNTY_TRPA'],['ZONING_DESCRIPTION'])\n",
    "    print(\"The Zoning Description field in the parcel data has been updated\")\n",
    "    # log.info(\"The Zoning Description field in the parcel data has been updated\")\n",
    "\n",
    "    # transfer attributes to Parcel Layer\n",
    "    fieldJoinCalc_multikey(ParcelLayer, ['APN_TRPA', 'COUNTY_TRPA'],[\"DESIGN_GUIDELINES_HYPERLINK_TRPA\"], \n",
    "                ParcelPoint_Zoning, ['APN_TRPA', 'COUNTY_TRPA'],[\"DESIGN_GUIDELINES_HYPERLINK\"])\n",
    "    print(\"The DESIGN_GUIDELINES_HYPERLINK field in the parcel data has been updated\")\n",
    "    # log.info(\"The DESIGN_GUIDELINES_HYPERLINK_TRPA field in the parcel data has been updated\")\n",
    "\n",
    "    ### TAZ Attirbute Update --------------------------------------------------------------------------------------###\n",
    "    # Spatial Join\n",
    "    print(\"Starting the TAZ Spatial Join: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    # log.info(\"Starting the TAZ Spatial Join: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    arcpy.SpatialJoin_analysis(ParcelPoint, sde_TAZ, ParcelPoint_TAZ, \n",
    "                            \"JOIN_ONE_TO_ONE\", \"KEEP_ALL\", \"\", \"HAVE_THEIR_CENTER_IN\", \"\", \"\")\n",
    "    print(\"Finished the TAZ Spatial Join: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    # log.info(\"Finished the TAZ Spatial Join: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "    # transfer attributes to Parcel Layer\n",
    "    fieldJoinCalc_multikey(ParcelLayer, ['APN_TRPA', 'COUNTY_TRPA'],['TAZ_TRPA'], \n",
    "                ParcelPoint_TAZ, ['APN_TRPA', 'COUNTY_TRPA'],[\"TAZ\"])\n",
    "    print(\"The TAZ field in the parcel data has been updated\")\n",
    "\n",
    "    ### LTinfo Parcel Details Hyperlink Attribute Update -------------------------------------------------------------###\n",
    "    print(\"Creating LTinfo Hyperlinks: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    # log.info(\"Creating LTinfo Hyperlinks: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "    # create ltinfo hyper link\n",
    "    with arcpy.da.UpdateCursor(ParcelLayer, [\"APN_TRPA\",\"LTINFO_HYPERLINK_TRPA\"]) as cursor:\n",
    "        for row in cursor:\n",
    "            if not (row[0] == None):\n",
    "                row[1] = 'https://parcels.laketahoeinfo.org/Parcel/Detail/'+ row[0]\n",
    "            else:\n",
    "                row[1] = ''\n",
    "            cursor.updateRow(row)\n",
    "    del cursor\n",
    "    print(\"The LTINFO_HYPERLINK field in the parcel data has been updated\")\n",
    "\n",
    "    ### set within TRPA boundary -------------------------------------------------------------------------------------###\n",
    "    print(\"Identifying parcels within TRPA Boundary: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    # log.info('Identifying parcels within TRPA Boundary: ' + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "    # Select all new parcels that have their center within\n",
    "    parcelSelect = arcpy.SelectLayerByLocation_management(ParcelLayer, \n",
    "                                                            'INTERSECT', \n",
    "                                                            sde_TRPAboundary, \n",
    "                                                            0, \n",
    "                                                            'NEW_SELECTION')\n",
    "\n",
    "    # Update field 1= yes 0 = no\n",
    "    with arcpy.da.UpdateCursor(parcelSelect, ['WITHIN_TRPA_BNDY_TRPA']) as cursor:\n",
    "        for row in cursor:\n",
    "            row[0] = '1'\n",
    "            cursor.updateRow(row) \n",
    "    del cursor        \n",
    "    # switch the selection\n",
    "    parcelSelect = arcpy.SelectLayerByAttribute_management(parcelSelect,'SWITCH_SELECTION')\n",
    "\n",
    "    # update other parcels\n",
    "    with arcpy.da.UpdateCursor(parcelSelect, ['WITHIN_TRPA_BNDY_TRPA']) as cursor:\n",
    "        for row in cursor:\n",
    "            row[0] = '0'\n",
    "            cursor.updateRow(row)\n",
    "    del cursor\n",
    "    print(\"Within TRPA Boundary Updated: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    # log.info(\"Within TRPA Boundary Updated: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "    ### set within Bonus Unit Boundary -------------------------------------------------------------------------------###\n",
    "    print(\"Identifying parcels within bonus unit boundary: \"  + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    # log.info(\"Identifying parcels within bonus unit boundary: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "    # Select all new parcels that have their center within\n",
    "    parcelSelect = arcpy.SelectLayerByLocation_management(ParcelLayer, \n",
    "                                                            'HAVE_THEIR_CENTER_IN', \n",
    "                                                            sde_BonusUnitboundary, \n",
    "                                                            0, \n",
    "                                                            'NEW_SELECTION')\n",
    "\n",
    "    with arcpy.da.UpdateCursor(parcelSelect, ['WITHIN_BONUSUNIT_BNDY_TRPA']) as cursor:\n",
    "        for row in cursor:\n",
    "            row[0] = '1'\n",
    "            cursor.updateRow(row) \n",
    "    del cursor   \n",
    "    # switch the selection\n",
    "    parcelSelect = arcpy.SelectLayerByAttribute_management(parcelSelect,'SWITCH_SELECTION')\n",
    "\n",
    "    with arcpy.da.UpdateCursor(parcelSelect, ['WITHIN_BONUSUNIT_BNDY_TRPA']) as cursor:\n",
    "        for row in cursor:\n",
    "            row[0] = '0'\n",
    "            cursor.updateRow(row)\n",
    "    del cursor     \n",
    "    print(\"Bonus Unit Boundary Updated: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    # log.info(\"Bonus Unit Boundary Updated: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    result = arcpy.GetCount_management(ParcelLayer)\n",
    "    print('{} has {} records now.'.format(ParcelLayer, result[0]))\n",
    "\n",
    "    ### Calculate Area Field------------------------------------------------------------------------------------------###\n",
    "    print(\"Calculating Acres...\" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    with arcpy.da.UpdateCursor(ParcelLayer, ['PARCEL_ACRES_TRPA', 'SHAPE@']) as cursor:\n",
    "        for row in cursor:\n",
    "            row[0] = row[1].getArea('PLANAR', 'ACRES')\n",
    "            cursor.updateRow(row)\n",
    "    del cursor\n",
    "\n",
    "    # calculate square feet\n",
    "    print(\"Calculating Square Feet...\" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    with arcpy.da.UpdateCursor(ParcelLayer, ['PARCEL_SQFT_TRPA', 'SHAPE@']) as cursor:\n",
    "        for row in cursor:\n",
    "            row[0] = row[1].getArea('PLANAR', 'SquareFeetUS')\n",
    "            cursor.updateRow(row)\n",
    "    del cursor\n",
    "    ### Set Status to Active--------------------------------------------------------------------------------------------------------###\n",
    "    with arcpy.da.UpdateCursor(ParcelLayer, ['STATUS_TRPA']) as cursor:\n",
    "        for row in cursor:\n",
    "            row[0] = 'A'\n",
    "            cursor.updateRow(row) \n",
    "    del cursor\n",
    "    print(\"The 'STATUS_TRPA' field in the parcel data has been updated\")\n",
    "    \n",
    "    ### Estimated Percent Coverage Allowed Update---------------------------------------------------------------------###\n",
    "    with arcpy.da.UpdateCursor(ParcelLayer, ['ESTIMATED_PRCNT_COV_ALLOWED_TRPA', \"ESTIMATED_COVERAGE_ALLOWED_TRPA\", \"PARCEL_SQFT_TRPA\"]) as cursor:\n",
    "        for row in cursor:\n",
    "            if not row[1] is None:\n",
    "                row[0] = (row[1] / row[2]) * 100\n",
    "            else:\n",
    "                row[0] = None\n",
    "            cursor.updateRow(row) \n",
    "    del cursor  \n",
    "    print(\"The 'ESTIMATED_PRCNT_COV_ALLOWED_TRPA' field in the parcel data has been updated\")\n",
    "\n",
    "    ### IPES Score Update --------------------------------------------------------------------------------------------###\n",
    "    # transfer attributes to Parcel Layer\n",
    "    fieldJoinCalc_multikey(ParcelLayer, ['APN_TRPA', 'JURISDICTION_TRPA'],['IPES_TRPA'], \n",
    "                sde_collect_IPES, ['APN', 'JURISDICTION'],['IPESScore'])\n",
    "    print(\"The 'IPES_TRPA' field in the parcel data has been updated\")\n",
    "\n",
    "    ### Set Status to Active--------------------------------------------------------------------------------------------------------###\n",
    "    with arcpy.da.UpdateCursor(ParcelLayer, ['STATUS_TRPA']) as cursor:\n",
    "        for row in cursor:\n",
    "            row[0] = 'A'\n",
    "            cursor.updateRow(row) \n",
    "    del cursor\n",
    "    print(\"The 'STATUS_TRPA' field in the parcel data has been updated\")\n",
    "    \n",
    "    ### Copy to Feature Class ----------------------------------------------------------------------------------------###\n",
    "    # copy in-memory features to staging feature class\n",
    "    arcpy.CopyFeatures_management(ParcelLayer, ParcelNew)\n",
    "    print(\"Copied in-memory features, parcel staging new is set: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "    arcpy.Delete_management(\"memory\")\n",
    "    print(\"Deleted Memory Workspace: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "    #---------------------------------\n",
    "    # REPLACE NULL\n",
    "    #---------------------------------\n",
    "    # replace null with ''\n",
    "    replace_null_values_with_blank(ParcelNew)\n",
    "    result = arcpy.GetCount_management(ParcelNew)\n",
    "    print('{} has {} records.'.format(ParcelNew, result[0]))\n",
    "    logger.info(f'{ParcelNew} has {result[0]} now')\n",
    "    #---------------------------------\n",
    "    # GET COUNT\n",
    "    #---------------------------------\n",
    "    result = arcpy.GetCount_management(\"Parcel_Staging\")\n",
    "    print('{} has {} records'.format(\"Parcel_Staging\", result[0]))\n",
    "    result = arcpy.GetCount_management(\"Parcel_Staging_Attributed\")\n",
    "    print('{} has {} records'.format(\"Parcel_Staging_Attributed\", result[0]))\n",
    "\n",
    "    #----------------------------------\n",
    "    # ATTRIBUTED TO STAGING FC\n",
    "    #----------------------------------\n",
    "    staging_fc     = \"Parcel_Staging_Attributed\"\n",
    "    new_fc         = \"Parcel_County_Staging\" \n",
    "\n",
    "    # Create FieldMappings object to manage merge output fields\n",
    "    fieldMappings = arcpy.FieldMappings()\n",
    "    # # Add all fields from all parcel staging layers\n",
    "    # fieldMappings.addTable(fc)\n",
    "\n",
    "    for field in arcpy.ListFields(staging_fc):\n",
    "        if not field.name == \"OBJECTID\" and not field.name == \"Shape\":\n",
    "            old_name = field.name\n",
    "\n",
    "            #Rename if necessary\n",
    "            if old_name.endswith(\"_TRPA\"):\n",
    "                new_name = old_name[:-5]\n",
    "            else:\n",
    "                new_name = old_name\n",
    "\n",
    "            #Create new FieldMap object    \n",
    "            new_f = arcpy.FieldMap()\n",
    "            new_f.addInputField(staging_fc, old_name) # Specify the input field to use\n",
    "\n",
    "            #Rename output field\n",
    "            new_f_name = new_f.outputField\n",
    "            new_f_name.name = new_name\n",
    "            new_f_name.aliasName = new_name\n",
    "            new_f.outputField = new_f_name\n",
    "\n",
    "            #Add field to FieldMappings object\n",
    "            fieldMappings.addFieldMap(new_f)\n",
    "\n",
    "    #Convert fc using new field names\n",
    "    arcpy.FeatureClassToFeatureClass_conversion(staging_fc, \n",
    "                                                os.path.dirname(new_fc), \n",
    "                                                os.path.basename(new_fc), \n",
    "                                                field_mapping=fieldMappings)\n",
    "\n",
    "    arcpy.DeleteField_management(\"Parcel_County_Staging\", \n",
    "                                [\"OBJECTID_1\"])\n",
    "\n",
    "    print(\"Parcel_County_Staging is good to go\")\n",
    "    logger.info(\"Parcel County Staging is good to go\")\n",
    "    \n",
    "    # report how long it took to run the script\n",
    "    runTime = datetime.datetime.now() - startTimer\n",
    "    logger.info(f\"\\nTime it took to run this script: {runTime}\")\n",
    "\n",
    "    header = \"SUCCESS - Parcel_County_Staging feature class updated.\"\n",
    "    # send email with header based on try/except result\n",
    "    send_mail(header)\n",
    "\n",
    "# catch any arcpy errors\n",
    "except arcpy.ExecuteError:\n",
    "    logger.error(arcpy.GetMessages())\n",
    "\n",
    "    header = \"ERROR - Arcpy Exception - Check Log\"\n",
    "    # send email with header based on try/except result\n",
    "    send_mail(header)\n",
    "\n",
    "# catch system errors\n",
    "except Exception:\n",
    "    e = sys.exc_info()[1]\n",
    "    logger.info(e.args[0])\n",
    "    logger.error(e)\n",
    "    header = \"ERROR - System Error - Check Log\"\n",
    "    # send email with header based on try/except result\n",
    "    send_mail(header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> TO DO\n",
    "* Add ADU, Bonus Unit, and Allocation fields to Parcel_History_Attributed\n",
    "* Clean up unnecessary fields in Parcel_History_Attributed\n",
    "* Add VHR/Bedrooms to the data\n",
    "* Add CFA research from Ken to the data\n",
    "* Check totals year over year\n",
    "* Add in way to model TAUs as Residential units where City converted Hotels>Apartments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Terminology "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Data engineering can consist of ***collection, cleaning, transformation, processing, and automating and monitoring tasks***\n",
    "* Collection - examples include getting data from a rest service as a\n",
    "* Cleaning - categorizing \n",
    "* Transformation - cateogorizing, standardization, \n",
    "* Processing - algorithm, pivot, groupby, merge\n",
    "* Automating - schedule task, Apache Airflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Planning Jargon\n",
    "* ADU - Accessory Dwelling Unit\n",
    "* Existing Development Right - refers to residential, commercial, or tourist development currently built in the Lake Tahoe Basin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Packages, Maps, and Reference Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from utils import *\n",
    "import getpass\n",
    "from arcgis.features import GeoAccessor, GeoSeriesAccessor\n",
    "from arcgis.mapping import show_styles, display_colormaps\n",
    "from arcgis.gis import GIS\n",
    "from utils import *\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Pandas Options***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data frame display options\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_rows', 2000)\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "   \n",
    "# set environement workspace to in memory \n",
    "arcpy.env.workspace = 'memory'\n",
    "# # set workspace\n",
    "# arcpy.env.workspace = os.path.join(local_path, 'Workspace.gdb')\n",
    "# overwrite true\n",
    "arcpy.env.overwriteOutput = True\n",
    "# Set spatial reference to NAD 1983 UTM Zone 10N\n",
    "sr = arcpy.SpatialReference(26910)\n",
    "arcpy.env.outputCoordinateSystem = sr\n",
    "# # Set the extent environment using a feature class\n",
    "# arcpy.env.extent = \"TRPA_Boundary\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network path to connection files\n",
    "filePath = \"F:/GIS/PARCELUPDATE/Workspace/\"\n",
    "# database file path \n",
    "sdeBase    = os.path.join(filePath, \"Vector.sde\")\n",
    "sdeCollect = os.path.join(filePath, \"Collection.sde\")\n",
    "sdeTabular = os.path.join(filePath, \"Tabular.sde\")\n",
    "# feature classes from sde\n",
    "sde_ParcelAtt        = sdeCollect + \"\\\\SDE.Parcel\\\\SDE.Parcel_History_Attributed\"\n",
    "sde_LocalPlan        = sdeBase + \"\\\\sde.SDE.Planning\\\\sde.SDE.LocalPlan\"\n",
    "sde_CSLT             = sdeBase + \"\\\\sde.SDE.Jurisdictions\\\\sde.SDE.CSLT\"\n",
    "sde_CurrentParcels   = sdeBase + \"\\\\sde.SDE.Parcels\\\\sde.SDE.Parcel_Master\"\n",
    "sde_District         = sdeBase + \"\\\\sde.SDE.Planning\\\\sde.SDE.District\"\n",
    "sde_TownCenter       = sdeBase + \"\\\\sde.SDE.Planning\\\\sde.SDE.TownCenter\"\n",
    "sde_TownCenterBuffer = sdeBase + \"\\\\sde.SDE.Planning\\\\sde.SDE.TownCenter_Buffer\"\n",
    "sde_TRPAboundary     = sdeBase + \"\\\\sde.SDE.Jurisdictions\\\\sde.SDE.TRPA_bdy\"\n",
    "sde_BonusUnitboundary= sdeBase + \"\\\\sde.SDE.Planning\\\\sde.SDE.Bonus_unit_boundary\"\n",
    "sde_UrbanArea        = sdeBase + \"\\\\sde.SDE.Jurisdictions\\\\sde.SDE.UrbanAreas\"\n",
    "sde_Zip              = sdeBase + \"\\\\sde.SDE.Jurisdictions\\\\sde.SDE.Postal_ZIP\"\n",
    "sde_TAZ              = sdeBase + \"\\\\sde.SDE.Transportation\\\\sde.SDE.Transportation_Analysis_Zone\"\n",
    "sdf_County           = sdeBase + \"\\\\sde.SDE.Jurisdictions\\\\SDE.Counties\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map Setups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Map Setup***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the GIS object\n",
    "## portal URL = \"https://maps.trpa.org/portal/home/\"\n",
    "## AGOL URL   = \"https://www.arcgis.com\"\n",
    "gis = GIS(\n",
    "    url=\"https://maps.trpa.org/portal/home/\",\n",
    "    ## enter username above ##\n",
    "    username= input(\"Enter username:\"),\n",
    "    ## enter password above ##\n",
    "    password=getpass.getpass(\"Enter password:\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a map object\n",
    "map = gis.map(\"Lake Tahoe\", zoomlevel=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data from web services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Get Reference Data***\n",
    "* https://www.laketahoeinfo.org/WebServices/List\n",
    "* https://maps.trpa.org/server/rest/services/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LT Info Data\n",
    "# Verified Development Rights\n",
    "dfDevRight  = pd.read_json(\"https://www.laketahoeinfo.org/WebServices/GetParcelDevelopmentRightsForAccela/JSON/e17aeb86-85e3-4260-83fd-a2b32501c476\")\n",
    "# Deed Restrictions as a DataFrame\n",
    "dfDeed      = pd.read_json(\"https://laketahoeinfo.org/WebServices/GetDeedRestrictedParcels/JSON/e17aeb86-85e3-4260-83fd-a2b32501c476\")\n",
    "# IPES LTinfo as a DataFrame\n",
    "dfIPES      = pd.read_json(\"https://www.laketahoeinfo.org/WebServices/GetParcelIPESScores/JSON/e17aeb86-85e3-4260-83fd-a2b32501c476\")\n",
    "# Development Rights Transacted and Banked as a DataFrame\n",
    "dfDevRights = pd.read_json(\"https://www.laketahoeinfo.org/WebServices/GetTransactedAndBankedDevelopmentRights/JSON/e17aeb86-85e3-4260-83fd-a2b32501c476\")\n",
    "# All Parcels as a DataFrame\n",
    "dfLTParcel  = pd.read_json(\"https://www.laketahoeinfo.org/WebServices/GetAllParcels/JSON/e17aeb86-85e3-4260-83fd-a2b32501c476\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRPA Data \n",
    "# Parcel Master as a Spatially Enabled Dataframe from a Feature Service\n",
    "sdfParcel     = get_fs_data_spatial(\"https://maps.trpa.org/server/rest/services/Parcels/FeatureServer/0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRPA Data \n",
    "# Parcel Master as a Spatially Enabled Dataframe from a Feature Service\n",
    "sdfParcel     = get_fs_data_spatial(\"https://maps.trpa.org/server/rest/services/Parcels/FeatureServer/0\")\n",
    "# TRPA Boundary as a Spatially Enabled Dataframe from a Feature Service\n",
    "sdfBoundary   = get_fs_data_spatial(\"https://maps.trpa.org/server/rest/services/Boundaries/FeatureServer/4\")\n",
    "# Plan Area Boundary as a Spatially Enabled Dataframe from a Feature Service\n",
    "sdfPlanArea   = get_fs_data_spatial(\"https://maps.trpa.org/server/rest/services/Boundaries/FeatureServer/0\")\n",
    "# District Boundary as a Spatially Enabled Dataframe from a Feature Service\n",
    "sdfDistrict   = get_fs_data_spatial(\"https://maps.trpa.org/server/rest/services/Zoning/FeatureServer/0\")\n",
    "# Town Center Boundary as a Spatially Enabled Dataframe from a Feature Service\n",
    "sdfTownCenter = get_fs_data_spatial(\"https://maps.trpa.org/server/rest/services/Boundaries/FeatureServer/1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get 2022 development units\n",
    "devhistoryURL = \"https://maps.trpa.org/server/rest/services/Existing_Development/MapServer/2\"\n",
    "# get parcel history for 2023\n",
    "df23 = get_fs_data_query(devhistoryURL, \"Year = 2023\")\n",
    "df22 = get_fs_data_query(devhistoryURL, \"Year = 2022\")\n",
    "df21 = get_fs_data_query(devhistoryURL, \"Year = 2021\")\n",
    "df20 = get_fs_data_query(devhistoryURL, \"Year = 2020\")\n",
    "df19 = get_fs_data_query(devhistoryURL, \"Year = 2019\")\n",
    "df18 = get_fs_data_query(devhistoryURL, \"Year = 2018\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get parcel data\n",
    "sdfParcel     = get_fs_data_spatial(\"https://maps.trpa.org/server/rest/services/Existing_Development/MapServer/2\")\n",
    "# get spatial data to join to\n",
    "sdfDistrict   = get_fs_data_spatial(\"https://maps.trpa.org/server/rest/services/Planning/MapServer/1\")\n",
    "sdfPlan       = get_fs_data_spatial(\"https://maps.trpa.org/server/rest/services/Boundaries/MapServer/0\")\n",
    "sdfTownCenter = get_fs_data_spatial(\"https://maps.trpa.org/server/rest/services/Boundaries/MapServer/1\")\n",
    "sdfTCbuffer   = get_fs_data_spatial(\"https://maps.trpa.org/server/rest/services/Planning/MapServer/4\")\n",
    "sdfCSLT       = get_fs_data_spatial(\"https://maps.trpa.org/server/rest/services/Boundaries/MapServer/2\")\n",
    "sdfCounty     = get_fs_data_spatial(\"https://maps.trpa.org/server/rest/services/Boundaries/MapServer/3\")\n",
    "sdfTRPA       = get_fs_data_spatial(\"https://maps.trpa.org/server/rest/services/Boundaries/MapServer/4\")\n",
    "\n",
    "# set spatial reference\n",
    "sdfParcel.spatial.sr = sr\n",
    "sdfDistrict.spatial.sr = sr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permit Data Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TRPA Permit Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Get Data***\n",
    "> TRPA permit data is exported from accela nightly then stored in colleciton.sde enterprise geodatabase and published to the trpa server as the web service below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# web service url\n",
    "permitTable = \"https://maps.trpa.org/server/rest/services/Permit_Records/MapServer/1\"\n",
    "# get permit data as a dataframe\n",
    "dfTRPAPermit = get_fs_data(permitTable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRPA Permit Data Engineering\n",
    "dfTRPAPermit.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Transformation***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfTRPAPermit\n",
    "\n",
    "# final fields for all permit dataframes\n",
    "fields = ['APN', 'Address', 'Jurisdiction', 'Permit_ID', \n",
    "          'Permit_Type','Permit_Category', 'Permit_Status',  'Description',\n",
    "          'Applied_Date', 'Issued_Date', 'PreGrade_Date', 'Finaled_Date'\n",
    "          ]\n",
    "\n",
    "# # set fields\n",
    "column_mapping = {\n",
    "'Accela_ID' : 'Permit_ID',\n",
    "'Detailed_Description' : 'Description',\n",
    "'Record_Status' : 'Permit_Status',\n",
    "'Accela_CAPType_Name' : 'Permit_Type',\n",
    "'File_Date' : 'Applied_Date'\n",
    "}\n",
    "\n",
    "# rename columns based on dictionary\n",
    "df = renamecolumns(df, column_mapping, False)\n",
    "\n",
    "# add missing fields\n",
    "for field in fields:\n",
    "    # if field not in dataframe add it\n",
    "    if field not in df.columns:\n",
    "        # insert new column\n",
    "        df[field] = None\n",
    "# limit to the final fields\n",
    "df = df[fields]\n",
    "# add jurisdiction value\n",
    "df.Jurisdiction = \"TRPA\"\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Processing***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out unique Record_Status values one at a time\n",
    "for description in dfTRPAPermit.Detailed_Description.unique():\n",
    "    print(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out unique Record_Status values one at a time\n",
    "for permittype in dfTRPAPermit.Accela_CAPType_Name.unique():\n",
    "    print(permittype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out unique Record_Status values one at a time\n",
    "for status in dfTRPAPermit.Record_Status.unique():\n",
    "    print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_lookup = \"resources\\Value_Lookups.csv\"\n",
    "trpa_reportingcategory_lookup = import_lookup_dictionary(value_lookup,'key','value','Jurisdiction','TRPA','FieldName','Reporting_Category')\n",
    "trpa_permittype_lookup        = import_lookup_dictionary(value_lookup,'key','value','Jurisdiction','TRPA','FieldName','Permit_Type')\n",
    "trpa_permitstatus_lookup      = import_lookup_dictionary(value_lookup,'key','value','Jurisdiction','TRPA','FieldName','Permit_Status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update fields from lookup dictionaries\n",
    "df['Reporting_Category'] = df['Reporting_Category'].map(trpa_reportingcategory_lookup)\n",
    "df['Permit_Type'] = df['Permit_Type'].map(trpa_permittype_lookup)\n",
    "df['Permit_Status'] = df['Permit_Status'].map(trpa_permitstatus_lookup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### City of South Lake Tahoe Permit Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Get Data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## City of South Lake Tahoe Permit data was sent over by Ryan Malhoski on 4/9/2021\n",
    "dfCSLTPermit = read_file(\"data\\PermitData_CSLT_040924.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCSLTPermit.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Transformation***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop existing 'Address' field\n",
    "df = dfCSLTPermit.drop('Address', axis=1)\n",
    "\n",
    "# final fields for all permit dataframes\n",
    "fields = ['APN', 'Address', 'Jurisdiction', \n",
    "          'Permit_ID', 'Permit_Type','Permit_Status', 'Description',\n",
    "          'Applied_Date', 'Issued_Date', 'Finaled_Date'\n",
    "          ]\n",
    "\n",
    "# # set fields\n",
    "column_mapping = {\n",
    "            'Parcel ID': 'APN',\n",
    "            'Location Address':'Address',\n",
    "            'Permit Number' : 'Permit_ID',\n",
    "            'Note Text' : 'Description',\n",
    "            'Status' : 'Permit_Status',\n",
    "            'Permit Type' : 'Permit_Type',\n",
    "            'Permit Issue Date' : 'Applied_Date',\n",
    "            'Certificate Issue Date': \"Finaled_Date\"\n",
    "            }\n",
    "\n",
    "# rename columns based on dictionary\n",
    "df = renamecolumns(df, column_mapping,False)\n",
    "\n",
    "# add missing fields\n",
    "for field in fields:\n",
    "    # if field not in dataframe add it\n",
    "    if field not in df.columns:\n",
    "        # insert new column\n",
    "        df[field] = None\n",
    "# limit to the final fields\n",
    "df = df[fields]\n",
    "# add jurisdiction value\n",
    "df.Jurisdiction = \"CSLT\"\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# APN is a PPNO format in the CSLT data, and also contains EL old naming convetion (-0)\n",
    "# need to format to xxx-xxx-xxx and filter any odd values (e.g. 500 series)\n",
    "# get rid of 100's and 500's series, and format to xxx-xxx-xxx, also remove any that start with strings\n",
    "# strip off trailing spaces\n",
    "df.APN = df.APN.str.replace(' ', '') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Processing***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# potential values for Permit Type\n",
    "# \n",
    "# get unique permit types\n",
    "for permittype in dfCSLTPermit[\"Permit Type\"].unique():\n",
    "    print(permittype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### El Dorado County Permit Data\n",
    ">  there are two files, one for all TRPA files and one for all files in our geographic area, including TRPA files and EDC files. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Get Data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## El Dorado Permit data representing all files in our geographic area\n",
    "## exported by Ken Kasman on 4/1/2021 from their Trakit database\n",
    "dfElDoPermit = read_file(\"data\\PermitData_ElDorado_040124.csv\")\n",
    "dfElDoPermit.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Transformation***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop existing 'Address' field\n",
    "df = dfElDoPermit\n",
    "\n",
    "# final fields for all permit dataframes\n",
    "fields = ['APN', 'Address', 'Jurisdiction', \n",
    "          'Permit_ID', 'Permit_Type','Permit_Status','Description',\n",
    "          'Applied_Date', 'Issued_Date', 'Finaled_Date'\n",
    "          ]\n",
    "\n",
    "# # set fields\n",
    "column_mapping = {\n",
    "            'SITE_APN' : 'APN',\n",
    "            'SITE_ADDR':'Address',\n",
    "            'Permit Number' : 'Permit_ID',\n",
    "            'DESCRIPTION' : 'Description',\n",
    "            'STATUS' : 'Permit_Status',\n",
    "            'PERMITTYPE' : 'Permit_Type',\n",
    "            'APPLIED' : 'Applied_Date',\n",
    "            'ISSUED'  : 'Issued_Date',\n",
    "            'FINALED' : \"Finaled_Date\"\n",
    "            }\n",
    "\n",
    "# rename columns based on dictionary\n",
    "df = renamecolumns(df, column_mapping, False)\n",
    "\n",
    "# add missing fields\n",
    "for field in fields:\n",
    "    # if field not in dataframe add it\n",
    "    if field not in df.columns:\n",
    "        # insert new column\n",
    "        df[field] = None\n",
    "# limit to the final fields\n",
    "df = df[fields]\n",
    "# add jurisdiction value\n",
    "df.Jurisdiction = \"EL\"\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for permittype in dfElDoPermit[\"PERMITTYPE\"].unique():\n",
    "    print(permittype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get lookup dictionary\n",
    "lookupTable = read_file(\"resources/lookup_reporting_category.csv\")\n",
    "lookupTable[\"Reporting Category\"].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Processing***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Placer County Permit Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Get Data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Placer Permit Data Comes in monthly via email, and gets saved to the folder below.\n",
    "## The code below will merge all the files in the folder into a single file, return a dataframe, and export to csv\n",
    "\n",
    "# folder with the CSV files\n",
    "folder_path = r\"F:\\Research and Analysis\\Local Jurisdiction MOU data collection\\Placer MOU Files\\Placer\"\n",
    "# List to hold the DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Loop through the files in the folder and identify CSV files\n",
    "for file_name in os.listdir(folder_path):\n",
    "    # Construct the full file path\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    # Read the CSV file into a DataFrame and append to the list\n",
    "    df = pd.read_excel(file_path)\n",
    "    # Append the DataFrame to the list\n",
    "    dfs.append(df)\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "final_df = pd.concat(dfs, ignore_index=True)\n",
    "# Add today's date at the end of the file name _MMDDYY\n",
    "today = pd.Timestamp.today().strftime(\"%m%d%y\")\n",
    "# Export the final DataFrame to a CSV file\n",
    "final_df.to_csv(\"data\\PermitData_Placer_\" + today + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Placer Permit data explained above. \n",
    "dfPlacerPermit =read_file(\"data\\PermitData_Placer_040924.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPlacerPermit.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPlacerPermit.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Transformation***\n",
    "> hyperlink to Placer Accela record can be bulit using SERV_PROD_CODE, B1_PER_ID1, B1_PER_ID2, B1_PER_ID3\n",
    "* https://permits.placer.ca.gov/CitizenAccess/Cap/CapDetail.aspx?Module=TRPA&TabName=TRPA&capID1=16CAP&capID2=00000&capID3=0036O&agencyCode=PLACERCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create lookup dictionary\n",
    "lookupTable = read_file(\"resources/PL_lookup_reporting_category.csv\")\n",
    "lookupTable[\"Reporting Category\"].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Processing***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merege the processed dfs\n",
    "df = pd.concat([dfTRPA, dfCSLT, dfEL, dfPL], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data\\PermitData.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cumulative Accounting Data Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Existing Development Rights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Get Data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spatial join features\n",
    "target_features   = sde_ParcelAtt\n",
    "join_features     = sde_LocalPlan\n",
    "out_feature_class = \"Parcel_District\"\n",
    "# Perform the spatial join\n",
    "arcpy.SpatialJoin_analysis(target_features, join_features, out_feature_class, \"JOIN_ONE_TO_ONE\", \"KEEP_ALL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get in memory feature class as spatial dataframe\n",
    "sdfParcelPlan = get_fs_data_spatial(\"memory\\Parcel_District\")\n",
    "sdfParcelPlan.spatial.sr = sr\n",
    "sdfParcelPlan.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get parcel data as spatial dataframe\n",
    "sdfParcel = get_fs_data_spatial(sde_ParcelAtt)\n",
    "sdfParcel.spatial.sr = sr\n",
    "sdfParcel.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a multikey index for the parcel data of APN and Year\n",
    "sdfParcelPlan['APN_Year'] = sdfParcelPlan['APN'] + sdfParcelPlan['Year'].astype(str)\n",
    "sdfParcelPlan.set_index('APN_Year', inplace=True)\n",
    "sdfParcel['APN_Year'] = sdfParcel['APN'] + sdfParcel['Year'].astype(str)\n",
    "sdfParcel.set_index('APN_Year', inplace=True)\n",
    "\n",
    "# join the dataframes\n",
    "sdfParcel = sdfParcel.join(sdfParcelPlan, how='left', rsuffix='_plan')\n",
    "\n",
    "# map values to new field\n",
    "# map dictionary to sdf_units dataframe to fill in TAZ and Block Group fields\n",
    "sdfParcel['PLAN_NAME']     = sdfParcel.APN_Year.map(dict(zip(sdfParcelPlan.APN_Year, sdfParcelPlan.PLAN_NAME)))\n",
    "sdfParcel['PLAN_ID']       = sdfParcel.APN_Year.map(dict(zip(sdfParcelPlan.APN_Year, sdfParcelPlan.PLAN_ID)))\n",
    "sdfParcel['PLAN_TYPE'] = sdfParcel.APN_Year.map(dict(zip(sdfParcelPlan.APN_Year, sdfParcelPlan.PLAN_CATEGORY)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map values to fields in sdfParcel\n",
    "sdfParcelPlan = sdfParcelPlan[['APN', 'DISTRICT']]\n",
    "\n",
    "# merge the dataframes\n",
    "sdfParcel = pd.merge(sdfParcel, sdfParcelPlan, on='APN_Year', how='left')\n",
    "\n",
    "# drop the index\n",
    "sdfParcel.reset_index(inplace=True)\n",
    "\n",
    "# get results of spatial joins as spatial dataframes\n",
    "sdf_parcel_plan = pd.DataFrame.spatial.from_featureclass(\"Join_PlanArea\", sr=sr)  \n",
    "sdf_parcel_zone = pd.DataFrame.spatial.from_featureclass(\"Join_Zone\", sr=sr)\n",
    "\n",
    "\n",
    "# map dictionary to sdf_units dataframe to fill in TAZ and Block Group fields\n",
    "sdfParcel['PLAN_NAME']     = sdfParcel.APN_Year.map(dict(zip(sdf_parcel_plan.APN_Year, sdf_parcel_plan.PLAN_NAME)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spatial join features\n",
    "target_features   = sde_ParcelAtt\n",
    "join_features     = sde_District\n",
    "out_feature_class = \"Parcel_District\"\n",
    "# Perform the spatial join\n",
    "arcpy.SpatialJoin_analysis(target_features, join_features, out_feature_class, \"JOIN_ONE_TO_ONE\", \"KEEP_ALL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spatial join to get Plan Area\n",
    "arcpy.SpatialJoin_analysis(sdfParcel, sdfPlan, \"Join_PlanArea\", \n",
    "                           \"JOIN_ONE_TO_MANY\", \"KEEP_ALL\", \"\", \"HAVE_THEIR_CENTER_IN\")\n",
    "# spatial join to get District\n",
    "arcpy.SpatialJoin_analysis(sdfParcel, sdfDistrict, \"Join_District\", \n",
    "                           \"JOIN_ONE_TO_ONE\", \"KEEP_ALL\", \"\", \"HAVE_THEIR_CENTER_IN\")\n",
    "# spatial join to get Town Center\n",
    "arcpy.SpatialJoin_analysis(sdfParcel, sdfTownCenter, \"Join_TownCenter\", \n",
    "                           \"JOIN_ONE_TO_ONE\", \"KEEP_ALL\", \"\", \"HAVE_THEIR_CENTER_IN\")\n",
    "# spatial join to get Town Center Buffer\n",
    "arcpy.SpatialJoin_analysis(sdfParcel, sdfTCbuffer, \"Join_TownCenterBuffer\", \n",
    "                           \"JOIN_ONE_TO_ONE\", \"KEEP_ALL\", \"\", \"HAVE_THEIR_CENTER_IN\")\n",
    "# spatial join to get CSLT\n",
    "arcpy.SpatialJoin_analysis(sdfParcel, sdfCSLT, \"Join_CSLT\", \n",
    "                           \"JOIN_ONE_TO_ONE\", \"KEEP_ALL\", \"\", \"HAVE_THEIR_CENTER_IN\")\n",
    "# spatial join to get County\n",
    "arcpy.SpatialJoin_analysis(sdfParcel, sdfCounty, \"Join_County\", \n",
    "                           \"JOIN_ONE_TO_ONE\", \"KEEP_ALL\", \"\", \"HAVE_THEIR_CENTER_IN\")\n",
    "# spatial join to get TRPA Boundary\n",
    "arcpy.SpatialJoin_analysis(sdfParcel, sdfTRPA, \"Join_TRPA\", \n",
    "                           \"JOIN_ONE_TO_ONE\", \"KEEP_ALL\", \"\", \"HAVE_THEIR_CENTER_IN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get results of spatial joins as spatial dataframes\n",
    "sdf_parcel_plan = pd.DataFrame.spatial.from_featureclass(\"Join_PlanArea\", sr=sr)  \n",
    "sdf_parcel_zone = pd.DataFrame.spatial.from_featureclass(\"Join_Zone\", sr=sr)\n",
    "\n",
    "\n",
    "# map dictionary to sdf_units dataframe to fill in TAZ and Block Group fields\n",
    "sdfParcel['PLAN_AREA']     = sdfParcel.APN.map(dict(zip(sdf_parcel_plan.APN, sdf_parcel_plan.PLAN_NAME)))\n",
    "sdfParcel['BLOCK_GROUP']   = sdfParcel.APN.map(dict(zip(sdf_units_block.APN, sdf_units_block.TRPAID)))\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create spatial dataframe from spatial join feature class\n",
    "sdf_PlanJoin   = pd.DataFrame.spatial.from_featureclass(\"Join_PlanArea\", sr=sr)\n",
    "sdf_ZoneJoin   = pd.DataFrame.spatial.from_featureclass(\"Join_Zone\", sr=sr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map dictionary to sdf_units dataframe to fill in TAZ and Block Group fields\n",
    "df['PLAN_NAME_NEW'] = sdfParcel.APN.map(dict(zip(sdf_PlanJoin.APN, sdf_PlanJoin.NAME)))\n",
    "df['PLAN_ID_NEW']   = sdfParcel.APN.map(dict(zip(sdf_PlanJoin.APN, sdf_PlanJoin.ID)))\n",
    "df['ZONE_NAME']     = sdfParcel.APN.map(dict(zip(sdf_ZoneJoin.APN, sdf_ZoneJoin.NAME)))\n",
    "df['ZONE_ID']       = sdfParcel.APN.map(dict(zip(sdf_ZoneJoin.APN, sdf_ZoneJoin.ID)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_PlanJoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the plan name and id\n",
    "df.groupby(['PLAN_ID', 'YEAR']).agg({'Residential_Units':'sum'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot_table(index='APN', columns='YEAR', values=['Residential_Units','CommercialFloorArea_SqFt', 'TouristAccommodation_Units'], aggfunc='sum').reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get 2022 development units\n",
    "devhistoryURL = \"https://maps.trpa.org/server/rest/services/Existing_Development/MapServer/2\"\n",
    "# get parcel history for 2023\n",
    "df = get_fs_data_query(devhistoryURL, \"Year = 2023\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # groub by EXISTING_LANDUSE and aggregate Residential Units\n",
    "# df.groupby(\"EXISTING_LANDUSE\")[\"Residential_Units\"].sum()\n",
    "# flatten out as a dataframe\n",
    "df.groupby(\"EXISTING_LANDUSE\")[\"Residential_Units\"].sum().reset_index()\n",
    "# add a total field\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display all rows\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# group by PLAN_NAME and sum Residential_Units\n",
    "df1 = df.groupby('PLAN_ID').agg({'Residential_Units':'sum', 'TouristAccommodation_Units':'sum','CommercialFloorArea_SqFt':'sum'}).reset_index()\n",
    "\n",
    "# print\n",
    "df1.sort_values('Residential_Units', ascending=False)\n",
    "\n",
    "# add total row\n",
    "df1.loc['Total'] = df1.sum(numeric_only=True, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # export to CSV\n",
    "# df = parcel_history\n",
    "\n",
    "# columns to keep\n",
    "columns_to_keep = ['APN', 'Residential_Units', 'TouristAccommodation_Units',\n",
    "                    'CommercialFloorArea_SqFt', 'YEAR',\n",
    "                    'JURISDICTION', 'COUNTY', \n",
    "                    # 'ADU', 'RBU', 'Allocation','Deed_Restricted_Units',\n",
    "                    'OWNERSHIP_TYPE','EXISTING_LANDUSE',\n",
    "                    # 'WITHIN_TRPA_BNDY'\n",
    "                    'PARCEL_ACRES', 'PARCEL_SQFT']\n",
    "\n",
    "# add integer columns for RBU, ADU, Allocation, and Deed Restricted Units\n",
    "df['ADU'] = 0\n",
    "df['RBU'] = 0\n",
    "df['Allocation'] = 0\n",
    "df['Deed_Restricted_Units'] = 0\n",
    "\n",
    "# keep only the columns in the list\n",
    "df = df[columns_to_keep]\n",
    "# # filter to 2023\n",
    "# df = df[df.YEAR == 2023]\n",
    "\n",
    "# export to csv with date stamp in name\n",
    "today = pd.Timestamp.today().strftime(\"%m%d%y\")\n",
    "df.to_csv(\"data\\DevelopmentHistory_2023_\" + today + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get 2022 development units\n",
    "devhistoryURL = \"https://maps.trpa.org/server/rest/services/Existing_Development/MapServer/2\"\n",
    "parcel_history = get_fs_data_spatial(devhistoryURL)\n",
    "\n",
    "# get unit table as pandas dataframe\n",
    "unitsTable = pd.read_csv(\"data/CumulativeAccounting_2012to2023_Updated.csv\", low_memory=False)\n",
    "# get rid of columns after YEAR\n",
    "unitsTable.drop(unitsTable.columns[unitsTable.columns.get_loc(\"YEAR\")+1:], axis=1,inplace=True)\n",
    "# set cfa to numeric\n",
    "unitsTable['CommercialFloorArea_SqFt'] = pd.to_numeric(unitsTable['CommercialFloorArea_SqFt'], errors='coerce').fillna(0)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "years = [2012, 2018, 2019, 2020, 2021, 2022, 2023]\n",
    "version = \"_v6_\"\n",
    "\n",
    "# merge parcel history and units table by year and \n",
    "# export to feature class\n",
    "def merge_and_export(parcel_history, unitsTable, years):\n",
    "    for year in years:\n",
    "        print(year)\n",
    "        # filter parcel_history by year\n",
    "        parcel_history_year = parcel_history.loc[parcel_history['YEAR'] == year]\n",
    "        # filter unitsTable by year\n",
    "        unitsTable_year = unitsTable.loc[unitsTable['YEAR'] == year]\n",
    "        # merge parcel_history_year and unitsTable_year\n",
    "        df = pd.merge(parcel_history_year, unitsTable_year, on='APN', how='left', indicator=True)\n",
    "        # make sure field types are numeric for Residential_Unit, TouristAccommodation_Units, and CommercialFloorArea_SqFt fields\n",
    "        df['Residential_Units']          = pd.to_numeric(df['Residential_Units_y'], errors='coerce')\n",
    "        df['TouristAccommodation_Units'] = pd.to_numeric(df['TouristAccommodation_Units_y'], errors='coerce')\n",
    "        df['CommercialFloorArea_SqFt']   = pd.to_numeric(df['CommercialFloorArea_SqFt_y'], errors='coerce')\n",
    "        # if NaN in Residential_Units, set to 0\n",
    "        df['Residential_Units'] = df['Residential_Units'].fillna(0)\n",
    "        # if NaN in TouristAccommodation_Units, set to 0\n",
    "        df['TouristAccommodation_Units'] = df['TouristAccommodation_Units'].fillna(0)\n",
    "        # if NaN in CommercialFloorArea_SqFt, set to 0\n",
    "        df['CommercialFloorArea_SqFt'] = df['CommercialFloorArea_SqFt'].fillna(0)\n",
    "        # change YEAR_y to YEAR\n",
    "        df['YEAR'] = df['YEAR_y']\n",
    "        # Sanitize column names\n",
    "        df.columns = [re.sub(r'[^a-zA-Z0-9_]', '_', col) for col in df.columns]\n",
    "        # set output feature class name\n",
    "        yearstr = str(year)\n",
    "        outfc = f\"Parcel_History_Attributed{version}{yearstr}\"    \n",
    "        # export updated parcel history to feature class filtered by year\n",
    "        df.spatial.to_featureclass(location=os.path.join(\"C:/GIS/Scratch.gdb\", outfc), overwrite=True, sanitize_columns=False)\n",
    "\n",
    "# identify parcels that did not join from the merge\n",
    "def get_unjoined(parcel_history, unitsTable, years):\n",
    "    for year in years:\n",
    "        # Filter parcel_history for the current year\n",
    "        parcel_history_filtered = parcel_history.loc[parcel_history['YEAR'] == year]\n",
    "        \n",
    "        # Merge with unitsTable for the same year\n",
    "        units_by_year = unitsTable.loc[unitsTable.YEAR == year]\n",
    "        merged_data = units_by_year.merge(parcel_history_filtered, on='APN', how='outer', indicator=True)\n",
    "        \n",
    "        # Print year and merge value counts\n",
    "        print(year)\n",
    "        print(merged_data._merge.value_counts())\n",
    "        \n",
    "        # Data manipulations\n",
    "        merged_data = merged_data.rename(columns={'YEAR_x': 'YEAR'})\n",
    "        merged_data = merged_data.loc[merged_data._merge != 'both']\n",
    "        merged_data.info()\n",
    "        merged_data = merged_data[['APN', 'YEAR', '_merge', 'CommercialFloorArea_SqFt_x', 'Residential_Units_x', 'TouristAccommodation_Units_x',\n",
    "                                   'CommercialFloorArea_SqFt_y', 'Residential_Units_y', 'TouristAccommodation_Units_y']]\n",
    "        merged_data.info()\n",
    "        # Save to CSV\n",
    "        merged_data.to_csv(f\"data\\\\Parcel_History_Attributed_APN_Merge{version, year}.csv\", index=False)\n",
    "\n",
    "# check for duplicates in parcel_history\n",
    "def check_duplicates(parcel_history, unitsTable, years):\n",
    "    for year in years:\n",
    "        print(year)\n",
    "        # make a list of duplicate APNs\n",
    "        duplicateAPNs = parcel_history.loc[parcel_history['YEAR'] == year].APN[parcel_history.loc[parcel_history['YEAR'] == year].APN.duplicated()].tolist()\n",
    "        # print out duplicate rows\n",
    "        print(duplicateAPNs)\n",
    "        # save 2021 duplicates to csv\n",
    "        if year == 2018:\n",
    "            parcel_history.loc[parcel_history['YEAR'] == year].loc[parcel_history.loc[parcel_history['YEAR'] == year].APN.duplicated()].to_csv(\"data\\Parcel_History_Duplicates_2018.csv\")\n",
    "\n",
    "        # make a list of duplicate APNs in unitsTable\n",
    "        duplicateAPNsCA = unitsTable.loc[unitsTable['YEAR'] == year].APN[unitsTable.loc[unitsTable['YEAR'] == year].APN.duplicated()].tolist()\n",
    "        # print out duplicate rows\n",
    "        print(duplicateAPNsCA)\n",
    "\n",
    "# compare total Residnetial Units, Commercial Floor Area, and Tourist Accommodation Units by year, bewtween parcel_history and unitsTable\n",
    "def compare_totals(parcel_history, unitsTable, years):\n",
    "    for year in years:\n",
    "        # filter parcel_history by year\n",
    "        parcel_history_year = parcel_history.loc[parcel_history['YEAR'] == year]\n",
    "        # filter unitsTable by year\n",
    "        unitsTable_year = unitsTable.loc[unitsTable['YEAR'] == year]\n",
    "        # # remove any commas from CommercialFloorArea_SqFt in unitsTable_year using .loc\n",
    "        # unitsTable_year.loc[:, 'CommercialFloorArea_SqFt'] = unitsTable_year['CommercialFloorArea_SqFt'].str.replace(',', '').astype(float)\n",
    "\n",
    "        # get sum of Residential Units in parcel_history\n",
    "        resTotal = parcel_history_year['Residential_Units'].sum()\n",
    "        cfaTotal = parcel_history_year['CommercialFloorArea_SqFt'].sum()\n",
    "        tauTotal = parcel_history_year['TouristAccommodation_Units'].sum()\n",
    "\n",
    "        # get sum of Residential Units in unitsTable\n",
    "        resTotalCA = unitsTable_year['Residential_Units'].sum()\n",
    "        cfaTotalCA = unitsTable_year['CommercialFloorArea_SqFt'].sum()\n",
    "        tauTotalCA = unitsTable_year['TouristAccommodation_Units'].sum()\n",
    "\n",
    "        # print totals\n",
    "        print(year)\n",
    "        print('Residential Units in Parcel_History \\n' + str(resTotal))\n",
    "        print('Residential Units in updated table \\n'+ str(resTotalCA))\n",
    "        print('Commercial Floor Area in Parcel_History \\n'+ str(cfaTotal))\n",
    "        print('Commercial Floor Area in updated table \\n'+ str(cfaTotalCA))\n",
    "        print('Tourist Accommodation Units in Parcel_History \\n'+ str(tauTotal))\n",
    "        print('Tourist Accommodation Units in updated table \\n'+ str(tauTotalCA))\n",
    "\n",
    "# identify rows where the Residential Units, Commercial Floor Area, and Tourist Accommodation Units are different between parcel_history and unitsTable\n",
    "def find_different_rows(parcel_history, unitsTable, years):\n",
    "    for year in years:\n",
    "        print(year)\n",
    "        # filter parcel_history by year\n",
    "        parcel_history_year = parcel_history.loc[parcel_history['YEAR'] == year]\n",
    "        # filter unitsTable by year\n",
    "        unitsTable_year = unitsTable.loc[unitsTable['YEAR'] == year]\n",
    "        # # remove any commas from CommercialFloorArea_SqFt in unitsTable_year using .loc\n",
    "        # unitsTable_year.loc[:, 'CommercialFloorArea_SqFt'] = unitsTable_year['CommercialFloorArea_SqFt'].str.replace(',', '').astype(float)\n",
    "        # merge parcel_history_year and unitsTable_year\n",
    "        df = pd.merge(parcel_history_year, unitsTable_year, right_on='APN', left_on='APN', how='outer', indicator=True)\n",
    "        # drop columns that are not needed\n",
    "        df = df[['APN', 'YEAR_x','YEAR_y', 'Residential_Units_x', 'CommercialFloorArea_SqFt_x', 'TouristAccommodation_Units_x', 'Residential_Units_y', 'CommercialFloorArea_SqFt_y', 'TouristAccommodation_Units_y']]\n",
    "        # get fields where the Residential Units, Commercial Floor Area, and Tourist Accommodation Units do not match\n",
    "        df = df.loc[(df['Residential_Units_x'] != df['Residential_Units_y']) | (df['CommercialFloorArea_SqFt_x'] != df['CommercialFloorArea_SqFt_y']) | (df['TouristAccommodation_Units_x'] != df['TouristAccommodation_Units_y'])]\n",
    "        # print out the rows\n",
    "        print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the merge functions to export feature classes and get unjoined data as csv\n",
    "# merge_and_export(parcel_history, unitsTable, years)\n",
    "get_unjoined(parcel_history, unitsTable, years)\n",
    "check_duplicates(parcel_history, unitsTable, years)\n",
    "compare_totals(parcel_history, unitsTable, years)\n",
    "find_different_rows(parcel_history, unitsTable, years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze the changes in parcel history by year\n",
    "years = [2012, 2018, 2019, 2020, 2021, 2022, 2023]\n",
    "df = sdfUnits\n",
    "for year in years:\n",
    "    print(year)\n",
    "    # filter parcel_history by year\n",
    "    parcel_history_year = df.loc[df['YEAR'] == year]\n",
    "    # get sum of Residential Units in parcel_history\n",
    "    resTotal = parcel_history_year['Residential_Units'].sum()\n",
    "    cfaTotal = parcel_history_year['CommercialFloorArea_SqFt'].sum()\n",
    "    tauTotal = parcel_history_year['TouristAccommodation_Units'].sum()\n",
    "    # print totals\n",
    "    print('Residential Units in Parcel_History \\n' + str(resTotal))\n",
    "    print('Commercial Floor Area in Parcel_History \\n'+ str(cfaTotal))\n",
    "    print('Tourist Accommodation Units in Parcel_History \\n'+ str(tauTotal))\n",
    "    # print out changes in units by APN\n",
    "# firnd all the rows where duplicate APNs change units between years\n",
    "for year in years:\n",
    "    print(year)\n",
    "    # make a list of duplicate APNs as sets of APNs\n",
    "    duplicateAPNs = df.loc[df['YEAR'] == year].APN[df.loc[df['YEAR'] == year].APN.duplicated()].tolist()\n",
    "    # loop through the duplicate APNs\n",
    "    for apn in duplicateAPNs:\n",
    "        # get the rows for the APN\n",
    "        df = df.loc[df['APN'] == apn]\n",
    "        # get the rows for the APN by year\n",
    "        df = df.loc[df['YEAR'] == year]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get total residential units by year\n",
    "def get_totals(parcels, years):\n",
    "    # total\n",
    "    total = pd.DataFrame(columns=['Year', 'Residential_Units'])\n",
    "    for year in years:\n",
    "        # filter parcel_history by year\n",
    "        parcel_history_year = parcels.loc[parcels['YEAR'] == year]\n",
    "        # get sum of Residential Units in parcel_history\n",
    "        resTotal = parcel_history_year['Residential_Units'].sum()\n",
    "\n",
    "        # add new row using concat\n",
    "        total = pd.concat([total, pd.DataFrame({'Year': [year], 'Residential_Units': [resTotal]})])\n",
    "    return total\n",
    "\n",
    "# get total residential units by year\n",
    "total = get_totals(parcel_history, years)\n",
    "# calculate percentage change in residential units year over year\n",
    "total['Percent_Change'] = (total['Residential_Units'].pct_change())*100\n",
    "# create a new column for the difference in residential units year over year\n",
    "total['Difference'] = total['Residential_Units'].diff()\n",
    "\n",
    "total\n",
    "# export to csv\n",
    "total.to_csv('total_residential_units_by_year.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Transformation***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Proecssing***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deed Restrictions\n",
    "> Deed restricted unit research needs to be merged with LTinfo housing deed restricitons and parcel unit data from 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Get Data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDeedUnits  = read_excel(\"data\\Housing_Deed_Restrcitions.xlsx\", 0)\n",
    "dfDeedLTinfo = pd.read_json(\"https://laketahoeinfo.org/WebServices/GetDeedRestrictedParcels/JSON/e17aeb86-85e3-4260-83fd-a2b32501c476\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDeedUnits.to_csv(\"data\\DeedRestricted_HousingUnits.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDeedUnits.Units.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDeedLTinfo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unique values for deed restrcition type\n",
    "dfDeedLTinfo.DeedRestrictionType.unique()\n",
    "\n",
    "# filter to Affordable, Achievable, and Moderate\n",
    "dfDeedLTinfo = dfDeedLTinfo[dfDeedLTinfo.DeedRestrictionType.isin(['Affordable Housing', 'Moderate Income Housing', 'Achievable Housing'])]  \n",
    "\n",
    "# count of total records\n",
    "dfDeedLTinfo.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcelUnits22.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDeedUnitsMerge = dfDeedUnits.merge(dfDeedLTinfo, on='APN', how='outer', indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDeedUnitsMerge._merge.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDeedLTinfo[dfDeedLTinfo.duplicated(subset=['APN','DeedRestrictionType'], keep=False)].sort_values('APN').to_csv(\"HousingDeedRestrictions_LTinfo_Duplicates.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify duplicates unique by APN and \n",
    "dfDeedUnits[dfDeedUnits.duplicated(subset=['APN', 'Deed_Restriction_Type','Units'], keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify duplicates\n",
    "dfDeedUnitsMerge[dfDeedUnitsMerge.duplicated(subset=['APN'], keep=False)].sort_values(by='APN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDeedUnitsMerge.to_csv(\"HousingDeedRestrictions_All.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the deed restricted units with the parcel units\n",
    "dfDeedUnits_ParcelUnits  = dfDeedUnits.merge(parcelUnits22, on='APN', how='left')\n",
    "# merge the deed restricted units with the parcel units\n",
    "dfDeedLTinfo_ParcelUnits = dfDeedLTinfo.merge(parcelUnits22, left_on='APN', right_on='APN', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDeedLTinfo_ParcelUnits.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDeedLTinfo_ParcelUnits.Residential_Units.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ADU Tracking\n",
    "> ADU permit tracking from TRPA and othe Jurisdictions. There is a need to establish a system of record for this information (LT Info). This is similar to the Residential Bonus Unit data and there’s crossover on some of these, where a bonus unit was used to create an ADU, but you can have an ADU without requiring a bonus unit, and you can use a bonus unit without it being an ADU… "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Get Data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfADU = read_excel(\"data\\ADU Tracking.xlsx\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfADU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Allocations\n",
    "> This file includes all of the allocations that have been tracked in LT Info, and adds in whether the subject parcel has been issued a BMP/SCC certificate and/or whether Air Quality/Mobility Mitigation fees (for added VMT) or Water Quality Mitigation fees (for added coverage) have been paid. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allocations = read_excel(\"data\\Allocation_Tracking.xlsx\", 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transactions with Inactive APNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inactiveParcels = read_file(\"data\\Transactions_InactiveParcels.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QA Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Process to compare against assessor parcel data signifying development\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create parcels feature class of missing parcels for Residential Units\n",
    "\n",
    "# get parcel master\n",
    "parcelURL = \"https://maps.trpa.org/server/rest/services/Parcels/MapServer/0\"\n",
    "vhrURL    = \"https://maps.trpa.org/server/rest/services/VHR/MapServer/0\"\n",
    "# get parcel and VHR data as spatial dataframes\n",
    "sdfParcel = get_fs_data_spatial(parcelURL)\n",
    "# sdfVHR    = get_fs_data_spatial(vhrURL)\n",
    "\n",
    "# # keep only the columns needed\n",
    "# sdfParcel = sdfParcel[['APN','EXISTING_LANDUSE','YEAR_BUILT','BEDROOMS','UNITS','SHAPE']]\n",
    "# sdfVHR    = sdfVHR[['APN','SHAPE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets feature service data as spatially enabled dataframe\n",
    "def get_fs_data_spatial(service_url):\n",
    "    feature_layer = FeatureLayer(service_url)\n",
    "    df = feature_layer.query().sdf\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the parcel and VHR data\n",
    "sdf = pd.merge(sdfParcel, sdfVHR, on='APN', how='left', indicator=True)\n",
    "# merge the 2023 parcelhistory and \n",
    "parcelDev2023 = parcel_history.loc[parcel_history['YEAR'] == 2023]\n",
    "sdf = pd.merge(sdf, parcelDev2023, on='APN', how='left', indicator=True)\n",
    "sdf.info()\n",
    "# # keep fields needed for QA\n",
    "# sdf = sdf[['APN','EXISTING_LANDUSE','YEAR_BUILT','BEDROOMS','UNITS','WITHIN_TRPABNDY','_merge','SHAPE']]\n",
    "# # export to feature class\n",
    "# sdf.spatial.to_featureclass(location=os.path.join(arcpy.env.workspace, 'Parcel_Review'), overwrite=True, sanitize_columns=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
