{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Engineering Notebook\n",
    "> Data engineering can consist of ***collection, cleaning, transformation, processing, and automating and monitoring tasks***\n",
    "* Collection \n",
    "* Cleaning\n",
    "* Transformation\n",
    "* Processing\n",
    "* Automating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages and modules\n",
    "import os,arcpy\n",
    "from arcgis.features import FeatureSet, GeoAccessor, GeoSeriesAccessor\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "import pyodbc\n",
    "\n",
    "# set data frame display options\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "# set overwrite to true\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "# in memory output file path\n",
    "wk_memory = \"memory\" + \"\\\\\"\n",
    "\n",
    "# set workspace and sde connections \n",
    "scratchFolder = \"C:\\\\GIS\"\n",
    "workspace     = \"//Trpa-fs01/GIS/PROJECTS/ResearchAnalysis/MailingLists/IPES\"\n",
    "desktop       = \"C:\\\\Users\\\\mbindl\\\\Desktop\"\n",
    "arcpy.env.workspace = \"C:\\\\GIS\\\\Scratch.gdb\"\n",
    "\n",
    "## SDE Connection Files saved on the Network\n",
    "# sdeTabular = \"F:\\\\GIS\\\\GIS_DATA\\\\Tabular.sde\"\n",
    "# sdeBase    = \"F:\\\\GIS\\\\GIS_DATA\\\\Vector.sde\"\n",
    "# sdeCollect = \"F:\\\\GIS\\\\GIS_DATA\\\\Collect.sde\"\n",
    "\n",
    "# network path to connection files\n",
    "filePath = \"C:\\\\GIS\\\\DB_CONNECT\"\n",
    "\n",
    "# database file path \n",
    "sdeBase = os.path.join(filePath, \"Vector.sde\")\n",
    "sdeCollect = os.path.join(filePath, \"Collection.sde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from utils import *\n",
    "\n",
    "# read_file, read_excel, get_fs_data, get_fs_data_query, get_fs_data_spatial, get_fs_data_spatial_query, import_lookup_dictionary, update_field_from_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Get Reference Data***\n",
    "* https://www.laketahoeinfo.org/WebServices/List\n",
    "* https://maps.trpa.org/server/rest/services/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LT Info Data\n",
    "# Deed Restrictions as a DataFrame\n",
    "dfDeed      = pd.read_json(\"https://laketahoeinfo.org/WebServices/GetDeedRestrictedParcels/JSON/e17aeb86-85e3-4260-83fd-a2b32501c476\")\n",
    "# IPES LTinfo as a DataFrame\n",
    "dfIPES      = pd.read_json(\"https://www.laketahoeinfo.org/WebServices/GetParcelIPESScores/JSON/e17aeb86-85e3-4260-83fd-a2b32501c476\")\n",
    "# Development Rights Transacted and Banked as a DataFrame\n",
    "dfDevRights = pd.read_json(\"https://www.laketahoeinfo.org/WebServices/GetTransactedAndBankedDevelopmentRights/JSON/e17aeb86-85e3-4260-83fd-a2b32501c476\")\n",
    "# All Parcels as a DataFrame\n",
    "dfLTParcel  = pd.read_json(\"https://www.laketahoeinfo.org/WebServices/GetAllParcels/JSON/e17aeb86-85e3-4260-83fd-a2b32501c476\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRPA Data \n",
    "# Parcel Master as a Spatially Enabled Dataframe from a Feature Service\n",
    "sdfParcel     = get_fs_data_spatial(\"https://maps.trpa.org/server/rest/services/Parcels/MapServer/0\")\n",
    "# TRPA Boundary as a Spatially Enabled Dataframe from a Feature Service\n",
    "sdfBoundary   = get_fs_data_spatial(\"https://maps.trpa.org/server/rest/services/Boundaries/MapServer/4\")\n",
    "# Plan Area Boundary as a Spatially Enabled Dataframe from a Feature Service\n",
    "sdfPlanArea   = get_fs_data_spatial(\"https://maps.trpa.org/server/rest/services/Boundaries/MapServer/0\")\n",
    "# District Boundary as a Spatially Enabled Dataframe from a Feature Service\n",
    "sdfDistrict   = get_fs_data_spatial(\"https://maps.trpa.org/server/rest/services/Zoning/MapServer/0\")\n",
    "# Town Center Boundary as a Spatially Enabled Dataframe from a Feature Service\n",
    "sdfTownCenter = get_fs_data_spatial(\"https://maps.trpa.org/server/rest/services/Boundaries/MapServer/1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permit Data Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TRPA Permit Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Get Data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRPA permit data is exported from accela nightly\n",
    "## then stored in colleciton.sde enterprise geodatabase and published to the trpa server as the web service below\n",
    "# web service url\n",
    "permitTable = \"https://maps.trpa.org/server/rest/services/Permit_Records/MapServer/1\"\n",
    "# get permit data as a dataframe\n",
    "dfTRPAPermit = get_fs_data(permitTable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRPA Permit Data Engineering\n",
    "dfTRPAPermit.info()\n",
    "dfTRPAPermit.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Transformation***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the permit type and description lookup dictionary\n",
    "permitTypeDict = import_lookup_dictionary(\"https://maps.trpa.org/server/rest/services/Permit_Records/MapServer/2\")\n",
    "# update the permit type and description fields\n",
    "dfTRPAPermit = update_field_from_dictionary(dfTRPAPermit, \"PermitType\", permitTypeDict, \"PermitTypeDesc\")\n",
    "# get the permit status lookup dictionary\n",
    "permitStatusDict = import_lookup_dictionary(\"https://maps.trpa.org/server/rest/services/Permit_Records/MapServer/3\")\n",
    "# update the permit status field\n",
    "dfTRPAPermit = update_field_from_dictionary(dfTRPAPermit, \"PermitStatus\", permitStatusDict, \"PermitStatusDesc\")\n",
    "# get the permit category lookup dictionary\n",
    "permitCategoryDict = import_lookup_dictionary(\"https://maps.trpa.org/server/rest/services/Permit_Records/MapServer/4\")\n",
    "# update the permit category field\n",
    "dfTRPAPermit = update_field_from_dictionary(dfTRPAPermit, \"PermitCategory\", permitCategoryDict, \"PermitCategoryDesc\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Processing***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot the permit data to get the permit counts by permit type\n",
    "dfPermitType = dfTRPAPermit.pivot_table(index='PermitTypeDesc', columns='PermitStatusDesc', values='OBJECTID', aggfunc='count', fill_value=0)\n",
    "dfPermitType = dfPermitType.reset_index()\n",
    "dfPermitType.columns.name = None\n",
    "dfPermitType = dfPermitType.rename_axis(None, axis=1)\n",
    "dfPermitType = dfPermitType.rename(columns={\"PermitTypeDesc\":\"Permit Type\"})\n",
    "dfPermitType = dfPermitType.sort_values(\"Permit Type\", ascending=True)\n",
    "dfPermitType[\"Total\"] = dfPermitType.sum(axis=1)\n",
    "dfPermitType = dfPermitType.sort_values(\"Total\", ascending=False)\n",
    "dfPermitType\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### City of South Lake Tahoe Permit Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Get Data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## City of South Lake Tahoe Permit data was sent over by Ryan Malhoski on 4/9/2021\n",
    "dfCSLTPermit = read_file(\"data\\PermitData_CSLT_040924.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CSLT Permit Data Engineering\n",
    "# get unique permit status\n",
    "dfCSLTPermit.Status.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Transformation***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Processing***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### El Dorado County Permit Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Get Data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El Dorado Permit data was exporeted by Ken Kasman on 4/1/2021 from their Trakit database\n",
    "dfElDoPermit = read_file(\"data\\PermitData_ElDorado_040124.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Transformation***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get lookup dictionary\n",
    "lookupTable = read_file(\"resources/lookup_reporting_category.csv\")\n",
    "lookupTable[\"Reporting Category\"].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Processing***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Placer County Permit Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Get Data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Placer Permit Data Comes in monthly via email, and gets saved to the folder below.\n",
    "## The code below will merge all the files in the folder into a single file, return a dataframe, and export to csv\n",
    "\n",
    "# folder with the CSV files\n",
    "folder_path = r\"F:\\Research and Analysis\\Local Jurisdiction MOU data collection\\Placer MOU Files\\Placer\"\n",
    "# List to hold the DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Loop through the files in the folder and identify CSV files\n",
    "for file_name in os.listdir(folder_path):\n",
    "    # Construct the full file path\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    # Read the CSV file into a DataFrame and append to the list\n",
    "    df = pd.read_excel(file_path)\n",
    "    # Append the DataFrame to the list\n",
    "    dfs.append(df)\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "final_df = pd.concat(dfs, ignore_index=True)\n",
    "# Add today's date at the end of the file name _MMDDYY\n",
    "today = pd.Timestamp.today().strftime(\"%m%d%y\")\n",
    "# Export the final DataFrame to a CSV file\n",
    "final_df.to_csv(\"data\\PermitData_Placer_\" + today + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Placer Permit data explained above. \n",
    "dfPlacerPermit =read_file(\"data\\PermitData_Placer_040924.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Transformation***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create lookup dictionary\n",
    "lookupTable = read_file(\"resources/PL_lookup_reporting_category.csv\")\n",
    "lookupTable[\"Reporting Category\"].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Processing***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cumulative Accounting Data Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Get Data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get 2022 development units\n",
    "devhistoryURL = \"https://maps.trpa.org/server/rest/services/Existing_Development/MapServer/2\"\n",
    "parcelUnits12 = get_fs_data_spatial_query(devhistoryURL, \"Year = 2012\")\n",
    "parcelUnits18 = get_fs_data_spatial_query(devhistoryURL, \"Year = 2018\")\n",
    "parcelUnits19 = get_fs_data_spatial_query(devhistoryURL, \"Year = 2019\")\n",
    "parcelUnits20 = get_fs_data_spatial_query(devhistoryURL, \"Year = 2020\")\n",
    "parcelUnits21 = get_fs_data_spatial_query(devhistoryURL, \"Year = 2021\")\n",
    "parcelUnits22 = get_fs_data_spatial_query(devhistoryURL, \"Year = 2022\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcelUnits12.Residential_Units.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Transformation***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deed Restrictions\n",
    "> We need to get Ken's housing deed restricted unit research merged with LTinfo housing deed restricitons and unit data from 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Get Data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDeedUnits = read_excel(\"data\\Housing_Deed_Restrcitions.xlsx\", sheet=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ADU Tracking\n",
    "> I’ve been working on tracking ADU permits from TRPA and other jurisdictions where I’ve located them. This is a compilation of other information, but over time I’d like to establish a system of record for this information (LT Info). This is similar to the Residential Bonus Unit data and there’s crossover on some of these, where a bonus unit was used to create an ADU, but you can have an ADU without requiring a bonus unit, and you can use a bonus unit without it being an ADU… "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Get Data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfADU = read_excel(\"data\\ADU Tracking.xlsx\", sheet=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Allocations\n",
    "> this file includes all of the allocations that have been tracked in LT Info, and adds in whether the subject parcel has been issued a BMP/SCC certificate and/or whether Air Quality/Mobility Mitigation fees (for added VMT) or Water Quality Mitigation fees (for added coverage) have been paid. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allocations = read_excel(\"data\\Allocation_Tracking.xlsx\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transactions with Inactive APNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inactiveParcels = read_file(\"data\\Transactions_InactiveParcels.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
